require("regenerator-runtime/runtime");
const Runtime = require('../../engine/runtime');

const ArgumentType = require('../../extension-support/argument-type');
const BlockType = require('../../extension-support/block-type');
const Clone = require('../../util/clone');
const Cast = require('../../util/cast');
const formatMessage = require('format-message');
const Video = require('../../io/video');

const VideoMotion = require('./library');

const tmImage = require('@teachablemachine/image');
const tmPose = require('@teachablemachine/pose');
const tmAudioSpeechCommands = require('@tensorflow-models/speech-commands');

/**
 * Icon svg to be displayed in the blocks category menu, encoded as a data URI.
 * @type {string}
 */
// eslint-disable-next-line max-len
const menuIconURI = 'data:image/svg+xml;base64,<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<svg
   xmlns:dc="http://purl.org/dc/elements/1.1/"
   xmlns:cc="http://creativecommons.org/ns#"
   xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
   xmlns:svg="http://www.w3.org/2000/svg"
   xmlns="http://www.w3.org/2000/svg"
   xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
   id="Layer_1_1_"
   enable-background="new 0 0 64 64"
   height="72.780205"
   viewBox="0 0 9.1991234 9.0975256"
   width="73.592987"
   version="1.1"
   inkscape:version="0.48.4 r9939"
   sodipodi:docname="teachable-machine-blocks-menu.svg">
  <metadata
     id="metadata21">
    <rdf:RDF>
      <cc:Work
         rdf:about="">
        <dc:format>image/svg+xml</dc:format>
        <dc:type
           rdf:resource="http://purl.org/dc/dcmitype/StillImage" />
        <dc:title />
      </cc:Work>
    </rdf:RDF>
  </metadata>
  <defs
     id="defs19" />
  <sodipodi:namedview
     pagecolor="#ffffff"
     bordercolor="#666666"
     borderopacity="1"
     objecttolerance="10"
     gridtolerance="10"
     guidetolerance="10"
     inkscape:pageopacity="0"
     inkscape:pageshadow="2"
     inkscape:window-width="1855"
     inkscape:window-height="1056"
     id="namedview17"
     showgrid="false"
     fit-margin-top="0"
     fit-margin-left="0"
     fit-margin-right="0"
     fit-margin-bottom="0"
     inkscape:zoom="10.429825"
     inkscape:cx="26.215729"
     inkscape:cy="44.901574"
     inkscape:window-x="65"
     inkscape:window-y="24"
     inkscape:window-maximized="1"
     inkscape:current-layer="Layer_1_1_" />
  <path
     sodipodi:type="arc"
     style="fill:#80b3ff;fill-opacity:1;stroke:#0055d4"
     id="path2993"
     sodipodi:cx="-4.3624892"
     sodipodi:cy="28.581223"
     sodipodi:rx="32.934399"
     sodipodi:ry="32.934399"
     d="m 28.571909,28.581223 a 32.934399,32.934399 0 1 1 -65.868797,0 32.934399,32.934399 0 1 1 65.868797,0 z"
     transform="matrix(0.13755698,0,0,0.13610137,5.2013733,0.65924101)" />
  <path
     d="m 2.9791233,6.137428 c 0,0.139175 -0.03202,0.269729 -0.09114,0.385503 -0.140407,0.283277 -0.433537,0.476644 -0.771006,0.476644 -0.476644,0 -0.862147,-0.385503 -0.862147,-0.862147 0,-0.476644 0.385503,-0.862147 0.862147,-0.862147 0.173661,0 0.333774,0.0505 0.468023,0.137943 0.237706,0.153955 0.394124,0.419989 0.394124,0.724204 z"
     id="path3"
     inkscape:connector-curvature="0"
     style="fill:#f6db40;fill-opacity:1" />
  <path
     d="m 7.5002307,3.8572393 c 0.476644,0 0.862147,0.385503 0.862147,0.862147 0,0.476644 -0.385503,0.862147 -0.862147,0.862147 -0.231548,0 -0.440926,-0.08991 -0.594881,-0.24017 -0.16504,-0.155186 -0.267266,-0.376881 -0.267266,-0.621977 0,-0.03941 0.0025,-0.07759 0.0086,-0.115774 0.02463,-0.192136 0.113311,-0.363334 0.243864,-0.493887 0.156418,-0.156418 0.370723,-0.252486 0.609661,-0.252486 z"
     id="path7"
     inkscape:connector-curvature="0"
     style="fill:#f6db40" />
  <path
     style="fill:#f6db40;fill-opacity:1;stroke:none"
     d="M 1.6842184,3.641441 C 1.2629901,3.3627243 1.2006396,2.7462127 1.5557106,2.3707757 1.9022591,2.0043501 2.4951785,2.0633456 2.7794918,2.4925419 3.2449268,3.1951577 2.3803563,4.1020583 1.6842184,3.641441 z"
     id="path2988"
     inkscape:connector-curvature="0" />
  <path
     style="fill:#f6db40;fill-opacity:1;stroke:none"
     d="M 4.3049044,2.5776682 C 4.0127706,2.3282715 3.9342559,2.0011231 4.0810112,1.6447697 4.3064184,1.0974329 4.9784113,0.92659387 5.3886513,1.3123316 6.1978274,2.0731787 5.1487365,3.2980525 4.3049044,2.5776682 z"
     id="path2990"
     inkscape:connector-curvature="0" />
  <path
     style="fill:#f6db40;fill-opacity:1;stroke:none"
     d="M 4.3784972,4.9757011 C 3.8278365,4.6409554 3.8928456,3.8504273 4.4938182,3.5733694 4.866088,3.4017469 5.2893822,3.5302824 5.5101175,3.8819738 5.7301862,4.2326033 5.7089766,4.5244492 5.4425609,4.8115608 5.1456488,5.1315377 4.7382343,5.1943846 4.3784972,4.9757011 z"
     id="path2992"
     inkscape:connector-curvature="0" />
  <path
     style="fill:#f6db40;fill-opacity:1;stroke:none"
     d="M 4.3246268,7.9820751 C 4.0366848,7.7379754 3.9592965,7.4177752 4.1039462,7.0689904 4.326119,6.5332782 4.9884695,6.3660676 5.392823,6.7436128 6.1903885,7.4883005 5.1563507,8.6871597 4.3246268,7.9820751 z"
     id="path2994"
     inkscape:connector-curvature="0" />
  <path
     style="fill:#f6db40;fill-opacity:1;stroke:none"
     d=""
     id="path3001"
     inkscape:connector-curvature="0" />
  <path
     d="m 2.5436163,5.250648 c -0.129322,-0.06244 -0.27367,-0.09853 -0.42664,-0.09853 -0.543275,0 -0.985311,0.442035 -0.985311,0.985311 0,0.543276 0.442036,0.985311 0.985311,0.985311 0.340918,0 0.641807,-0.174154 0.818793,-0.438094 l 0.93075,0.465929 c -0.01601,0.07033 -0.02525,0.143362 -0.02525,0.218492 0,0.543276 0.442035,0.985311 0.985311,0.985311 0.543275,0 0.98531,-0.442035 0.98531,-0.985311 0,-0.204205 -0.06244,-0.394001 -0.16935,-0.551527 l 1.307877,-1.367489 c 0.164054,0.121686 0.366289,0.194722 0.585767,0.194722 0.543276,0 0.985311,-0.442035 0.985311,-0.98531 0,-0.543276 -0.442035,-0.985311 -0.985311,-0.985311 -0.22736,0 -0.436246,0.07809 -0.603256,0.207901 L 5.6039903,2.553115 c 0.129815,-0.16701 0.2079,-0.375896 0.2079,-0.603257 0,-0.543275 -0.442035,-0.98531102 -0.98531,-0.98531102 -0.543276,0 -0.985311,0.44203602 -0.985311,0.98531102 0,0.07488 0.0091,0.147674 0.02512,0.217877 L 2.9929113,2.48599 C 2.8292333,2.168104 2.4984153,1.949857 2.1169763,1.949857 c -0.543275,0 -0.985311,0.442035 -0.985311,0.985311 0,0.543276 0.442036,0.985311 0.985311,0.985311 0.140161,0 0.273301,-0.02981 0.394125,-0.08289 l 0.453366,0.763 z m -0.42664,1.625763 c -0.407549,0 -0.738983,-0.331434 -0.738983,-0.738983 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.407549 -0.331434,0.738983 -0.738983,0.738983 z m 0.928532,-0.412476 c 0.03609,-0.102349 0.05678,-0.211965 0.05678,-0.326507 0,-0.302121 -0.136958,-0.572589 -0.351633,-0.753393 l 0.354219,-0.547094 1.067954,1.797083 c -0.08991,0.08006 -0.165163,0.175878 -0.220956,0.283647 z m 1.781073,-3.528767 c 0.22736,0 0.436246,-0.07809 0.603256,-0.207901 l 1.329061,1.329061 c -0.07969,0.102473 -0.139298,0.220833 -0.173661,0.349663 L 5.8115223,4.299577 c -1.23e-4,-0.0032 3.69e-4,-0.0064 3.69e-4,-0.0096 0,-0.543275 -0.442035,-0.985311 -0.98531,-0.985311 -0.340918,0 -0.64193,0.174154 -0.818793,0.438094 L 3.8608533,3.66935 4.4000643,2.836639 c 0.129199,0.06244 0.273547,0.09853 0.426517,0.09853 z m 0.123164,3.457086 V 5.266659 c 0.400282,-0.05025 0.725927,-0.341163 0.827907,-0.723218 l 0.773715,0.106414 c 0,0.0032 -4.92e-4,0.0064 -4.92e-4,0.0096 0,0.235243 0.08301,0.451149 0.221079,0.620746 L 5.4787333,6.632416 C 5.3337693,6.503956 5.1513643,6.417619 4.9497453,6.392247 z M 4.8265813,3.550987 c 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.407549 -0.331434,0.738983 -0.738983,0.738983 -0.407549,0 -0.738983,-0.331434 -0.738983,-0.738983 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 z m -0.928532,0.412476 c -0.03609,0.102349 -0.05678,0.211965 -0.05678,0.326507 0,0.501523 0.376881,0.915847 0.862147,0.976813 v 1.125594 c -0.116759,0.01466 -0.226991,0.04964 -0.32737,0.101487 L 3.2542703,4.606132 3.7261113,3.877495 z m 0.928532,4.144586 c -0.407549,0 -0.738983,-0.331434 -0.738983,-0.738983 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.407549 -0.331434,0.738983 -0.738983,0.738983 z m 2.709604,-4.18757 c 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.407549 -0.331434,0.738983 -0.738983,0.738983 -0.407549,0 -0.738983,-0.331434 -0.738983,-0.738983 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 z M 4.8265813,1.210874 c 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.407549 -0.331434,0.738983 -0.738983,0.738983 -0.407549,0 -0.738983,-0.331434 -0.738983,-0.738983 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 z m -0.875818,1.188162 c 0.06023,0.116882 0.142623,0.220217 0.242263,0.304214 L 3.6392813,3.5585 3.0456323,3.261675 c 0.03596,-0.102349 0.05665,-0.211965 0.05665,-0.326507 0,-0.07488 -0.0091,-0.147673 -0.02512,-0.217877 z m -2.57277,0.536132 c 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.407549 -0.331434,0.738983 -0.738983,0.738983 -0.407549,0 -0.738983,-0.331434 -0.738983,-0.738983 z m 1.344334,0.775809 c 0.08252,-0.06454 0.15494,-0.141392 0.213442,-0.228592 l 0.568648,0.284262 -0.390553,0.603133 z"
     id="path15"
     inkscape:connector-curvature="0"
     style="fill:#ffffff" />
</svg>
';

/**
 * Icon svg to be displayed at the left edge of each extension block, encoded as a data URI.
 * @type {string}
 */
// eslint-disable-next-line max-len
const blockIconURI = 'data:image/svg+xml;base64,<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<svg
   xmlns:dc="http://purl.org/dc/elements/1.1/"
   xmlns:cc="http://creativecommons.org/ns#"
   xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
   xmlns:svg="http://www.w3.org/2000/svg"
   xmlns="http://www.w3.org/2000/svg"
   xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
   id="Layer_1_1_"
   enable-background="new 0 0 64 64"
   height="59.118649"
   viewBox="0 0 7.3898301 7.3898311"
   width="59.118641"
   version="1.1"
   inkscape:version="0.48.4 r9939"
   sodipodi:docname="teachable-machine-blocks-small.svg">
  <metadata
     id="metadata21">
    <rdf:RDF>
      <cc:Work
         rdf:about="">
        <dc:format>image/svg+xml</dc:format>
        <dc:type
           rdf:resource="http://purl.org/dc/dcmitype/StillImage" />
      </cc:Work>
    </rdf:RDF>
  </metadata>
  <defs
     id="defs19" />
  <sodipodi:namedview
     pagecolor="#ffffff"
     bordercolor="#666666"
     borderopacity="1"
     objecttolerance="10"
     gridtolerance="10"
     guidetolerance="10"
     inkscape:pageopacity="0"
     inkscape:pageshadow="2"
     inkscape:window-width="1855"
     inkscape:window-height="1056"
     id="namedview17"
     showgrid="false"
     fit-margin-top="0"
     fit-margin-left="0"
     fit-margin-right="0"
     fit-margin-bottom="0"
     inkscape:zoom="10.429825"
     inkscape:cx="17.162407"
     inkscape:cy="38.956391"
     inkscape:window-x="65"
     inkscape:window-y="24"
     inkscape:window-maximized="1"
     inkscape:current-layer="Layer_1_1_" />
  <path
     d="m 1.847458,5.172881 c 0,0.139175 -0.03202,0.269729 -0.09114,0.385503 -0.140407,0.283277 -0.433537,0.476644 -0.771006,0.476644 -0.476644,0 -0.862147,-0.385503 -0.862147,-0.862147 0,-0.476644 0.385503,-0.862147 0.862147,-0.862147 0.173661,0 0.333774,0.0505 0.468023,0.137943 0.237706,0.153955 0.394124,0.419989 0.394124,0.724204 z"
     id="path3"
     inkscape:connector-curvature="0"
     style="fill:#f6db40;fill-opacity:1" />
  <path
     d="m 6.3685654,2.8926923 c 0.476644,0 0.862147,0.385503 0.862147,0.862147 0,0.476644 -0.385503,0.862147 -0.862147,0.862147 -0.231548,0 -0.440926,-0.08991 -0.594881,-0.24017 -0.16504,-0.155186 -0.267266,-0.376881 -0.267266,-0.621977 0,-0.03941 0.0025,-0.07759 0.0086,-0.115774 0.02463,-0.192136 0.113311,-0.363334 0.243864,-0.493887 0.156418,-0.156418 0.370723,-0.252486 0.609661,-0.252486 z"
     id="path7"
     inkscape:connector-curvature="0"
     style="fill:#f6db40" />
  <path
     style="fill:#f6db40;fill-opacity:1;stroke:none"
     d="M 0.55255309,2.676894 C 0.1313248,2.3981773 0.06897432,1.7816657 0.42404531,1.4062287 0.77059381,1.0398031 1.3635132,1.0987986 1.6478265,1.5279949 2.1132615,2.2306107 1.248691,3.1375113 0.55255309,2.676894 z"
     id="path2988"
     inkscape:connector-curvature="0" />
  <path
     style="fill:#f6db40;fill-opacity:1;stroke:none"
     d="M 3.1732391,1.6131212 C 2.8811053,1.3637245 2.8025906,1.0365761 2.9493459,0.68022276 3.1747531,0.1328859 3.846746,-0.03795311 4.256986,0.34778461 5.0661621,1.1086317 4.0170712,2.3335055 3.1732391,1.6131212 z"
     id="path2990"
     inkscape:connector-curvature="0" />
  <path
     style="fill:#f6db40;fill-opacity:1;stroke:none"
     d="M 3.2468319,4.0111541 C 2.6961712,3.6764084 2.7611803,2.8858803 3.3621529,2.6088224 3.7344227,2.4371999 4.1577169,2.5657354 4.3784522,2.9174268 4.5985209,3.2680563 4.5773113,3.5599022 4.3108956,3.8470138 4.0139835,4.1669907 3.606569,4.2298376 3.2468319,4.0111541 z"
     id="path2992"
     inkscape:connector-curvature="0" />
  <path
     style="fill:#f6db40;fill-opacity:1;stroke:none"
     d="M 3.1929615,7.0175281 C 2.9050195,6.7734284 2.8276312,6.4532282 2.9722809,6.1044434 3.1944537,5.5687312 3.8568042,5.4015206 4.2611577,5.7790658 5.0587232,6.5237535 4.0246854,7.7226127 3.1929615,7.0175281 z"
     id="path2994"
     inkscape:connector-curvature="0" />
  <path
     style="fill:#f6db40;fill-opacity:1;stroke:none"
     d=""
     id="path3001"
     inkscape:connector-curvature="0"
     transform="scale(0.125,0.125)" />
  <path
     d="M 1.411951,4.286101 C 1.282629,4.223661 1.138281,4.187571 0.985311,4.187571 0.442036,4.187571 0,4.629606 0,5.172882 c 0,0.543276 0.442036,0.985311 0.985311,0.985311 0.340918,0 0.641807,-0.174154 0.818793,-0.438094 l 0.93075,0.465929 c -0.01601,0.07033 -0.02525,0.143362 -0.02525,0.218492 0,0.543276 0.442035,0.985311 0.985311,0.985311 0.543275,0 0.98531,-0.442035 0.98531,-0.985311 0,-0.204205 -0.06244,-0.394001 -0.16935,-0.551527 L 5.818752,4.485504 c 0.164054,0.121686 0.366289,0.194722 0.585767,0.194722 0.543276,0 0.985311,-0.442035 0.985311,-0.98531 0,-0.543276 -0.442035,-0.985311 -0.985311,-0.985311 -0.22736,0 -0.436246,0.07809 -0.603256,0.207901 L 4.472325,1.588568 C 4.60214,1.421558 4.680225,1.212672 4.680225,0.985311 4.680225,0.442036 4.23819,0 3.694915,0 3.151639,0 2.709604,0.442036 2.709604,0.985311 c 0,0.07488 0.0091,0.147674 0.02512,0.217877 L 1.861246,1.521443 C 1.697568,1.203557 1.36675,0.98531 0.985311,0.98531 0.442036,0.98531 0,1.427345 0,1.970621 c 0,0.543276 0.442036,0.985311 0.985311,0.985311 0.140161,0 0.273301,-0.02981 0.394125,-0.08289 l 0.453366,0.763 z m -0.42664,1.625763 c -0.407549,0 -0.738983,-0.331434 -0.738983,-0.738983 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.407549 -0.331434,0.738983 -0.738983,0.738983 z M 1.913843,5.499388 C 1.949933,5.397039 1.970623,5.287423 1.970623,5.172881 1.970623,4.87076 1.833665,4.600292 1.61899,4.419488 L 1.973209,3.872394 3.041163,5.669477 C 2.951253,5.749537 2.876,5.845355 2.820207,5.953124 z M 3.694916,1.970621 c 0.22736,0 0.436246,-0.07809 0.603256,-0.207901 L 5.627233,3.091781 C 5.547543,3.194254 5.487935,3.312614 5.453572,3.441444 L 4.679857,3.33503 c -1.23e-4,-0.0032 3.69e-4,-0.0064 3.69e-4,-0.0096 0,-0.543275 -0.442035,-0.985311 -0.98531,-0.985311 -0.340918,0 -0.64193,0.174154 -0.818793,0.438094 L 2.729188,2.704803 3.268399,1.872092 c 0.129199,0.06244 0.273547,0.09853 0.426517,0.09853 z M 3.81808,5.427707 V 4.302112 C 4.218362,4.251862 4.544007,3.960949 4.645987,3.578894 l 0.773715,0.106414 c 0,0.0032 -4.92e-4,0.0064 -4.92e-4,0.0096 0,0.235243 0.08301,0.451149 0.221079,0.620746 L 4.347068,5.667869 C 4.202104,5.539409 4.019699,5.453072 3.81808,5.4277 z M 3.694916,2.58644 c 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.407549 -0.331434,0.738983 -0.738983,0.738983 -0.407549,0 -0.738983,-0.331434 -0.738983,-0.738983 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 z M 2.766384,2.998916 c -0.03609,0.102349 -0.05678,0.211965 -0.05678,0.326507 0,0.501523 0.376881,0.915847 0.862147,0.976813 V 5.42783 C 3.454992,5.44249 3.34476,5.47747 3.244381,5.529317 L 2.122605,3.641585 2.594446,2.912948 z m 0.928532,4.144586 c -0.407549,0 -0.738983,-0.331434 -0.738983,-0.738983 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.407549 -0.331434,0.738983 -0.738983,0.738983 z M 6.40452,2.955932 c 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.407549 -0.331434,0.738983 -0.738983,0.738983 -0.407549,0 -0.738983,-0.331434 -0.738983,-0.738983 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 z M 3.694916,0.246327 c 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.407549 -0.331434,0.738983 -0.738983,0.738983 -0.407549,0 -0.738983,-0.331434 -0.738983,-0.738983 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 z M 2.819098,1.434489 c 0.06023,0.116882 0.142623,0.220217 0.242263,0.304214 L 2.507616,2.593953 1.913967,2.297128 c 0.03596,-0.102349 0.05665,-0.211965 0.05665,-0.326507 0,-0.07488 -0.0091,-0.147673 -0.02512,-0.217877 z m -2.57277,0.536132 c 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.407549 -0.331434,0.738983 -0.738983,0.738983 -0.407549,0 -0.738983,-0.331434 -0.738983,-0.738983 z M 1.590662,2.74643 C 1.673182,2.68189 1.745602,2.605038 1.804104,2.517838 L 2.372752,2.8021 1.982199,3.405233 z"
     id="path15"
     inkscape:connector-curvature="0"
     style="fill:#ffffff" />
</svg>
';


/**
 * Sensor attribute video sensor block should report.
 * @readonly
 * @enum {string}
 */
const SensingAttribute = {
    /** The amount of motion. */
    MOTION: 'motion',

    /** The direction of the motion. */
    DIRECTION: 'direction'
};

/**
 * Subject video sensor block should report for.
 * @readonly
 * @enum {string}
 */
const SensingSubject = {
    /** The sensor traits of the whole stage. */
    STAGE: 'Stage',

    /** The senosr traits of the area overlapped by this sprite. */
    SPRITE: 'this sprite'
};

/**
 * States the video sensing activity can be set to.
 * @readonly
 * @enum {string}
 */
const VideoState = {
    /** Video turned off. */
    OFF: 'off',

    /** Video turned on with default y axis mirroring. */
    ON: 'on',

    /** Video turned on without default y axis mirroring. */
    ON_FLIPPED: 'on-flipped'
};

const ModelType = {
    POSE: 'pose',
    IMAGE: 'image',
    AUDIO: 'audio',
}

const EXTENSION_ID = 'teachableMachine';

/**
 * Class for the motion-related blocks in Scratch 3.0
 * @param {Runtime} runtime - the runtime instantiating this block package.
 * @constructor
 */
class Scratch3VideoSensingBlocks {
    constructor (runtime) {
        /**
         * The runtime instantiating this block package.
         * @type {Runtime}
         */
        this.runtime = runtime;
        this.runtime.registerPeripheralExtension(EXTENSION_ID, this);
        this.runtime.connectPeripheral(EXTENSION_ID, 0);
        this.runtime.emit(this.runtime.constructor.PERIPHERAL_CONNECTED);

        /**
         * The motion detection algoritm used to power the motion amount and
         * direction values.
         * @type {VideoMotion}
         */
        this.detect = new VideoMotion();

        /**
         * The last millisecond epoch timestamp that the video stream was
         * analyzed.
         * @type {number}
         */
        this._lastUpdate = null;

        this.lastFrameEstimate = null;

        /**
         * A flag to determine if this extension has been installed in a project.
         * It is set to false the first time getInfo is run.
         * @type {boolean}
         */
        this.firstInstall = true;
        
        // What is the confidence of the latest prediction
        this.maxConfidence = '';
        this.modelConfidences = {};

        if (this.runtime.ioDevices) {
            // Configure the video device with values from globally stored locations.
            this.runtime.on(Runtime.PROJECT_LOADED, this.updateVideoDisplay.bind(this));
            // Kick off looping the analysis logic.
            this._loop();
        }
    }

    /**
     * After analyzing a frame the amount of milliseconds until another frame
     * is analyzed.
     * @type {number}
     */
    static get INTERVAL () {
        return 33;
    }

    /**
     * Dimensions the video stream is analyzed at after its rendered to the
     * sample canvas.
     * @type {Array.<number>}
     */
    static get DIMENSIONS () {
        return [480, 360];
    }

    /**
     * The key to load & store a target's motion-related state.
     * @type {string}
     */
    static get STATE_KEY () {
        return 'Scratch.videoSensing';
    }

    /**
     * The default motion-related state, to be used when a target has no existing motion state.
     * @type {MotionState}
     */
    static get DEFAULT_MOTION_STATE () {
        return {
            motionFrameNumber: 0,
            motionAmount: 0,
            motionDirection: 0
        };
    }

    /**
     * The transparency setting of the video preview stored in a value
     * accessible by any object connected to the virtual machine.
     * @type {number}
     */
    get globalVideoTransparency () {
        const stage = this.runtime.getTargetForStage();
        if (stage) {
            return stage.videoTransparency;
        }
        return 50;
    }

    set globalVideoTransparency (transparency) {
        const stage = this.runtime.getTargetForStage();
        if (stage) {
            stage.videoTransparency = transparency;
        }
        return transparency;
    }

    /**
     * The video state of the video preview stored in a value accessible by any
     * object connected to the virtual machine.
     * @type {number}
     */
    get globalVideoState () {
        const stage = this.runtime.getTargetForStage();
        if (stage) {
            return stage.videoState;
        }
        // Though the default value for the stage is normally 'on', we need to default
        // to 'off' here to prevent the video device from briefly activating
        // while waiting for stage targets to be installed that say it should be off
        return VideoState.OFF;
    }

    set globalVideoState (state) {
        const stage = this.runtime.getTargetForStage();
        if (stage) {
            stage.videoState = state;
        }
        return state;
    }

    /**
     * Get the latest values for video transparency and state,
     * and set the video device to use them.
     */
    updateVideoDisplay () {
        this.setVideoTransparency({
            TRANSPARENCY: this.globalVideoTransparency
        });
        this.videoToggle({
            VIDEO_STATE: this.globalVideoState
        });
    }

    async estimateFrameTime () {
        const time = Date.now();
        const estimateInterval = 100;
        const offset = time - this.lastFrameEstimate;
        if (offset > estimateInterval) {
            this.lastFrameEstimate = time;
            let startTime = Date.now();
            setTimeout(() => {
                let endTime = Date.now();
                const delta = endTime - startTime;
                if (delta > 4000) {
                    console.error(`Slow loop: ${delta / 1000}s`);
                }
            });
        }
    }   

    /**
     * Occasionally step a loop to sample the video, stamp it to the preview
     * skin, and add a TypedArray copy of the canvas's pixel data.
     * @private
     */
    _loop () {
        setTimeout(this._loop.bind(this), Math.max(this.runtime.currentStepTime, Scratch3VideoSensingBlocks.INTERVAL));
        
        this.estimateFrameTime();

        // Add frame to detector
        const time = Date.now();
        if (this._lastUpdate === null) {
            this._lastUpdate = time;
        }
        if (!this._isPredicting) {
            this._isPredicting = 0;
        }
        const offset = time - this._lastUpdate;

        // TOOD: Self-throttle interval if slow to run predictions
        if (offset > Scratch3VideoSensingBlocks.INTERVAL && this._isPredicting === 0) {
            const frame = this.runtime.ioDevices.video.getFrame({
                format: Video.FORMAT_IMAGE_DATA,
                dimensions: Scratch3VideoSensingBlocks.DIMENSIONS
            });

            if (frame) {
                this._lastUpdate = time;
                this._isPredicting = 0;
                this.predictAllBlocks(frame);
            }
        }
    }

    scan() {
    }

    reset () {
    }

    isConnected() {
        return this.predictionState &&
            this.teachableImageModel &&
            this.predictionState.hasOwnProperty(this.teachableImageModel);
    }

    connect() {
    }


    async predictAllBlocks(frame) {
        for (let modelUrl in this.predictionState) {
            if (!this.predictionState[modelUrl].model) {
                continue;
            }
            if (this.teachableImageModel !== modelUrl) {
                continue;
            }
            ++this._isPredicting;
            const prediction = await this.predictModel(modelUrl, frame);
            this.predictionState[modelUrl].topClass = prediction;
            this.runtime.emit(this.runtime.constructor.PERIPHERAL_CONNECTED);
            --this._isPredicting;
        }
    }

    /**
     * Create data for a menu in scratch-blocks format, consisting of an array
     * of objects with text and value properties. The text is a translated
     * string, and the value is one-indexed.
     * @param {object[]} info - An array of info objects each having a name
     *   property.
     * @return {array} - An array of objects with text and value properties.
     * @private
     */
    _buildMenu (info) {
        return info.map((entry, index) => {
            const obj = {};
            obj.text = entry.name;
            obj.value = entry.value || String(index + 1);
            return obj;
        });
    }

    /**
     * @param {Target} target - collect motion state for this target.
     * @returns {MotionState} the mutable motion state associated with that
     *   target. This will be created if necessary.
     * @private
     */
    _getMotionState (target) {
        let motionState = target.getCustomState(Scratch3VideoSensingBlocks.STATE_KEY);
        if (!motionState) {
            motionState = Clone.simple(Scratch3VideoSensingBlocks.DEFAULT_MOTION_STATE);
            target.setCustomState(Scratch3VideoSensingBlocks.STATE_KEY, motionState);
        }
        return motionState;
    }

    static get SensingAttribute () {
        return SensingAttribute;
    }

    /**
     * An array of choices of whether a reporter should return the frame's
     * motion amount or direction.
     * @type {object[]}
     * @param {string} name - the translatable name to display in sensor
     *   attribute menu
     * @param {string} value - the serializable value of the attribute
     */
    get ATTRIBUTE_INFO () {
        return [
            {
                name: formatMessage({
                    id: 'videoSensing.motion',
                    default: 'motion',
                    description: 'Attribute for the "video [ATTRIBUTE] on [SUBJECT]" block'
                }),
                value: SensingAttribute.MOTION
            },
            {
                name: formatMessage({
                    id: 'videoSensing.direction',
                    default: 'direction',
                    description: 'Attribute for the "video [ATTRIBUTE] on [SUBJECT]" block'
                }),
                value: SensingAttribute.DIRECTION
            }
        ];
    }

    static get SensingSubject () {
        return SensingSubject;
    }

    /**
     * An array of info about the subject choices.
     * @type {object[]}
     * @param {string} name - the translatable name to display in the subject menu
     * @param {string} value - the serializable value of the subject
     */
    get SUBJECT_INFO () {
        return [
            {
                name: formatMessage({
                    id: 'videoSensing.sprite',
                    default: 'sprite',
                    description: 'Subject for the "video [ATTRIBUTE] on [SUBJECT]" block'
                }),
                value: SensingSubject.SPRITE
            },
            {
                name: formatMessage({
                    id: 'videoSensing.stage',
                    default: 'stage',
                    description: 'Subject for the "video [ATTRIBUTE] on [SUBJECT]" block'
                }),
                value: SensingSubject.STAGE
            }
        ];
    }

    /**
     * States the video sensing activity can be set to.
     * @readonly
     * @enum {string}
     */
    static get VideoState () {
        return VideoState;
    }

    /**
     * An array of info on video state options for the "turn video [STATE]" block.
     * @type {object[]}
     * @param {string} name - the translatable name to display in the video state menu
     * @param {string} value - the serializable value stored in the block
     */
    get VIDEO_STATE_INFO () {
        return [
            {
                name: formatMessage({
                    id: 'videoSensing.off',
                    default: 'off',
                    description: 'Option for the "turn video [STATE]" block'
                }),
                value: VideoState.OFF
            },
            {
                name: formatMessage({
                    id: 'videoSensing.on',
                    default: 'on',
                    description: 'Option for the "turn video [STATE]" block'
                }),
                value: VideoState.ON
            },
            {
                name: formatMessage({
                    id: 'videoSensing.onFlipped',
                    default: 'on flipped',
                    description: 'Option for the "turn video [STATE]" block that causes the video to be flipped' +
                        ' horizontally (reversed as in a mirror)'
                }),
                value: VideoState.ON_FLIPPED
            }
        ];
    }

    /**
     * @returns {object} metadata for this extension and its blocks.
     */
    getInfo () {
        // Set the video display properties to defaults the first time
        // getInfo is run. This turns on the video device when it is
        // first added to a project, and is overwritten by a PROJECT_LOADED
        // event listener that later calls updateVideoDisplay
        if (this.firstInstall) {
            this.globalVideoState = VideoState.OFF;
            this.globalVideoTransparency = 50;
            this.updateVideoDisplay();
            this.updateToStageModel();
            this.firstInstall = false;
            this.predictionState = {};
        }

        // Return extension definition
        const blocks = [
            {
                opcode: 'useModelBlock',
                text: `use model [MODEL_URL]`,
                arguments: {
                    MODEL_URL: {
                        type: ArgumentType.STRING,
                        defaultValue: this.teachableImageModel || 'https://teachablemachine.withgoogle.com/models/knrpLxv8N/'
                    }
                }
            },
            {
                // @todo (copied from motion) this hat needs to be set itself to restart existing
                // threads like Scratch 2's behaviour.
                opcode: 'whenModelMatches',
                text: 'when model detects [CLASS_NAME]',
                blockType: BlockType.HAT,
                arguments: {
                    CLASS_NAME: {
                        type: ArgumentType.STRING,
                        defaultValue: this.getCurrentClasses()[0],
                        menu: 'CLASS_NAME'
                    }
                },
            },
            {
                opcode: 'modelPrediction',
                text: formatMessage({
                    id: 'teachableMachine.modelPrediction',
                    default: 'model prediction',
                    description: 'Value of latest model prediction'
                }),
                blockType: BlockType.REPORTER,
                isTerminal: true
            },
            {
                // @todo (copied from motion) this hat needs to be set itself to restart existing
                // threads like Scratch 2's behaviour.
                opcode: 'modelMatches',
                text: formatMessage({
                    id: 'teachableMachine.modelMatches',
                    default: 'prediction is [CLASS_NAME]',
                    description: 'Boolean that is true when the model matches [CLASS_NAME]'
                }),
                blockType: BlockType.BOOLEAN,
                arguments: {
                    CLASS_NAME: {
                        type: ArgumentType.STRING,
                        defaultValue: this.getCurrentClasses()[0],
                        menu: 'CLASS_NAME'
                    }
                },
            },
            /*{
                opcode: 'modelCon',
                text: formatMessage({
                    id: 'teachableMachine.modelConfidence',
                    default: 'prediction confidence',
                    description: 'Confidence value of latest model prediction'
                }),
                blockType: BlockType.REPORTER,
                isTerminal: true
            },*/
            {
                opcode: 'classConfidence',
                text: formatMessage({
                    id: 'teachableMachine.classConfidence',
                    default: 'confidence for [CLASS_NAME]',
                    description: 'Reporter that returns the model confience level for [CLASS_NAME]'
                }),
                blockType: BlockType.REPORTER,
                isTerminal: true,
                arguments: {
                    CLASS_NAME: {
                        type: ArgumentType.STRING,
                        defaultValue: this.getCurrentClasses()[0],
                        menu: 'CLASS_NAME'
                    }
                },
            },
            '---',
            {
                opcode: 'videoToggle',
                text: formatMessage({
                    id: 'videoSensing.videoToggle',
                    default: 'turn video [VIDEO_STATE]',
                    description: 'Controls display of the video preview layer'
                }),
                arguments: {
                    VIDEO_STATE: {
                        type: ArgumentType.NUMBER,
                        menu: 'VIDEO_STATE',
                        defaultValue: VideoState.ON
                    }
                }
            },
            {
                opcode: 'setVideoTransparency',
                text: formatMessage({
                    id: 'videoSensing.setVideoTransparency',
                    default: 'set video transparency to [TRANSPARENCY]',
                    description: 'Controls transparency of the video preview layer'
                }),
                arguments: {
                    TRANSPARENCY: {
                        type: ArgumentType.NUMBER,
                        defaultValue: 50
                    }
                }
            }
        ];

        return {
            id: EXTENSION_ID,
            name: formatMessage({
                id: 'videoSensing.categoryName',
                default: 'Teachable Machine',
                description: 'Label for the Teachable Machine extension category'
            }),
            showStatusButton: true,
            blockIconURI: blockIconURI,
            menuIconURI: menuIconURI,
            blocks: blocks,
            menus: {
                CLASS_NAME: 'getCurrentClasses',
                ATTRIBUTE: {
                    acceptReporters: true,
                    items: this._buildMenu(this.ATTRIBUTE_INFO)
                },
                SUBJECT: {
                    acceptReporters: true,
                    items: this._buildMenu(this.SUBJECT_INFO)
                },
                VIDEO_STATE: {
                    acceptReporters: true,
                    items: this._buildMenu(this.VIDEO_STATE_INFO)
                }
            }
        };
    }

    updateToStageModel() {
        const stage = this.runtime.getTargetForStage();
        if (stage) {
            this.teachableImageModel = stage.teachableImageModel;
            if (this.teachableImageModel) {
                this.useModel(this.teachableImageModel);
            }
        }
    }

    updateStageModel(modelUrl) {
        const stage = this.runtime.getTargetForStage();
        this.teachableImageModel = modelUrl;
        if (stage) {
            stage.teachableImageModel = modelUrl;
        }
    }

    useModelBlock(args, util) {
        const modelArg = args.MODEL_URL;
        this.useModel(modelArg);
    }

    useModel(modelArg) {
        try {
            const modelUrl = this.modelArgumentToURL(modelArg);
            this.getPredictionStateOrStartPredicting(modelUrl);
            this.updateStageModel(modelUrl);
        } catch (e) {
            this.teachableImageModel = null;
        }
    }

    modelArgumentToURL(modelArg) {
        return modelArg.startsWith('https://teachablemachine.withgoogle.com/models/') ?
            modelArg :
            `https://teachablemachine.withgoogle.com/models/${modelArg}/`;
    }

    /**
     * A scratch hat block edge handle that downloads a teachable machine model and determines whether the
     * current video frame matches the model class.
     * @param {object} args - the block arguments
     * @param {BlockUtility} util - the block utility
     * @returns {boolean} true if the model matches
     *   reference
     */
    whenModelMatches(args, util) {
        const modelUrl = this.teachableImageModel;
        const className = args.CLASS_NAME;

        const predictionState = this.getPredictionStateOrStartPredicting(modelUrl);
        if (!predictionState) {
            return false;
        }

        const currentMaxClass = predictionState.topClass;
        return (currentMaxClass === String(className));
    }

    modelMatches(args, util) {
        const modelUrl = this.teachableImageModel;
        const className = args.CLASS_NAME;

        const predictionState = this.getPredictionStateOrStartPredicting(modelUrl);
        if (!predictionState) {
            return false;
        }

        const currentMaxClass = predictionState.topClass;
        return (currentMaxClass === String(className));
    }
    
    classConfidence(args, util) {
        const className = args.CLASS_NAME;
        
        return this.modelConfidences[className];
    }
    
    
    modelCon(args, util) {
        return this.maxConfidence;
    }

    /**
     * A scratch reporter that returns the top class seen in the current video frame
     * @param {object} args - the block arguments
     * @param {BlockUtility} util - the block utility
     * @returns {string} class name if video frame matched, empty string if model not loaded yet
     */
    modelPrediction(args, util) {
        const modelUrl = this.teachableImageModel;
        const predictionState = this.getPredictionStateOrStartPredicting(modelUrl);
        if (!predictionState) {
            return '';
        }
        return predictionState.topClass;
    }
    

    getPredictionStateOrStartPredicting(modelUrl) {
        const hasPredictionState = this.predictionState.hasOwnProperty(modelUrl);
        if (!hasPredictionState) {
            this.startPredicting(modelUrl);
            return null;
        }
        return this.predictionState[modelUrl];
    }

    getCurrentClasses() {
        if (
            !this.teachableImageModel ||
            !this.predictionState ||
            !this.predictionState[this.teachableImageModel] ||
            !this.predictionState[this.teachableImageModel].hasOwnProperty('model')
        ) {
            return ["Class 1"];
        }

        if (this.predictionState[this.teachableImageModel].modelType === ModelType.AUDIO) {
            return this.predictionState[this.teachableImageModel].model.wordLabels();
        }

        return this.predictionState[this.teachableImageModel].model.getClassLabels();
    }

    async startPredicting(modelDataUrl) {
        if (!this.predictionState[modelDataUrl]) {
            try {
                this.predictionState[modelDataUrl] = {};
                // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/image
                const {model, type} = await this.initModel(modelDataUrl);
                this.predictionState[modelDataUrl].modelType = type;
                this.predictionState[modelDataUrl].model = model;
                this.runtime.requestToolboxExtensionsUpdate();
            } catch (e) {
                this.predictionState[modelDataUrl] = {};
                console.log("Model initialization failure!", e);
            }
        }
    }

    async initModel(modelUrl) {
        const modelURL = modelUrl + "model.json";
        const metadataURL = modelUrl + "metadata.json";
        const customMobileNet = await tmImage.load(modelURL, metadataURL);
        if (customMobileNet._metadata.hasOwnProperty('tfjsSpeechCommandsVersion')) {
            // customMobileNet.dispose(); // too early to dispose
            //console.log("We got a speech net yay")
            const recognizer = tmAudioSpeechCommands.create("BROWSER_FFT", undefined, modelURL, metadataURL);
            await recognizer.ensureModelLoaded();
            await recognizer.listen(result => {
                this.latestAudioResults = result;
                //console.log(result);
            }, {
                includeSpectrogram: true, // in case listen should return result.spectrogram
                probabilityThreshold: 0.75,
                invokeCallbackOnNoiseAndUnknown: true,
                overlapFactor: 0.50 // probably want between 0.5 and 0.75. More info in README
            });
            return {model: recognizer, type: ModelType.AUDIO};
        } else if (customMobileNet._metadata.packageName === "@teachablemachine/pose") {
            const customPoseNet = await tmPose.load(modelURL, metadataURL);
            return {model: customPoseNet, type: ModelType.POSE};
        } else {
           return {model: customMobileNet, type: ModelType.IMAGE};
        }
    }

    async predictModel(modelUrl, frame) {
        const predictions = await this.getPredictionFromModel(modelUrl, frame);
        if (!predictions) {
            return;
        }
        let maxProbability = 0;
        let maxClassName = "";
        for (let i = 0; i < predictions.length; i++) {
            const probability = predictions[i].probability.toFixed(2);
            const className = predictions[i].className;
            this.modelConfidences[className] = probability; // update for reporter block
            if (probability > maxProbability) {
                maxClassName = className;
                maxProbability = probability;
            }
        }
        this.maxConfidence = maxProbability; // update for reporter block
        return maxClassName;
    }

    async getPredictionFromModel(modelUrl, frame) {
        const {model, modelType} = this.predictionState[modelUrl];
        switch (modelType) {
            case ModelType.IMAGE:
                const imageBitmap = await createImageBitmap(frame);
                return await model.predict(imageBitmap);
            case ModelType.POSE:
                const {pose, posenetOutput} = await model.estimatePose(frame);
                return await model.predict(posenetOutput);
            case ModelType.AUDIO:
                if (this.latestAudioResults) {
                    return model.wordLabels().map((label, i) => {
                        return {className: label, probability: this.latestAudioResults.scores[i]}
                    });
                } else {
                    return null;
                }
        }
    }

    /**
     * A scratch command block handle that configures the video state from
     * passed arguments.
     * @param {object} args - the block arguments
     * @param {VideoState} args.VIDEO_STATE - the video state to set the device to
     */
    videoToggle (args) {
        const state = args.VIDEO_STATE;
        this.globalVideoState = state;
        if (state === VideoState.OFF) {
            this.runtime.ioDevices.video.disableVideo();
        } else {
            this.runtime.ioDevices.video.enableVideo();
            // Mirror if state is ON. Do not mirror if state is ON_FLIPPED.
            this.runtime.ioDevices.video.mirror = state === VideoState.ON;
        }
    }

    /**
     * A scratch command block handle that configures the video preview's
     * transparency from passed arguments.
     * @param {object} args - the block arguments
     * @param {number} args.TRANSPARENCY - the transparency to set the video
     *   preview to
     */
    setVideoTransparency (args) {
        const transparency = Cast.toNumber(args.TRANSPARENCY);
        this.globalVideoTransparency = transparency;
        this.runtime.ioDevices.video.setPreviewGhost(transparency);
    }
}

module.exports = Scratch3VideoSensingBlocks;
