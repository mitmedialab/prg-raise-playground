require("regenerator-runtime/runtime");
const Runtime = require('../../engine/runtime');

const ArgumentType = require('../../extension-support/argument-type');
const BlockType = require('../../extension-support/block-type');
const Clone = require('../../util/clone');
const Cast = require('../../util/cast');
const formatMessage = require('format-message');
const Video = require('../../io/video');

const VideoMotion = require('./library');

const tmImage = require('@teachablemachine/image');
const tmPose = require('@teachablemachine/pose');
const tmAudioSpeechCommands = require('@tensorflow-models/speech-commands');

/**
 * Icon svg to be displayed in the blocks category menu, encoded as a data URI.
 * @type {string}
 */
// eslint-disable-next-line max-len
const menuIconURI = "data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8"?>
<!-- Generator: Adobe Illustrator 24.0.1, SVG Export Plug-In . SVG Version: 6.00 Build 0)  -->
<svg version="1.1"
	 id="svg117" xmlns:cc="http://creativecommons.org/ns#" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd" xmlns:svg="http://www.w3.org/2000/svg"
	 xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 40 40"
	 style="enable-background:new 0 0 40 40;" xml:space="preserve">
<style type="text/css">
	.st0{opacity:0.25;fill:#0EBD8C;enable-background:new    ;}
	.st1{opacity:0.5;fill:#0EBD8C;enable-background:new    ;}
	.st2{opacity:0.75;fill:#0EBD8C;enable-background:new    ;}
	.st3{fill:#0EBD8C;}
	.st4{fill:#4692FF;}
	.st5{fill:#0B64E5;}
	.st6{fill:#FDA22E;}
	.st7{fill:#E50023;}
	.st8{fill:#171526;}
</style>
<circle id="Oval-Copy" class="st0" cx="77.9" cy="2.6" r="4.5"/>
<circle id="Oval-Copy_1_" class="st1" cx="71.7" cy="1" r="4.5"/>
<circle id="Oval-Copy_2_" class="st2" cx="66.2" cy="1" r="4.5"/>
<circle id="Oval" class="st3" cx="60.2" cy="3.4" r="4.5"/>
<sodipodi:namedview  bordercolor="#666666" borderopacity="1" gridtolerance="10" guidetolerance="10" id="namedview119" inkscape:current-layer="Extensions/Software/Video-Sensing-Block" inkscape:cx="14.467069" inkscape:cy="6.5903056" inkscape:document-rotation="0" inkscape:pageopacity="0" inkscape:pageshadow="2" inkscape:snap-smooth-nodes="false" inkscape:window-height="907" inkscape:window-maximized="0" inkscape:window-width="1600" inkscape:window-x="571" inkscape:window-y="96" inkscape:zoom="7.04" objecttolerance="10" pagecolor="#ffffff" showgrid="false">
	</sodipodi:namedview>
<title  id="title104">Extensions/Software/Video-Sensing-Block</title>
<desc  id="desc106">Created with Sketch.</desc>
<g>
	<g>
		<path class="st4" d="M47.3,21.6c-0.9-3.7-2.8-4.9-2.9-6c-0.1-0.6,1-1.4,2.4-0.9c1.4,0.5,1.9,1.4,3.1,2.9c1.3,1.5,2.1,2.9,2.8,2.4
			c0,0,1.5-1.8,1.8-2.3c0.4-0.9,2.5-7.4,3.8-10.2c1.2-2.5,2.9-2.1,2.9-1.3c0.1,1.8-3.4,13-3.4,13s3.6-7.4,4.8-9.9
			c1.2-2.4,3.4-1.9,3.2-1.2c-1.1,3.2-5.1,13.4-5.1,13.4s4.4-7.7,5.2-9c1-1.6,2.9-1.7,2.9-0.7c0,0.7-5.3,11.9-5.3,11.9
			s3.4-5.5,4.4-6.8c0.9-1.2,2.9-1.5,2.5-0.3c-0.3,1-5.3,10.2-5.8,11c-0.9,1.9-2.6,3.5-4.3,5.1c-1.8,1.7-3.9,2.2-4.9,2.4
			c-0.4,0.1-0.8,0-1.1-0.3l-5.9-4.6c-0.3-0.2-0.5-0.6-0.5-0.9C47.6,28.4,48.3,25.6,47.3,21.6z"/>
	</g>
</g>
<g>
	<circle class="st5" cx="36.3" cy="20.6" r="1.2"/>
	<circle class="st5" cx="36.3" cy="26.1" r="1.2"/>
	<circle class="st5" cx="36.3" cy="31.5" r="1.2"/>
	<circle class="st5" cx="36.3" cy="37" r="1.2"/>
	<circle class="st5" cx="36.3" cy="15.2" r="1.2"/>
	<circle class="st5" cx="36.3" cy="9.8" r="1.2"/>
	<circle class="st5" cx="36.3" cy="4.3" r="1.2"/>
</g>
<circle class="st4" cx="4.9" cy="4.9" r="2.4"/>
<circle class="st4" cx="4.9" cy="12.8" r="2.4"/>
<circle class="st4" cx="4.9" cy="20.6" r="2.4"/>
<circle class="st4" cx="4.9" cy="28.5" r="2.4"/>
<circle class="st6" cx="15.2" cy="12.8" r="2.4"/>
<circle class="st6" cx="15.2" cy="20.6" r="2.4"/>
<circle class="st6" cx="15.2" cy="28.5" r="2.4"/>
<circle class="st4" cx="4.9" cy="36.4" r="2.4"/>
<path class="st7" d="M23,31.5c-0.7,0-1.2-0.5-1.2-1.2V10.4c0-0.7,0.5-1.2,1.2-1.2s1.2,0.5,1.2,1.2v19.9C24.2,31,23.7,31.5,23,31.5z"
	/>
<path class="st8" d="M26,12.2c0.2,0,0.3-0.1,0.4-0.2l7.1-7.1h1.1c0.3,0.7,0.9,1.2,1.7,1.2c1,0,1.8-0.8,1.8-1.8s-0.8-1.8-1.8-1.8
	c-0.8,0-1.5,0.5-1.7,1.2h-1.3c-0.2,0-0.3,0.1-0.4,0.2L25.8,11h-1v-0.6c0-1-0.8-1.8-1.8-1.8s-1.8,0.8-1.8,1.8v1.8h-3.1
	c-0.3-1.4-1.5-2.4-3-2.4c-0.8,0-1.4,0.3-2,0.8L7.6,6.3c0.2-0.4,0.3-0.8,0.3-1.3c0-1.7-1.4-3-3-3s-3,1.4-3,3s1.4,3,3,3
	c0.8,0,1.4-0.3,2-0.8l5.6,4.3c-0.1,0.2-0.2,0.5-0.3,0.7H7.9c-0.3-1.4-1.5-2.4-3-2.4c-1.7,0-3,1.4-3,3s1.4,3,3,3c0.8,0,1.4-0.3,2-0.8
	L9,16.7l-2.2,1.7c-0.5-0.5-1.2-0.8-2-0.8c-1.7,0-3,1.4-3,3c0,1.7,1.4,3,3,3c0.8,0,1.4-0.3,2-0.8L9,24.6l-2.2,1.7
	c-0.5-0.5-1.2-0.8-2-0.8c-1.7,0-3,1.4-3,3c0,1.7,1.4,3,3,3c1.5,0,2.7-1,3-2.4h4.4c0.1,0.3,0.1,0.5,0.3,0.7l-5.6,4.3
	c-0.5-0.5-1.2-0.7-2-0.7c-1.7,0-3,1.4-3,3c0,1.7,1.4,3,3,3s3-1.4,3-3c0-0.5-0.1-0.9-0.3-1.3l5.6-4.3c0.5,0.5,1.2,0.7,2,0.7
	c1.5,0,2.7-1,3-2.4h3.1v1.2c0,1,0.8,1.8,1.8,1.8s1.8-0.8,1.8-1.8h1l7.1,7.1c0.1,0.1,0.3,0.2,0.4,0.2h1.3c0.3,0.7,0.9,1.2,1.7,1.2
	c1,0,1.8-0.8,1.8-1.8c0-1-0.8-1.8-1.8-1.8c-0.8,0-1.5,0.5-1.7,1.2h-1.1l-7.1-7.1c-0.1-0.1-0.3-0.2-0.4-0.2h-1.2v-1.8h2.8l4.7,4.7
	c0.1,0.1,0.3,0.2,0.4,0.2h1.9c0.3,0.7,0.9,1.2,1.7,1.2c1,0,1.8-0.8,1.8-1.8c0-1-0.8-1.8-1.8-1.8c-0.8,0-1.5,0.5-1.7,1.2h-1.7
	l-4.7-4.7c-0.1-0.1-0.3-0.2-0.4-0.2h-3v-1.8H30l2.2,2.2c0.1,0.1,0.3,0.2,0.4,0.2h1.9c0.3,0.7,0.9,1.2,1.7,1.2c1,0,1.8-0.8,1.8-1.8
	s-0.8-1.8-1.8-1.8c-0.8,0-1.5,0.5-1.7,1.2h-1.7l-2.2-2.2c-0.1-0.1-0.3-0.2-0.4-0.2h-5.4v-1.8h9.8c0.3,0.7,0.9,1.2,1.7,1.2
	c1,0,1.8-0.8,1.8-1.8s-0.8-1.8-1.8-1.8c-0.8,0-1.5,0.5-1.7,1.2h-9.8v-1.8h5.4c0.2,0,0.3-0.1,0.4-0.2l2.2-2.2h1.7
	c0.3,0.7,0.9,1.2,1.7,1.2c1,0,1.8-0.8,1.8-1.8s-0.8-1.8-1.8-1.8c-0.8,0-1.5,0.5-1.7,1.2h-1.9c-0.2,0-0.3,0.1-0.4,0.2L30,17h-5.2
	v-1.8h3c0.2,0,0.3-0.1,0.4-0.2l4.7-4.7h1.7c0.3,0.7,0.9,1.2,1.7,1.2c1,0,1.8-0.8,1.8-1.8S37.3,8,36.3,8c-0.8,0-1.5,0.5-1.7,1.2h-1.9
	c-0.2,0-0.3,0.1-0.4,0.2L27.6,14h-2.8v-1.8H26z M36.3,3.7c0.3,0,0.6,0.3,0.6,0.6c0,0.3-0.3,0.6-0.6,0.6c-0.3,0-0.6-0.3-0.6-0.6
	C35.7,4,36,3.7,36.3,3.7z M36.3,36.4c0.3,0,0.6,0.3,0.6,0.6c0,0.3-0.3,0.6-0.6,0.6c-0.3,0-0.6-0.3-0.6-0.6
	C35.7,36.6,36,36.4,36.3,36.4z M36.3,30.9c0.3,0,0.6,0.3,0.6,0.6s-0.3,0.6-0.6,0.6c-0.3,0-0.6-0.3-0.6-0.6S36,30.9,36.3,30.9z
	 M36.3,25.5c0.3,0,0.6,0.3,0.6,0.6s-0.3,0.6-0.6,0.6c-0.3,0-0.6-0.3-0.6-0.6S36,25.5,36.3,25.5z M36.3,20c0.3,0,0.6,0.3,0.6,0.6
	c0,0.3-0.3,0.6-0.6,0.6c-0.3,0-0.6-0.3-0.6-0.6S36,20,36.3,20z M36.3,14.6c0.3,0,0.6,0.3,0.6,0.6c0,0.3-0.3,0.6-0.6,0.6
	c-0.3,0-0.6-0.3-0.6-0.6C35.7,14.9,36,14.6,36.3,14.6z M36.3,9.2c0.3,0,0.6,0.3,0.6,0.6s-0.3,0.6-0.6,0.6c-0.3,0-0.6-0.3-0.6-0.6
	S36,9.2,36.3,9.2z M18.1,13.4h3.1V20h-3.1c-0.3-1.4-1.5-2.4-3-2.4c-0.8,0-1.4,0.3-2,0.8L11,16.7l2.2-1.7c0.5,0.5,1.2,0.8,2,0.8
	C16.6,15.8,17.8,14.8,18.1,13.4z M13.4,20.6c0-1,0.8-1.8,1.8-1.8s1.8,0.8,1.8,1.8s-0.8,1.8-1.8,1.8S13.4,21.6,13.4,20.6z M15.2,11
	c1,0,1.8,0.8,1.8,1.8s-0.8,1.8-1.8,1.8s-1.8-0.8-1.8-1.8S14.2,11,15.2,11z M4.9,6.8c-1,0-1.8-0.8-1.8-1.8s0.8-1.8,1.8-1.8
	s1.8,0.8,1.8,1.8S5.9,6.8,4.9,6.8z M4.9,14.6c-1,0-1.8-0.8-1.8-1.8S3.9,11,4.9,11s1.8,0.8,1.8,1.8S5.9,14.6,4.9,14.6z M7.6,14.1
	c0.1-0.2,0.2-0.5,0.3-0.7h4.4c0.1,0.3,0.1,0.5,0.3,0.7L10,16L7.6,14.1z M12.5,19.3c-0.1,0.2-0.2,0.5-0.3,0.7H7.9
	c-0.1-0.3-0.1-0.5-0.3-0.7l2.4-1.9L12.5,19.3z M4.9,22.5c-1,0-1.8-0.8-1.8-1.8s0.8-1.8,1.8-1.8s1.8,0.8,1.8,1.8S5.9,22.5,4.9,22.5z
	 M7.6,22c0.1-0.2,0.2-0.5,0.3-0.7h4.4c0.1,0.3,0.1,0.5,0.3,0.7L10,23.8L7.6,22z M12.2,27.9H7.9c-0.1-0.3-0.1-0.5-0.3-0.7l2.4-1.9
	l2.4,1.9C12.3,27.4,12.3,27.6,12.2,27.9z M4.9,30.3c-1,0-1.8-0.8-1.8-1.8s0.8-1.8,1.8-1.8s1.8,0.8,1.8,1.8S5.9,30.3,4.9,30.3z
	 M4.9,38.2c-1,0-1.8-0.8-1.8-1.8c0-1,0.8-1.8,1.8-1.8s1.8,0.8,1.8,1.8C6.7,37.4,5.9,38.2,4.9,38.2z M15.2,30.3c-1,0-1.8-0.8-1.8-1.8
	s0.8-1.8,1.8-1.8s1.8,0.8,1.8,1.8S16.2,30.3,15.2,30.3z M18.1,27.9c-0.3-1.4-1.5-2.4-3-2.4c-0.8,0-1.4,0.3-2,0.8L11,24.6l2.2-1.7
	c0.5,0.5,1.2,0.8,2,0.8c1.5,0,2.7-1,3-2.4h3.1v6.6H18.1z M23.6,30.3c0,0.3-0.3,0.6-0.6,0.6c-0.3,0-0.6-0.3-0.6-0.6V10.4
	c0-0.3,0.3-0.6,0.6-0.6c0.3,0,0.6,0.3,0.6,0.6V30.3z"/>
</svg>
";

/**
 * Icon svg to be displayed at the left edge of each extension block, encoded as a data URI.
 * @type {string}
 */
// eslint-disable-next-line max-len
const blockIconURI = 'data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8"?>
<!-- Generator: Adobe Illustrator 24.0.1, SVG Export Plug-In . SVG Version: 6.00 Build 0)  -->
<svg version="1.1"
	 id="svg117" xmlns:cc="http://creativecommons.org/ns#" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd" xmlns:svg="http://www.w3.org/2000/svg"
	 xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 40 40"
	 style="enable-background:new 0 0 40 40;" xml:space="preserve">
<style type="text/css">
	.st0{opacity:0.25;fill:#0EBD8C;enable-background:new    ;}
	.st1{opacity:0.5;fill:#0EBD8C;enable-background:new    ;}
	.st2{opacity:0.75;fill:#0EBD8C;enable-background:new    ;}
	.st3{fill:#0EBD8C;}
	.st4{fill:#4692FF;}
	.st5{fill:#0B64E5;}
	.st6{fill:#FDA22E;}
	.st7{fill:#E50023;}
	.st8{fill:#171526;}
</style>
<circle id="Oval-Copy" class="st0" cx="77.9" cy="2.6" r="4.5"/>
<circle id="Oval-Copy_1_" class="st1" cx="71.7" cy="1" r="4.5"/>
<circle id="Oval-Copy_2_" class="st2" cx="66.2" cy="1" r="4.5"/>
<circle id="Oval" class="st3" cx="60.2" cy="3.4" r="4.5"/>
<sodipodi:namedview  bordercolor="#666666" borderopacity="1" gridtolerance="10" guidetolerance="10" id="namedview119" inkscape:current-layer="Extensions/Software/Video-Sensing-Block" inkscape:cx="14.467069" inkscape:cy="6.5903056" inkscape:document-rotation="0" inkscape:pageopacity="0" inkscape:pageshadow="2" inkscape:snap-smooth-nodes="false" inkscape:window-height="907" inkscape:window-maximized="0" inkscape:window-width="1600" inkscape:window-x="571" inkscape:window-y="96" inkscape:zoom="7.04" objecttolerance="10" pagecolor="#ffffff" showgrid="false">
	</sodipodi:namedview>
<title  id="title104">Extensions/Software/Video-Sensing-Block</title>
<desc  id="desc106">Created with Sketch.</desc>
<g>
	<g>
		<path class="st4" d="M47.3,21.6c-0.9-3.7-2.8-4.9-2.9-6c-0.1-0.6,1-1.4,2.4-0.9c1.4,0.5,1.9,1.4,3.1,2.9c1.3,1.5,2.1,2.9,2.8,2.4
			c0,0,1.5-1.8,1.8-2.3c0.4-0.9,2.5-7.4,3.8-10.2c1.2-2.5,2.9-2.1,2.9-1.3c0.1,1.8-3.4,13-3.4,13s3.6-7.4,4.8-9.9
			c1.2-2.4,3.4-1.9,3.2-1.2c-1.1,3.2-5.1,13.4-5.1,13.4s4.4-7.7,5.2-9c1-1.6,2.9-1.7,2.9-0.7c0,0.7-5.3,11.9-5.3,11.9
			s3.4-5.5,4.4-6.8c0.9-1.2,2.9-1.5,2.5-0.3c-0.3,1-5.3,10.2-5.8,11c-0.9,1.9-2.6,3.5-4.3,5.1c-1.8,1.7-3.9,2.2-4.9,2.4
			c-0.4,0.1-0.8,0-1.1-0.3l-5.9-4.6c-0.3-0.2-0.5-0.6-0.5-0.9C47.6,28.4,48.3,25.6,47.3,21.6z"/>
	</g>
</g>
<g>
	<circle class="st5" cx="36.3" cy="20.6" r="1.2"/>
	<circle class="st5" cx="36.3" cy="26.1" r="1.2"/>
	<circle class="st5" cx="36.3" cy="31.5" r="1.2"/>
	<circle class="st5" cx="36.3" cy="37" r="1.2"/>
	<circle class="st5" cx="36.3" cy="15.2" r="1.2"/>
	<circle class="st5" cx="36.3" cy="9.8" r="1.2"/>
	<circle class="st5" cx="36.3" cy="4.3" r="1.2"/>
</g>
<circle class="st4" cx="4.9" cy="4.9" r="2.4"/>
<circle class="st4" cx="4.9" cy="12.8" r="2.4"/>
<circle class="st4" cx="4.9" cy="20.6" r="2.4"/>
<circle class="st4" cx="4.9" cy="28.5" r="2.4"/>
<circle class="st6" cx="15.2" cy="12.8" r="2.4"/>
<circle class="st6" cx="15.2" cy="20.6" r="2.4"/>
<circle class="st6" cx="15.2" cy="28.5" r="2.4"/>
<circle class="st4" cx="4.9" cy="36.4" r="2.4"/>
<path class="st7" d="M23,31.5c-0.7,0-1.2-0.5-1.2-1.2V10.4c0-0.7,0.5-1.2,1.2-1.2s1.2,0.5,1.2,1.2v19.9C24.2,31,23.7,31.5,23,31.5z"
	/>
<path class="st8" d="M26,12.2c0.2,0,0.3-0.1,0.4-0.2l7.1-7.1h1.1c0.3,0.7,0.9,1.2,1.7,1.2c1,0,1.8-0.8,1.8-1.8s-0.8-1.8-1.8-1.8
	c-0.8,0-1.5,0.5-1.7,1.2h-1.3c-0.2,0-0.3,0.1-0.4,0.2L25.8,11h-1v-0.6c0-1-0.8-1.8-1.8-1.8s-1.8,0.8-1.8,1.8v1.8h-3.1
	c-0.3-1.4-1.5-2.4-3-2.4c-0.8,0-1.4,0.3-2,0.8L7.6,6.3c0.2-0.4,0.3-0.8,0.3-1.3c0-1.7-1.4-3-3-3s-3,1.4-3,3s1.4,3,3,3
	c0.8,0,1.4-0.3,2-0.8l5.6,4.3c-0.1,0.2-0.2,0.5-0.3,0.7H7.9c-0.3-1.4-1.5-2.4-3-2.4c-1.7,0-3,1.4-3,3s1.4,3,3,3c0.8,0,1.4-0.3,2-0.8
	L9,16.7l-2.2,1.7c-0.5-0.5-1.2-0.8-2-0.8c-1.7,0-3,1.4-3,3c0,1.7,1.4,3,3,3c0.8,0,1.4-0.3,2-0.8L9,24.6l-2.2,1.7
	c-0.5-0.5-1.2-0.8-2-0.8c-1.7,0-3,1.4-3,3c0,1.7,1.4,3,3,3c1.5,0,2.7-1,3-2.4h4.4c0.1,0.3,0.1,0.5,0.3,0.7l-5.6,4.3
	c-0.5-0.5-1.2-0.7-2-0.7c-1.7,0-3,1.4-3,3c0,1.7,1.4,3,3,3s3-1.4,3-3c0-0.5-0.1-0.9-0.3-1.3l5.6-4.3c0.5,0.5,1.2,0.7,2,0.7
	c1.5,0,2.7-1,3-2.4h3.1v1.2c0,1,0.8,1.8,1.8,1.8s1.8-0.8,1.8-1.8h1l7.1,7.1c0.1,0.1,0.3,0.2,0.4,0.2h1.3c0.3,0.7,0.9,1.2,1.7,1.2
	c1,0,1.8-0.8,1.8-1.8c0-1-0.8-1.8-1.8-1.8c-0.8,0-1.5,0.5-1.7,1.2h-1.1l-7.1-7.1c-0.1-0.1-0.3-0.2-0.4-0.2h-1.2v-1.8h2.8l4.7,4.7
	c0.1,0.1,0.3,0.2,0.4,0.2h1.9c0.3,0.7,0.9,1.2,1.7,1.2c1,0,1.8-0.8,1.8-1.8c0-1-0.8-1.8-1.8-1.8c-0.8,0-1.5,0.5-1.7,1.2h-1.7
	l-4.7-4.7c-0.1-0.1-0.3-0.2-0.4-0.2h-3v-1.8H30l2.2,2.2c0.1,0.1,0.3,0.2,0.4,0.2h1.9c0.3,0.7,0.9,1.2,1.7,1.2c1,0,1.8-0.8,1.8-1.8
	s-0.8-1.8-1.8-1.8c-0.8,0-1.5,0.5-1.7,1.2h-1.7l-2.2-2.2c-0.1-0.1-0.3-0.2-0.4-0.2h-5.4v-1.8h9.8c0.3,0.7,0.9,1.2,1.7,1.2
	c1,0,1.8-0.8,1.8-1.8s-0.8-1.8-1.8-1.8c-0.8,0-1.5,0.5-1.7,1.2h-9.8v-1.8h5.4c0.2,0,0.3-0.1,0.4-0.2l2.2-2.2h1.7
	c0.3,0.7,0.9,1.2,1.7,1.2c1,0,1.8-0.8,1.8-1.8s-0.8-1.8-1.8-1.8c-0.8,0-1.5,0.5-1.7,1.2h-1.9c-0.2,0-0.3,0.1-0.4,0.2L30,17h-5.2
	v-1.8h3c0.2,0,0.3-0.1,0.4-0.2l4.7-4.7h1.7c0.3,0.7,0.9,1.2,1.7,1.2c1,0,1.8-0.8,1.8-1.8S37.3,8,36.3,8c-0.8,0-1.5,0.5-1.7,1.2h-1.9
	c-0.2,0-0.3,0.1-0.4,0.2L27.6,14h-2.8v-1.8H26z M36.3,3.7c0.3,0,0.6,0.3,0.6,0.6c0,0.3-0.3,0.6-0.6,0.6c-0.3,0-0.6-0.3-0.6-0.6
	C35.7,4,36,3.7,36.3,3.7z M36.3,36.4c0.3,0,0.6,0.3,0.6,0.6c0,0.3-0.3,0.6-0.6,0.6c-0.3,0-0.6-0.3-0.6-0.6
	C35.7,36.6,36,36.4,36.3,36.4z M36.3,30.9c0.3,0,0.6,0.3,0.6,0.6s-0.3,0.6-0.6,0.6c-0.3,0-0.6-0.3-0.6-0.6S36,30.9,36.3,30.9z
	 M36.3,25.5c0.3,0,0.6,0.3,0.6,0.6s-0.3,0.6-0.6,0.6c-0.3,0-0.6-0.3-0.6-0.6S36,25.5,36.3,25.5z M36.3,20c0.3,0,0.6,0.3,0.6,0.6
	c0,0.3-0.3,0.6-0.6,0.6c-0.3,0-0.6-0.3-0.6-0.6S36,20,36.3,20z M36.3,14.6c0.3,0,0.6,0.3,0.6,0.6c0,0.3-0.3,0.6-0.6,0.6
	c-0.3,0-0.6-0.3-0.6-0.6C35.7,14.9,36,14.6,36.3,14.6z M36.3,9.2c0.3,0,0.6,0.3,0.6,0.6s-0.3,0.6-0.6,0.6c-0.3,0-0.6-0.3-0.6-0.6
	S36,9.2,36.3,9.2z M18.1,13.4h3.1V20h-3.1c-0.3-1.4-1.5-2.4-3-2.4c-0.8,0-1.4,0.3-2,0.8L11,16.7l2.2-1.7c0.5,0.5,1.2,0.8,2,0.8
	C16.6,15.8,17.8,14.8,18.1,13.4z M13.4,20.6c0-1,0.8-1.8,1.8-1.8s1.8,0.8,1.8,1.8s-0.8,1.8-1.8,1.8S13.4,21.6,13.4,20.6z M15.2,11
	c1,0,1.8,0.8,1.8,1.8s-0.8,1.8-1.8,1.8s-1.8-0.8-1.8-1.8S14.2,11,15.2,11z M4.9,6.8c-1,0-1.8-0.8-1.8-1.8s0.8-1.8,1.8-1.8
	s1.8,0.8,1.8,1.8S5.9,6.8,4.9,6.8z M4.9,14.6c-1,0-1.8-0.8-1.8-1.8S3.9,11,4.9,11s1.8,0.8,1.8,1.8S5.9,14.6,4.9,14.6z M7.6,14.1
	c0.1-0.2,0.2-0.5,0.3-0.7h4.4c0.1,0.3,0.1,0.5,0.3,0.7L10,16L7.6,14.1z M12.5,19.3c-0.1,0.2-0.2,0.5-0.3,0.7H7.9
	c-0.1-0.3-0.1-0.5-0.3-0.7l2.4-1.9L12.5,19.3z M4.9,22.5c-1,0-1.8-0.8-1.8-1.8s0.8-1.8,1.8-1.8s1.8,0.8,1.8,1.8S5.9,22.5,4.9,22.5z
	 M7.6,22c0.1-0.2,0.2-0.5,0.3-0.7h4.4c0.1,0.3,0.1,0.5,0.3,0.7L10,23.8L7.6,22z M12.2,27.9H7.9c-0.1-0.3-0.1-0.5-0.3-0.7l2.4-1.9
	l2.4,1.9C12.3,27.4,12.3,27.6,12.2,27.9z M4.9,30.3c-1,0-1.8-0.8-1.8-1.8s0.8-1.8,1.8-1.8s1.8,0.8,1.8,1.8S5.9,30.3,4.9,30.3z
	 M4.9,38.2c-1,0-1.8-0.8-1.8-1.8c0-1,0.8-1.8,1.8-1.8s1.8,0.8,1.8,1.8C6.7,37.4,5.9,38.2,4.9,38.2z M15.2,30.3c-1,0-1.8-0.8-1.8-1.8
	s0.8-1.8,1.8-1.8s1.8,0.8,1.8,1.8S16.2,30.3,15.2,30.3z M18.1,27.9c-0.3-1.4-1.5-2.4-3-2.4c-0.8,0-1.4,0.3-2,0.8L11,24.6l2.2-1.7
	c0.5,0.5,1.2,0.8,2,0.8c1.5,0,2.7-1,3-2.4h3.1v6.6H18.1z M23.6,30.3c0,0.3-0.3,0.6-0.6,0.6c-0.3,0-0.6-0.3-0.6-0.6V10.4
	c0-0.3,0.3-0.6,0.6-0.6c0.3,0,0.6,0.3,0.6,0.6V30.3z"/>
</svg>
';

/**
 * Sensor attribute video sensor block should report.
 * @readonly
 * @enum {string}
 */
const SensingAttribute = {
    /** The amount of motion. */
    MOTION: 'motion',

    /** The direction of the motion. */
    DIRECTION: 'direction'
};

/**
 * Subject video sensor block should report for.
 * @readonly
 * @enum {string}
 */
const SensingSubject = {
    /** The sensor traits of the whole stage. */
    STAGE: 'Stage',

    /** The senosr traits of the area overlapped by this sprite. */
    SPRITE: 'this sprite'
};

/**
 * States the video sensing activity can be set to.
 * @readonly
 * @enum {string}
 */
const VideoState = {
    /** Video turned off. */
    OFF: 'off',

    /** Video turned on with default y axis mirroring. */
    ON: 'on',

    /** Video turned on without default y axis mirroring. */
    ON_FLIPPED: 'on-flipped'
};

const ModelType = {
    POSE: 'pose',
    IMAGE: 'image',
    AUDIO: 'audio',
}

const EXTENSION_ID = 'teachableMachine';

/**
 * Class for the motion-related blocks in Scratch 3.0
 * @param {Runtime} runtime - the runtime instantiating this block package.
 * @constructor
 */
class Scratch3VideoSensingBlocks {
    constructor (runtime) {
        /**
         * The runtime instantiating this block package.
         * @type {Runtime}
         */
        this.runtime = runtime;
        this.runtime.registerPeripheralExtension(EXTENSION_ID, this);
        this.runtime.connectPeripheral(EXTENSION_ID, 0);
        this.runtime.emit(this.runtime.constructor.PERIPHERAL_CONNECTED);

        /**
         * The motion detection algoritm used to power the motion amount and
         * direction values.
         * @type {VideoMotion}
         */
        this.detect = new VideoMotion();

        /**
         * The last millisecond epoch timestamp that the video stream was
         * analyzed.
         * @type {number}
         */
        this._lastUpdate = null;

        /**
         * A flag to determine if this extension has been installed in a project.
         * It is set to false the first time getInfo is run.
         * @type {boolean}
         */
        this.firstInstall = true;

        if (this.runtime.ioDevices) {
            // Configure the video device with values from globally stored locations.
            this.runtime.on(Runtime.PROJECT_LOADED, this.updateVideoDisplay.bind(this));
            // Kick off looping the analysis logic.
            this._loop();
        }
    }

    /**
     * After analyzing a frame the amount of milliseconds until another frame
     * is analyzed.
     * @type {number}
     */
    static get INTERVAL () {
        return 33;
    }

    /**
     * Dimensions the video stream is analyzed at after its rendered to the
     * sample canvas.
     * @type {Array.<number>}
     */
    static get DIMENSIONS () {
        return [480, 360];
    }

    /**
     * The key to load & store a target's motion-related state.
     * @type {string}
     */
    static get STATE_KEY () {
        return 'Scratch.videoSensing';
    }

    /**
     * The default motion-related state, to be used when a target has no existing motion state.
     * @type {MotionState}
     */
    static get DEFAULT_MOTION_STATE () {
        return {
            motionFrameNumber: 0,
            motionAmount: 0,
            motionDirection: 0
        };
    }

    /**
     * The transparency setting of the video preview stored in a value
     * accessible by any object connected to the virtual machine.
     * @type {number}
     */
    get globalVideoTransparency () {
        const stage = this.runtime.getTargetForStage();
        if (stage) {
            return stage.videoTransparency;
        }
        return 50;
    }

    set globalVideoTransparency (transparency) {
        const stage = this.runtime.getTargetForStage();
        if (stage) {
            stage.videoTransparency = transparency;
        }
        return transparency;
    }

    /**
     * The video state of the video preview stored in a value accessible by any
     * object connected to the virtual machine.
     * @type {number}
     */
    get globalVideoState () {
        const stage = this.runtime.getTargetForStage();
        if (stage) {
            return stage.videoState;
        }
        // Though the default value for the stage is normally 'on', we need to default
        // to 'off' here to prevent the video device from briefly activating
        // while waiting for stage targets to be installed that say it should be off
        return VideoState.OFF;
    }

    set globalVideoState (state) {
        const stage = this.runtime.getTargetForStage();
        if (stage) {
            stage.videoState = state;
        }
        return state;
    }

    /**
     * Get the latest values for video transparency and state,
     * and set the video device to use them.
     */
    updateVideoDisplay () {
        this.setVideoTransparency({
            TRANSPARENCY: this.globalVideoTransparency
        });
        this.videoToggle({
            VIDEO_STATE: this.globalVideoState
        });
    }

    /**
     * Occasionally step a loop to sample the video, stamp it to the preview
     * skin, and add a TypedArray copy of the canvas's pixel data.
     * @private
     */
    _loop () {
        setTimeout(this._loop.bind(this), Math.max(this.runtime.currentStepTime, Scratch3VideoSensingBlocks.INTERVAL));

        // Add frame to detector
        const time = Date.now();
        if (this._lastUpdate === null) {
            this._lastUpdate = time;
        }
        if (!this._isPredicting) {
            this._isPredicting = 0;
        }
        const offset = time - this._lastUpdate;

        // TOOD: Self-throttle interval if slow to run predictions
        const isAudioModel = this.isAudio();
        if (isAudioModel) {
            this.predictAllBlocks(null);
            this._lastUpdate = time;
            this._isPredicting = 0;
        }
        else if (offset > Scratch3VideoSensingBlocks.INTERVAL && this._isPredicting === 0) {
            const frame = this.runtime.ioDevices.video.getFrame({
                format: Video.FORMAT_IMAGE_DATA,
                dimensions: Scratch3VideoSensingBlocks.DIMENSIONS
            });

            if (frame) {
                this._lastUpdate = time;
                this._isPredicting = 0;
                this.predictAllBlocks(frame);
            }
        }
    }

    scan() {
    }

    reset () {
    }

    isConnected() {
        return this.predictionState &&
            this.teachableImageModel &&
            this.predictionState.hasOwnProperty(this.teachableImageModel);
    }

    connect() {
    }


    async predictAllBlocks(frame) {
        for (let modelUrl in this.predictionState) {
            if (!this.predictionState[modelUrl].model) {
                continue;
            }
            if (this.teachableImageModel !== modelUrl) {
                continue;
            }
            ++this._isPredicting;
            const prediction = await this.predictModel(modelUrl, frame);
            this.predictionState[modelUrl].topClass = prediction;
            this.runtime.emit(this.runtime.constructor.PERIPHERAL_CONNECTED);
            --this._isPredicting;
        }
    }

    /**
     * Create data for a menu in scratch-blocks format, consisting of an array
     * of objects with text and value properties. The text is a translated
     * string, and the value is one-indexed.
     * @param {object[]} info - An array of info objects each having a name
     *   property.
     * @return {array} - An array of objects with text and value properties.
     * @private
     */
    _buildMenu (info) {
        return info.map((entry, index) => {
            const obj = {};
            obj.text = entry.name;
            obj.value = entry.value || String(index + 1);
            return obj;
        });
    }

    /**
     * @param {Target} target - collect motion state for this target.
     * @returns {MotionState} the mutable motion state associated with that
     *   target. This will be created if necessary.
     * @private
     */
    _getMotionState (target) {
        let motionState = target.getCustomState(Scratch3VideoSensingBlocks.STATE_KEY);
        if (!motionState) {
            motionState = Clone.simple(Scratch3VideoSensingBlocks.DEFAULT_MOTION_STATE);
            target.setCustomState(Scratch3VideoSensingBlocks.STATE_KEY, motionState);
        }
        return motionState;
    }

    static get SensingAttribute () {
        return SensingAttribute;
    }

    /**
     * An array of choices of whether a reporter should return the frame's
     * motion amount or direction.
     * @type {object[]}
     * @param {string} name - the translatable name to display in sensor
     *   attribute menu
     * @param {string} value - the serializable value of the attribute
     */
    get ATTRIBUTE_INFO () {
        return [
            {
                name: formatMessage({
                    id: 'videoSensing.motion',
                    default: 'motion',
                    description: 'Attribute for the "video [ATTRIBUTE] on [SUBJECT]" block'
                }),
                value: SensingAttribute.MOTION
            },
            {
                name: formatMessage({
                    id: 'videoSensing.direction',
                    default: 'direction',
                    description: 'Attribute for the "video [ATTRIBUTE] on [SUBJECT]" block'
                }),
                value: SensingAttribute.DIRECTION
            }
        ];
    }

    static get SensingSubject () {
        return SensingSubject;
    }

    /**
     * An array of info about the subject choices.
     * @type {object[]}
     * @param {string} name - the translatable name to display in the subject menu
     * @param {string} value - the serializable value of the subject
     */
    get SUBJECT_INFO () {
        return [
            {
                name: formatMessage({
                    id: 'videoSensing.sprite',
                    default: 'sprite',
                    description: 'Subject for the "video [ATTRIBUTE] on [SUBJECT]" block'
                }),
                value: SensingSubject.SPRITE
            },
            {
                name: formatMessage({
                    id: 'videoSensing.stage',
                    default: 'stage',
                    description: 'Subject for the "video [ATTRIBUTE] on [SUBJECT]" block'
                }),
                value: SensingSubject.STAGE
            }
        ];
    }

    /**
     * States the video sensing activity can be set to.
     * @readonly
     * @enum {string}
     */
    static get VideoState () {
        return VideoState;
    }

    /**
     * An array of info on video state options for the "turn video [STATE]" block.
     * @type {object[]}
     * @param {string} name - the translatable name to display in the video state menu
     * @param {string} value - the serializable value stored in the block
     */
    get VIDEO_STATE_INFO () {
        return [
            {
                name: formatMessage({
                    id: 'videoSensing.off',
                    default: 'off',
                    description: 'Option for the "turn video [STATE]" block'
                }),
                value: VideoState.OFF
            },
            {
                name: formatMessage({
                    id: 'videoSensing.on',
                    default: 'on',
                    description: 'Option for the "turn video [STATE]" block'
                }),
                value: VideoState.ON
            },
            {
                name: formatMessage({
                    id: 'videoSensing.onFlipped',
                    default: 'on flipped',
                    description: 'Option for the "turn video [STATE]" block that causes the video to be flipped' +
                        ' horizontally (reversed as in a mirror)'
                }),
                value: VideoState.ON_FLIPPED
            }
        ];
    }

    /**
     * @returns {object} metadata for this extension and its blocks.
     */
    getInfo () {
        // Set the video display properties to defaults the first time
        // getInfo is run. This turns on the video device when it is
        // first added to a project, and is overwritten by a PROJECT_LOADED
        // event listener that later calls updateVideoDisplay
        if (this.firstInstall) {
            this.globalVideoState = VideoState.ON;
            this.globalVideoTransparency = 50;
            this.updateVideoDisplay();
            this.updateToStageModel();
            this.firstInstall = false;
            this.predictionState = {};
        }

        // Return extension definition
        const blocks = [
            {
                opcode: 'useModelBlock',
                text: `use model [MODEL_URL]`,
                arguments: {
                    MODEL_URL: {
                        type: ArgumentType.STRING,
                        defaultValue: this.teachableImageModel || 'Paste URL Here!'
                    }
                }
            },
            {
                // @todo (copied from motion) this hat needs to be set itself to restart existing
                // threads like Scratch 2's behaviour.
                opcode: 'whenModelMatches',
                text: 'when model detects [CLASS_NAME]',
                blockType: BlockType.HAT,
                arguments: {
                    CLASS_NAME: {
                        type: ArgumentType.STRING,
                        defaultValue: this.getCurrentClasses()[0],
                        menu: 'CLASS_NAME'
                    }
                },
            },
            {
                opcode: 'modelPrediction',
                text: formatMessage({
                    id: 'teachableMachine.modelPrediction',
                    default: 'model prediction',
                    description: 'Value of latest model prediction'
                }),
                blockType: BlockType.REPORTER,
                isTerminal: true,
            },
            {
                // @todo (copied from motion) this hat needs to be set itself to restart existing
                // threads like Scratch 2's behaviour.
                opcode: 'modelMatches',
                text: formatMessage({
                    id: 'teachableMachine.modelMatches',
                    default: 'prediction is [CLASS_NAME]',
                    description: 'Boolean that is true when the model matches [CLASS_NAME]'
                }),
                blockType: BlockType.BOOLEAN,
                arguments: {
                    CLASS_NAME: {
                        type: ArgumentType.STRING,
                        defaultValue: this.getCurrentClasses()[0],
                        menu: 'CLASS_NAME'
                    }
                },
            },
            '---',
            {
                opcode: 'videoToggle',
                text: formatMessage({
                    id: 'videoSensing.videoToggle',
                    default: 'turn video [VIDEO_STATE]',
                    description: 'Controls display of the video preview layer'
                }),
                arguments: {
                    VIDEO_STATE: {
                        type: ArgumentType.NUMBER,
                        menu: 'VIDEO_STATE',
                        defaultValue: VideoState.ON
                    }
                }
            },
            {
                opcode: 'setVideoTransparency',
                text: formatMessage({
                    id: 'videoSensing.setVideoTransparency',
                    default: 'set video transparency to [TRANSPARENCY]',
                    description: 'Controls transparency of the video preview layer'
                }),
                arguments: {
                    TRANSPARENCY: {
                        type: ArgumentType.NUMBER,
                        defaultValue: 50
                    }
                }
            }
        ];

        return {
            id: EXTENSION_ID,
            name: formatMessage({
                id: 'videoSensing.categoryName',
                default: 'Teachable Machine',
                description: 'Label for the Teachable Machine extension category'
            }),
            showStatusButton: true,
            blockIconURI: blockIconURI,
            menuIconURI: menuIconURI,
            blocks: blocks,
            menus: {
                CLASS_NAME: 'getCurrentClasses',
                ATTRIBUTE: {
                    acceptReporters: true,
                    items: this._buildMenu(this.ATTRIBUTE_INFO)
                },
                SUBJECT: {
                    acceptReporters: true,
                    items: this._buildMenu(this.SUBJECT_INFO)
                },
                VIDEO_STATE: {
                    acceptReporters: true,
                    items: this._buildMenu(this.VIDEO_STATE_INFO)
                }
            }
        };
    }

    updateToStageModel() {
        const stage = this.runtime.getTargetForStage();
        if (stage) {
            this.teachableImageModel = stage.teachableImageModel;
            if (this.teachableImageModel) {
                this.useModel(this.teachableImageModel);
            }
        }
    }

    updateStageModel(modelUrl) {
        const stage = this.runtime.getTargetForStage();
        this.teachableImageModel = modelUrl;
        if (stage) {
            stage.teachableImageModel = modelUrl;
        }
    }

    useModelBlock(args, util) {
        const modelArg = args.MODEL_URL;
        this.useModel(modelArg);
    }

    useModel(modelArg) {
        try {
            const modelUrl = this.modelArgumentToURL(modelArg);
            this.getPredictionStateOrStartPredicting(modelUrl);
            this.updateStageModel(modelUrl);
        } catch (e) {
            this.teachableImageModel = null;
        }
    }

    modelArgumentToURL(modelArg) {
        return modelArg.startsWith('https://teachablemachine.withgoogle.com/models/') ?
            modelArg :
            `https://teachablemachine.withgoogle.com/models/${modelArg}/`;
    }

    /**
     * A scratch hat block edge handle that downloads a teachable machine model and determines whether the
     * current video frame matches the model class.
     * @param {object} args - the block arguments
     * @param {BlockUtility} util - the block utility
     * @returns {boolean} true if the model matches
     *   reference
     */
    whenModelMatches(args, util) {
        const modelUrl = this.teachableImageModel;
        const className = args.CLASS_NAME;

        const predictionState = this.getPredictionStateOrStartPredicting(modelUrl);
        if (!predictionState) {
            return false;
        }

        const currentMaxClass = predictionState.topClass;
        return (currentMaxClass === String(className));
    }

    modelMatches(args, util) {
        const modelUrl = this.teachableImageModel;
        const className = args.CLASS_NAME;

        const predictionState = this.getPredictionStateOrStartPredicting(modelUrl);
        if (!predictionState) {
            return false;
        }

        const currentMaxClass = predictionState.topClass;
        return (currentMaxClass === String(className));
    }

    /**
     * A scratch hat block reporter that returns whether the current video frame matches the model class.
     * @param {object} args - the block arguments
     * @param {BlockUtility} util - the block utility
     * @returns {string} class name if video frame matched, empty string if model not loaded yet
     */
    modelPrediction(args, util) {
        const modelUrl = this.teachableImageModel;
        const predictionState = this.getPredictionStateOrStartPredicting(modelUrl);
        if (!predictionState) {
            return '';
        }

        return predictionState.topClass;
    }

    getPredictionStateOrStartPredicting(modelUrl) {
        const hasPredictionState = this.predictionState.hasOwnProperty(modelUrl);
        if (!hasPredictionState) {
            this.startPredicting(modelUrl);
            return null;
        }
        return this.predictionState[modelUrl];
    }

    getCurrentClasses() {
        if (
            !this.teachableImageModel ||
            !this.predictionState ||
            !this.predictionState[this.teachableImageModel] ||
            !this.predictionState[this.teachableImageModel].hasOwnProperty('model')
        ) {
            return ["Class 1"];
        }
        if (this.predictionState[this.teachableImageModel].modelType === ModelType.AUDIO) {
            return this.predictionState[this.teachableImageModel].model.wordLabels();
        }

        return this.predictionState[this.teachableImageModel].model.getClassLabels();
    }

    isAudio() {
        return this.predictionState && this.predictionState[this.teachableImageModel] &&
            this.predictionState[this.teachableImageModel].modelType === ModelType.AUDIO;
    }

    async startPredicting(modelDataUrl) {
        if (!this.predictionState[modelDataUrl]) {
            try {
                this.predictionState[modelDataUrl] = {};
                // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/image
                const {model, type} = await this.initModel(modelDataUrl);
                this.predictionState[modelDataUrl].modelType = type;
                this.predictionState[modelDataUrl].model = model;
                this.runtime.requestToolboxExtensionsUpdate();
            } catch (e) {
                this.predictionState[modelDataUrl] = {};
                console.log("Model initialization failure!", e);
            }
        }
    }

    async initModel(modelUrl) {
        const modelURL = modelUrl + "model.json";
        const metadataURL = modelUrl + "metadata.json";
        const customMobileNet = await tmImage.load(modelURL, metadataURL);
        if (customMobileNet._metadata.hasOwnProperty('tfjsSpeechCommandsVersion')) {
            // customMobileNet.dispose(); // too early to dispose
            console.log("We got a speech net yay")
            const recognizer = tmAudioSpeechCommands.create("BROWSER_FFT", undefined, modelURL, metadataURL);
            await recognizer.ensureModelLoaded();
            await recognizer.listen(result => {
                this.latestAudioResults = result;
            }, {
                includeSpectrogram: true, // in case listen should return result.spectrogram
                probabilityThreshold: 0.75,
                invokeCallbackOnNoiseAndUnknown: true,
                overlapFactor: 0.50 // probably want between 0.5 and 0.75. More info in README
            });
            return {model: recognizer, type: ModelType.AUDIO};
        } else if (customMobileNet._metadata.packageName === "@teachablemachine/pose") {
            console.log("We got a pose net yay")
            const customPoseNet = await tmPose.load(modelURL, metadataURL);
            return {model: customPoseNet, type: ModelType.POSE};
        } else {
            console.log("Not a pose net yay")
           return {model: customMobileNet, type: ModelType.IMAGE};
        }
    }

    async predictModel(modelUrl, frame) {
        console.log("Predicting model");
        const predictions = await this.getPredictionFromModel(modelUrl, frame);
        if (!predictions) {
            return;
        }
        let maxProbability = 0;
        let maxClassName = "";
        for (let i = 0; i < predictions.length; i++) {
            const probability = predictions[i].probability.toFixed(2);
            const className = predictions[i].className;
            if (probability > maxProbability) {
                maxClassName = className;
                maxProbability = probability;
            }
        }
        return maxClassName;
    }

    async getPredictionFromModel(modelUrl, frame) {
        const {model, modelType} = this.predictionState[modelUrl];
        switch (modelType) {
            case ModelType.IMAGE:
                const imageBitmap = await createImageBitmap(frame);
                return await model.predict(imageBitmap);
            case ModelType.POSE:
                const {pose, posenetOutput} = await model.estimatePose(frame);
                return await model.predict(posenetOutput);
            case ModelType.AUDIO:
                if (this.latestAudioResults) {
                    return model.wordLabels().map((label, i) => {
                        return {className: label, probability: this.latestAudioResults.scores[i]}
                    });
                } else {
                    return null;
                }
        }
    }

    /**
     * A scratch command block handle that configures the video state from
     * passed arguments.
     * @param {object} args - the block arguments
     * @param {VideoState} args.VIDEO_STATE - the video state to set the device to
     */
    videoToggle (args) {
        const state = args.VIDEO_STATE;
        this.globalVideoState = state;
        if (state === VideoState.OFF) {
            this.runtime.ioDevices.video.disableVideo();
        } else {
            this.runtime.ioDevices.video.enableVideo();
            // Mirror if state is ON. Do not mirror if state is ON_FLIPPED.
            this.runtime.ioDevices.video.mirror = state === VideoState.ON;
        }
    }

    /**
     * A scratch command block handle that configures the video preview's
     * transparency from passed arguments.
     * @param {object} args - the block arguments
     * @param {number} args.TRANSPARENCY - the transparency to set the video
     *   preview to
     */
    setVideoTransparency (args) {
        const transparency = Cast.toNumber(args.TRANSPARENCY);
        this.globalVideoTransparency = transparency;
        this.runtime.ioDevices.video.setPreviewGhost(transparency);
    }
}

module.exports = Scratch3VideoSensingBlocks;
