/*
 * Resources:
 *  - Text to speech extension written by Scratch Team 2019
 *  - Speech to text extension written by Sayamindu Dasgupta <sayamindu@media.mit.edu>, April 2014
 *  - Knn Classifier model written by Katya3141 https://katya3141.github.io/scratch-gui/teachable-classifier/ August 2019
 */

require("regenerator-runtime/runtime");
const Runtime = require('../../engine/runtime');
const nets = require('nets');
const MathUtil = require('../../util/math-util');

const ArgumentType = require('../../extension-support/argument-type');
const BlockType = require('../../extension-support/block-type');
const Clone = require('../../util/clone');
const Cast = require('../../util/cast');
const formatMessage = require('format-message');
const Tag = require("en-pos").Tag;
const { wordsToNumbers } = require("words-to-numbers");
const Timer = require('../../util/timer');
const tf = require('@tensorflow/tfjs');
const use = require('@tensorflow-models/universal-sentence-encoder');
const toxicity = require('@tensorflow-models/toxicity');
var Sentiment = require('sentiment');
//const node = require('@tensorflow/tfjs-node');
//const layers = require('@tensorflow/tfjs-layers');


/**
 * Icon svg to be displayed in the blocks category menu, encoded as a data URI.
 * @type {string}
 */
// eslint-disable-next-line max-len
const menuIconURI = 'data:image/svg+xml;base64,<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<svg
   xmlns:dc="http://purl.org/dc/elements/1.1/"
   xmlns:cc="http://creativecommons.org/ns#"
   xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
   xmlns:svg="http://www.w3.org/2000/svg"
   xmlns="http://www.w3.org/2000/svg"
   xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
   id="Layer_1_1_"
   enable-background="new 0 0 64 64"
   height="72.780205"
   viewBox="0 0 9.1991234 9.0975256"
   width="73.592987"
   version="1.1"
   inkscape:version="0.48.4 r9939"
   sodipodi:docname="text-classification-blocks-menu.svg">
  <metadata
     id="metadata21">
    <rdf:RDF>
      <cc:Work
         rdf:about="">
        <dc:format>image/svg+xml</dc:format>
        <dc:type
           rdf:resource="http://purl.org/dc/dcmitype/StillImage" />
        <dc:title></dc:title>
      </cc:Work>
    </rdf:RDF>
  </metadata>
  <defs
     id="defs19" />
  <sodipodi:namedview
     pagecolor="#ffffff"
     bordercolor="#666666"
     borderopacity="1"
     objecttolerance="10"
     gridtolerance="10"
     guidetolerance="10"
     inkscape:pageopacity="0"
     inkscape:pageshadow="2"
     inkscape:window-width="1007"
     inkscape:window-height="783"
     id="namedview17"
     showgrid="false"
     fit-margin-top="0"
     fit-margin-left="0"
     fit-margin-right="0"
     fit-margin-bottom="0"
     inkscape:zoom="10.429825"
     inkscape:cx="44.912112"
     inkscape:cy="33.108471"
     inkscape:window-x="627"
     inkscape:window-y="178"
     inkscape:window-maximized="0"
     inkscape:current-layer="Layer_1_1_" />
  <path
     sodipodi:type="arc"
     style="fill:#aaffcc;fill-opacity:1;stroke:#00aa44"
     id="path2993"
     sodipodi:cx="-4.3624892"
     sodipodi:cy="28.581223"
     sodipodi:rx="32.934399"
     sodipodi:ry="32.934399"
     d="m 28.571909,28.581223 a 32.934399,32.934399 0 1 1 -65.868797,0 32.934399,32.934399 0 1 1 65.868797,0 z"
     transform="matrix(0.13755698,0,0,0.13610137,5.2013733,0.65924101)" />
  <path
     d="m 2.9791233,6.137428 c 0,0.139175 -0.03202,0.269729 -0.09114,0.385503 -0.140407,0.283277 -0.433537,0.476644 -0.771006,0.476644 -0.476644,0 -0.862147,-0.385503 -0.862147,-0.862147 0,-0.476644 0.385503,-0.862147 0.862147,-0.862147 0.173661,0 0.333774,0.0505 0.468023,0.137943 0.237706,0.153955 0.394124,0.419989 0.394124,0.724204 z"
     id="path3"
     inkscape:connector-curvature="0"
     style="fill:#000080;fill-opacity:1" />
  <path
     d="m 7.5002307,3.8572393 c 0.476644,0 0.862147,0.385503 0.862147,0.862147 0,0.476644 -0.385503,0.862147 -0.862147,0.862147 -0.231548,0 -0.440926,-0.08991 -0.594881,-0.24017 -0.16504,-0.155186 -0.267266,-0.376881 -0.267266,-0.621977 0,-0.03941 0.0025,-0.07759 0.0086,-0.115774 0.02463,-0.192136 0.113311,-0.363334 0.243864,-0.493887 0.156418,-0.156418 0.370723,-0.252486 0.609661,-0.252486 z"
     id="path7"
     inkscape:connector-curvature="0"
     style="fill:#000080" />
  <path
     style="fill:#000080;fill-opacity:1;stroke:none"
     d="M 1.6842184,3.641441 C 1.2629901,3.3627243 1.2006396,2.7462127 1.5557106,2.3707757 1.9022591,2.0043501 2.4951785,2.0633456 2.7794918,2.4925419 3.2449268,3.1951577 2.3803563,4.1020583 1.6842184,3.641441 z"
     id="path2988"
     inkscape:connector-curvature="0" />
  <path
     style="fill:#000080;fill-opacity:1;stroke:none"
     d="M 4.3049044,2.5776682 C 4.0127706,2.3282715 3.9342559,2.0011231 4.0810112,1.6447697 4.3064184,1.0974329 4.9784113,0.92659387 5.3886513,1.3123316 6.1978274,2.0731787 5.1487365,3.2980525 4.3049044,2.5776682 z"
     id="path2990"
     inkscape:connector-curvature="0" />
  <path
     style="fill:#000080;fill-opacity:1;stroke:none"
     d="M 4.3784972,4.9757011 C 3.8278365,4.6409554 3.8928456,3.8504273 4.4938182,3.5733694 4.866088,3.4017469 5.2893822,3.5302824 5.5101175,3.8819738 5.7301862,4.2326033 5.7089766,4.5244492 5.4425609,4.8115608 5.1456488,5.1315377 4.7382343,5.1943846 4.3784972,4.9757011 z"
     id="path2992"
     inkscape:connector-curvature="0" />
  <path
     style="fill:#000080;fill-opacity:1;stroke:none"
     d="M 4.3246268,7.9820751 C 4.0366848,7.7379754 3.9592965,7.4177752 4.1039462,7.0689904 4.326119,6.5332782 4.9884695,6.3660676 5.392823,6.7436128 6.1903885,7.4883005 5.1563507,8.6871597 4.3246268,7.9820751 z"
     id="path2994"
     inkscape:connector-curvature="0" />
  <path
     style="fill:#f6db40;fill-opacity:1;stroke:none"
     d=""
     id="path3001"
     inkscape:connector-curvature="0" />
  <path
     d="m 2.5436163,5.250648 c -0.129322,-0.06244 -0.27367,-0.09853 -0.42664,-0.09853 -0.543275,0 -0.985311,0.442035 -0.985311,0.985311 0,0.543276 0.442036,0.985311 0.985311,0.985311 0.340918,0 0.641807,-0.174154 0.818793,-0.438094 l 0.93075,0.465929 c -0.01601,0.07033 -0.02525,0.143362 -0.02525,0.218492 0,0.543276 0.442035,0.985311 0.985311,0.985311 0.543275,0 0.98531,-0.442035 0.98531,-0.985311 0,-0.204205 -0.06244,-0.394001 -0.16935,-0.551527 l 1.307877,-1.367489 c 0.164054,0.121686 0.366289,0.194722 0.585767,0.194722 0.543276,0 0.985311,-0.442035 0.985311,-0.98531 0,-0.543276 -0.442035,-0.985311 -0.985311,-0.985311 -0.22736,0 -0.436246,0.07809 -0.603256,0.207901 L 5.6039903,2.553115 c 0.129815,-0.16701 0.2079,-0.375896 0.2079,-0.603257 0,-0.543275 -0.442035,-0.98531102 -0.98531,-0.98531102 -0.543276,0 -0.985311,0.44203602 -0.985311,0.98531102 0,0.07488 0.0091,0.147674 0.02512,0.217877 L 2.9929113,2.48599 C 2.8292333,2.168104 2.4984153,1.949857 2.1169763,1.949857 c -0.543275,0 -0.985311,0.442035 -0.985311,0.985311 0,0.543276 0.442036,0.985311 0.985311,0.985311 0.140161,0 0.273301,-0.02981 0.394125,-0.08289 l 0.453366,0.763 z m -0.42664,1.625763 c -0.407549,0 -0.738983,-0.331434 -0.738983,-0.738983 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.407549 -0.331434,0.738983 -0.738983,0.738983 z m 0.928532,-0.412476 c 0.03609,-0.102349 0.05678,-0.211965 0.05678,-0.326507 0,-0.302121 -0.136958,-0.572589 -0.351633,-0.753393 l 0.354219,-0.547094 1.067954,1.797083 c -0.08991,0.08006 -0.165163,0.175878 -0.220956,0.283647 z m 1.781073,-3.528767 c 0.22736,0 0.436246,-0.07809 0.603256,-0.207901 l 1.329061,1.329061 c -0.07969,0.102473 -0.139298,0.220833 -0.173661,0.349663 L 5.8115223,4.299577 c -1.23e-4,-0.0032 3.69e-4,-0.0064 3.69e-4,-0.0096 0,-0.543275 -0.442035,-0.985311 -0.98531,-0.985311 -0.340918,0 -0.64193,0.174154 -0.818793,0.438094 L 3.8608533,3.66935 4.4000643,2.836639 c 0.129199,0.06244 0.273547,0.09853 0.426517,0.09853 z m 0.123164,3.457086 V 5.266659 c 0.400282,-0.05025 0.725927,-0.341163 0.827907,-0.723218 l 0.773715,0.106414 c 0,0.0032 -4.92e-4,0.0064 -4.92e-4,0.0096 0,0.235243 0.08301,0.451149 0.221079,0.620746 L 5.4787333,6.632416 C 5.3337693,6.503956 5.1513643,6.417619 4.9497453,6.392247 z M 4.8265813,3.550987 c 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.407549 -0.331434,0.738983 -0.738983,0.738983 -0.407549,0 -0.738983,-0.331434 -0.738983,-0.738983 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 z m -0.928532,0.412476 c -0.03609,0.102349 -0.05678,0.211965 -0.05678,0.326507 0,0.501523 0.376881,0.915847 0.862147,0.976813 v 1.125594 c -0.116759,0.01466 -0.226991,0.04964 -0.32737,0.101487 L 3.2542703,4.606132 3.7261113,3.877495 z m 0.928532,4.144586 c -0.407549,0 -0.738983,-0.331434 -0.738983,-0.738983 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.407549 -0.331434,0.738983 -0.738983,0.738983 z m 2.709604,-4.18757 c 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.407549 -0.331434,0.738983 -0.738983,0.738983 -0.407549,0 -0.738983,-0.331434 -0.738983,-0.738983 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 z M 4.8265813,1.210874 c 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.407549 -0.331434,0.738983 -0.738983,0.738983 -0.407549,0 -0.738983,-0.331434 -0.738983,-0.738983 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 z m -0.875818,1.188162 c 0.06023,0.116882 0.142623,0.220217 0.242263,0.304214 L 3.6392813,3.5585 3.0456323,3.261675 c 0.03596,-0.102349 0.05665,-0.211965 0.05665,-0.326507 0,-0.07488 -0.0091,-0.147673 -0.02512,-0.217877 z m -2.57277,0.536132 c 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.407549 -0.331434,0.738983 -0.738983,0.738983 -0.407549,0 -0.738983,-0.331434 -0.738983,-0.738983 z m 1.344334,0.775809 c 0.08252,-0.06454 0.15494,-0.141392 0.213442,-0.228592 l 0.568648,0.284262 -0.390553,0.603133 z"
     id="path15"
     inkscape:connector-curvature="0"
     style="fill:#000000" />
</svg>
';

/**
 * Icon svg to be displayed at the left edge of each extension block, encoded as a data URI.
 * @type {string}
 */
// eslint-disable-next-line max-len
//const blockIconURI = 'data:image/svg+xml;base64,<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<svg
   xmlns:dc="http://purl.org/dc/elements/1.1/"
   xmlns:cc="http://creativecommons.org/ns#"
   xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
   xmlns:svg="http://www.w3.org/2000/svg"
   xmlns="http://www.w3.org/2000/svg"
   xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
   id="Layer_1_1_"
   enable-background="new 0 0 64 64"
   height="59.118649"
   viewBox="0 0 7.3898301 7.3898311"
   width="59.118641"
   version="1.1"
   inkscape:version="0.48.4 r9939"
   sodipodi:docname="text-classification-blocks-small.svg">
  <metadata
     id="metadata21">
    <rdf:RDF>
      <cc:Work
         rdf:about="">
        <dc:format>image/svg+xml</dc:format>
        <dc:type
           rdf:resource="http://purl.org/dc/dcmitype/StillImage" />
        <dc:title></dc:title>
      </cc:Work>
    </rdf:RDF>
  </metadata>
  <defs
     id="defs19" />
  <sodipodi:namedview
     pagecolor="#ffffff"
     bordercolor="#666666"
     borderopacity="1"
     objecttolerance="10"
     gridtolerance="10"
     guidetolerance="10"
     inkscape:pageopacity="0"
     inkscape:pageshadow="2"
     inkscape:window-width="1007"
     inkscape:window-height="783"
     id="namedview17"
     showgrid="false"
     fit-margin-top="0"
     fit-margin-left="0"
     fit-margin-right="0"
     fit-margin-bottom="0"
     inkscape:zoom="7.375"
     inkscape:cx="40.244264"
     inkscape:cy="27.374394"
     inkscape:window-x="627"
     inkscape:window-y="178"
     inkscape:window-maximized="0"
     inkscape:current-layer="Layer_1_1_" />
  <path
     d="m 1.847458,5.172881 c 0,0.139175 -0.03202,0.269729 -0.09114,0.385503 -0.140407,0.283277 -0.433537,0.476644 -0.771006,0.476644 -0.476644,0 -0.862147,-0.385503 -0.862147,-0.862147 0,-0.476644 0.385503,-0.862147 0.862147,-0.862147 0.173661,0 0.333774,0.0505 0.468023,0.137943 0.237706,0.153955 0.394124,0.419989 0.394124,0.724204 z"
     id="path3"
     inkscape:connector-curvature="0"
     style="fill:#000080;fill-opacity:1" />
  <path
     d="m 6.3685654,2.8926923 c 0.476644,0 0.862147,0.385503 0.862147,0.862147 0,0.476644 -0.385503,0.862147 -0.862147,0.862147 -0.231548,0 -0.440926,-0.08991 -0.594881,-0.24017 -0.16504,-0.155186 -0.267266,-0.376881 -0.267266,-0.621977 0,-0.03941 0.0025,-0.07759 0.0086,-0.115774 0.02463,-0.192136 0.113311,-0.363334 0.243864,-0.493887 0.156418,-0.156418 0.370723,-0.252486 0.609661,-0.252486 z"
     id="path7"
     inkscape:connector-curvature="0"
     style="fill:#000080" />
  <path
     style="fill:#000080;fill-opacity:1;stroke:none"
     d="M 0.5525531,2.676894 C 0.1313248,2.3981773 0.0689743,1.7816657 0.4240453,1.4062287 0.7705938,1.0398031 1.3635132,1.0987986 1.6478265,1.5279949 2.1132615,2.2306107 1.248691,3.1375113 0.5525531,2.676894 z"
     id="path2988"
     inkscape:connector-curvature="0" />
  <path
     style="fill:#000080;fill-opacity:1;stroke:none"
     d="M 3.1732391,1.6131212 C 2.8811053,1.3637245 2.8025906,1.0365761 2.9493459,0.68022271 3.1747531,0.13288591 3.846746,-0.03795312 4.256986,0.34778461 5.0661621,1.1086317 4.0170712,2.3335055 3.1732391,1.6131212 z"
     id="path2990"
     inkscape:connector-curvature="0" />
  <path
     style="fill:#000080;fill-opacity:1;stroke:none"
     d="M 3.2468319,4.0111541 C 2.6961712,3.6764084 2.7611803,2.8858803 3.3621529,2.6088224 3.7344227,2.4371999 4.1577169,2.5657354 4.3784522,2.9174268 4.5985209,3.2680563 4.5773113,3.5599022 4.3108956,3.8470138 4.0139835,4.1669907 3.606569,4.2298376 3.2468319,4.0111541 z"
     id="path2992"
     inkscape:connector-curvature="0" />
  <path
     style="fill:#000080;fill-opacity:1;stroke:none"
     d="M 3.1929615,7.0175281 C 2.9050195,6.7734284 2.8276312,6.4532282 2.9722809,6.1044434 3.1944537,5.5687312 3.8568042,5.4015206 4.2611577,5.7790658 5.0587232,6.5237535 4.0246854,7.7226127 3.1929615,7.0175281 z"
     id="path2994"
     inkscape:connector-curvature="0" />
  <path
     style="fill:#f6db40;fill-opacity:1;stroke:none"
     d=""
     id="path3001"
     inkscape:connector-curvature="0" />
  <path
     d="M 1.411951,4.286101 C 1.282629,4.223661 1.138281,4.187571 0.985311,4.187571 0.442036,4.187571 0,4.629606 0,5.172882 c 0,0.543276 0.442036,0.985311 0.985311,0.985311 0.340918,0 0.641807,-0.174154 0.818793,-0.438094 l 0.93075,0.465929 c -0.01601,0.07033 -0.02525,0.143362 -0.02525,0.218492 0,0.543276 0.442035,0.985311 0.985311,0.985311 0.543275,0 0.98531,-0.442035 0.98531,-0.985311 0,-0.204205 -0.06244,-0.394001 -0.16935,-0.551527 L 5.818752,4.485504 c 0.164054,0.121686 0.366289,0.194722 0.585767,0.194722 0.543276,0 0.985311,-0.442035 0.985311,-0.98531 0,-0.543276 -0.442035,-0.985311 -0.985311,-0.985311 -0.22736,0 -0.436246,0.07809 -0.603256,0.207901 L 4.472325,1.588568 C 4.60214,1.421558 4.680225,1.212672 4.680225,0.98531101 4.680225,0.44203601 4.23819,0 3.694915,0 3.151639,0 2.709604,0.44203601 2.709604,0.98531101 c 0,0.07488 0.0091,0.14767399 0.02512,0.21787699 L 1.861246,1.521443 C 1.697568,1.203557 1.36675,0.98531001 0.985311,0.98531001 0.442036,0.98531001 0,1.427345 0,1.970621 c 0,0.543276 0.442036,0.985311 0.985311,0.985311 0.140161,0 0.273301,-0.02981 0.394125,-0.08289 l 0.453366,0.763 z m -0.42664,1.625763 c -0.407549,0 -0.738983,-0.331434 -0.738983,-0.738983 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.407549 -0.331434,0.738983 -0.738983,0.738983 z M 1.913843,5.499388 C 1.949933,5.397039 1.970623,5.287423 1.970623,5.172881 1.970623,4.87076 1.833665,4.600292 1.61899,4.419488 L 1.973209,3.872394 3.041163,5.669477 C 2.951253,5.749537 2.876,5.845355 2.820207,5.953124 z M 3.694916,1.970621 c 0.22736,0 0.436246,-0.07809 0.603256,-0.207901 L 5.627233,3.091781 C 5.547543,3.194254 5.487935,3.312614 5.453572,3.441444 L 4.679857,3.33503 c -1.23e-4,-0.0032 3.69e-4,-0.0064 3.69e-4,-0.0096 0,-0.543275 -0.442035,-0.985311 -0.98531,-0.985311 -0.340918,0 -0.64193,0.174154 -0.818793,0.438094 L 2.729188,2.704803 3.268399,1.872092 c 0.129199,0.06244 0.273547,0.09853 0.426517,0.09853 z M 3.81808,5.427707 V 4.302112 C 4.218362,4.251862 4.544007,3.960949 4.645987,3.578894 l 0.773715,0.106414 c 0,0.0032 -4.92e-4,0.0064 -4.92e-4,0.0096 0,0.235243 0.08301,0.451149 0.221079,0.620746 L 4.347068,5.667869 C 4.202104,5.539409 4.019699,5.453072 3.81808,5.4277 z M 3.694916,2.58644 c 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.407549 -0.331434,0.738983 -0.738983,0.738983 -0.407549,0 -0.738983,-0.331434 -0.738983,-0.738983 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 z M 2.766384,2.998916 c -0.03609,0.102349 -0.05678,0.211965 -0.05678,0.326507 0,0.501523 0.376881,0.915847 0.862147,0.976813 V 5.42783 C 3.454992,5.44249 3.34476,5.47747 3.244381,5.529317 L 2.122605,3.641585 2.594446,2.912948 z m 0.928532,4.144586 c -0.407549,0 -0.738983,-0.331434 -0.738983,-0.738983 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.407549 -0.331434,0.738983 -0.738983,0.738983 z M 6.40452,2.955932 c 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.407549 -0.331434,0.738983 -0.738983,0.738983 -0.407549,0 -0.738983,-0.331434 -0.738983,-0.738983 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 z M 3.694916,0.24632701 c 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.40754899 -0.331434,0.73898299 -0.738983,0.73898299 -0.407549,0 -0.738983,-0.331434 -0.738983,-0.73898299 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 z M 2.819098,1.434489 c 0.06023,0.116882 0.142623,0.220217 0.242263,0.304214 L 2.507616,2.593953 1.913967,2.297128 c 0.03596,-0.102349 0.05665,-0.211965 0.05665,-0.326507 0,-0.07488 -0.0091,-0.147673 -0.02512,-0.217877 z m -2.57277,0.536132 c 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.407549 -0.331434,0.738983 -0.738983,0.738983 -0.407549,0 -0.738983,-0.331434 -0.738983,-0.738983 z M 1.590662,2.74643 C 1.673182,2.68189 1.745602,2.605038 1.804104,2.517838 L 2.372752,2.8021 1.982199,3.405233 z"
     id="path15"
     inkscape:connector-curvature="0"
     style="fill:#000000" />
</svg>
';
const blockIconURI =
    "data:image/svg+xml;base64,<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!-- Created with Inkscape (http://www.inkscape.org/) -->

<svg
   xmlns:dc="http://purl.org/dc/elements/1.1/"
   xmlns:cc="http://creativecommons.org/ns#"
   xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
   xmlns:svg="http://www.w3.org/2000/svg"
   xmlns="http://www.w3.org/2000/svg"
   xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
   width="52.171387mm"
   height="39.865608mm"
   viewBox="0 0 52.171387 39.865608"
   version="1.1"
   id="svg8"
   inkscape:version="0.92.4 (5da689c313, 2019-01-14)"
   sodipodi:docname="nlp_icon.svg">
  <defs
     id="defs2" />
  <sodipodi:namedview
     id="base"
     pagecolor="#ffffff"
     bordercolor="#666666"
     borderopacity="1.0"
     inkscape:pageopacity="0.0"
     inkscape:pageshadow="2"
     inkscape:zoom="5.6"
     inkscape:cx="162.76051"
     inkscape:cy="70.954415"
     inkscape:document-units="mm"
     inkscape:current-layer="layer1"
     showgrid="false"
     fit-margin-top="0"
     fit-margin-left="-0.1"
     fit-margin-right="0"
     fit-margin-bottom="0"
     inkscape:window-width="1573"
     inkscape:window-height="1080"
     inkscape:window-x="3521"
     inkscape:window-y="226"
     inkscape:window-maximized="0" />
  <metadata
     id="metadata5">
    <rdf:RDF>
      <cc:Work
         rdf:about="">
        <dc:format>image/svg+xml</dc:format>
        <dc:type
           rdf:resource="http://purl.org/dc/dcmitype/StillImage" />
        <dc:title></dc:title>
      </cc:Work>
    </rdf:RDF>
  </metadata>
  <g
     inkscape:label="Layer 1"
     inkscape:groupmode="layer"
     id="layer1"
     transform="translate(81.173731,-168.79918)">
    <path
       style="fill:#f9cfcf;fill-opacity:1;stroke:#4770c7;stroke-width:0.94999999;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:4;stroke-dasharray:none;stroke-opacity:1"
       d="m -52.353194,180.71488 3.340867,0.53454 1.80407,-1.33634 2.138156,-0.0668 2.071341,0.73499 1.403164,1.73725 0.734992,1.93771 -0.534541,1.73725 -0.753924,1.3393 -1.842633,1.39379 -1.81901,0.25986 0.245689,3.12739 2.187533,-0.0563 2.504091,-1.27567 1.700892,-1.93713 0.944941,-1.67727 0.519718,-2.05525 -0.04725,-2.3151 -0.661459,-1.77176 -1.252048,-1.93713 -1.582774,-1.53553 -2.055247,-0.82682 -3.732514,-0.18899 -2.244232,0.82682 -3.094681,2.62221 z"
       id="path3870"
       inkscape:connector-curvature="0" />
    <path
       style="fill:#f9a7a7;fill-opacity:1;stroke:#4770c7;stroke-width:3.59055114;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:4;stroke-dasharray:none;stroke-opacity:1"
       d="M 145.89258,2.9375 123,3.5 l -2.01758,13.009766 -7.58984,3.570312 -10.80274,-9.105469 -10.804684,8.035157 -6.427734,9.820312 8.570312,9.28711 0.439454,6.382812 2.15039,1.830078 10.714842,-1.96289 13.21485,-10.892579 13.92773,-4.019531 14.62305,4.212891 0.0371,0.185547 11.14843,13 2.69532,8.703125 0.31445,9.93164 -1.51172,5.667969 -8.51562,11.744141 -2.58204,2.126953 -7.8164,3.982422 -8.26758,0.21289 v 0.712891 l -8.91992,0.457031 -15.48047,-10.769531 -5.00586,-9.369141 -0.37305,-8.261718 -8.779294,0.169921 2.328125,47.339841 5.910159,0.77735 9.41601,-10.650394 9.14844,3.291014 0.17383,15.74414 13.24609,1.5293 11.11133,-2.62891 0.97461,-14.1289 7.08594,-2.9961 5.92187,5.95703 6.48661,4.9682 12.3591,-14.712336 c 0,0 3.91268,-3.752978 3.52315,-6.354632 l -3.45479,-3.114118 -7.86915,-6.101563 5.38393,-10.348772 9.77344,0.30664 6.37891,-0.780133 1.16015,-10.80413 L 192.589,48.29548 177.51366,49.019531 176.36913,45.466797 173.92772,39.367188 180,33.5625 l 4.46429,-3.749442 -9.69085,-11.012277 -0.6875,-0.886719 -0.44532,-0.279296 -5.51562,-5.679688 -2.13588,-0.835659 -1.8485,0.560269 -2.56054,2.457031 -0.41992,0.140625 -0.94141,1.166015 -5.19531,4.986329 -2.22266,0.197265 -4.58594,-3.046875 z"
       transform="matrix(0.26458333,0,0,0.26458333,-81.151486,168.50704)"
       id="path3872"
       inkscape:connector-curvature="0"
       sodipodi:nodetypes="ccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc" />
    <path
       style="fill:#e0ebfc;fill-opacity:1;stroke:#4770c7;stroke-width:3.77952766;stroke-miterlimit:4;stroke-dasharray:none;stroke-opacity:1"
       d="m 27.15625,46.242188 c -14.253434,0 -25.7285156,9.945064 -25.7285156,22.298828 v 42.544924 c 0,12.35376 11.4750816,22.29883 25.7285156,22.29883 h 28.521484 l -0.945312,15.08984 1.964844,1.07227 L 69.876953,140 l 9.982422,-6.61523 h 26.912105 c 14.25344,0 25.72852,-9.94507 25.72852,-22.29883 V 68.541016 c 0,-12.353764 -11.47508,-22.298828 -25.72852,-22.298828 z"
       transform="matrix(0.26458333,0,0,0.26458333,-81.151486,168.50704)"
       id="rect3770"
       inkscape:connector-curvature="0" />
    <path
       inkscape:connector-curvature="0"
       id="path3738"
       d="m -75.760377,196.71014 c -0.170334,-0.27275 -0.276939,-0.71923 -0.236901,-0.99219 0.06982,-0.47596 0.573378,-0.49909 12.300841,-0.56508 10.350017,-0.0582 12.286503,-0.0103 12.608672,0.31183 0.493284,0.49329 0.482521,0.58112 -0.148537,1.21218 -0.513402,0.5134 -0.881943,0.52917 -12.371772,0.52917 -11.291295,0 -11.857022,-0.0231 -12.152303,-0.49591 z m 0,-7.40833 c -0.170334,-0.27275 -0.27694,-0.71924 -0.236902,-0.99219 0.06978,-0.47575 0.569853,-0.49925 12.086157,-0.56804 13.482091,-0.0805 14.19628,0.006 12.67482,1.52697 -0.513402,0.5134 -0.881943,0.52916 -12.371772,0.52916 -11.291295,0 -11.857022,-0.0231 -12.152303,-0.4959 z"
       style="fill:#4770c7;stroke-width:0.26458332"
       sodipodi:nodetypes="cccccscccccsc" />
    <path
       style="fill:#ff6600;fill-opacity:1;stroke:#1a1a1a;stroke-width:0.04464286;stroke-miterlimit:4;stroke-dasharray:none"
       d=""
       id="path3823"
       inkscape:connector-curvature="0"
       transform="matrix(0.26458333,0,0,0.26458333,-81.151486,168.50704)" />
    <path
       style="fill:#ff6600;fill-opacity:1;stroke:#1a1a1a;stroke-width:0.04464286;stroke-miterlimit:4;stroke-dasharray:none"
       d=""
       id="path3829"
       inkscape:connector-curvature="0"
       transform="matrix(0.26458333,0,0,0.26458333,-81.151486,168.50704)" />
    <path
       style="fill:#ff6600;fill-opacity:1;stroke:#1a1a1a;stroke-width:0.04464286;stroke-miterlimit:4;stroke-dasharray:none"
       d=""
       id="path3831"
       inkscape:connector-curvature="0"
       transform="matrix(0.26458333,0,0,0.26458333,-81.151486,168.50704)" />
  </g>
</svg>
";

/**
 * The url of the synthesis server.
 * @type {string}
 */
const SERVER_HOST = 'https://synthesis-service.scratch.mit.edu';

/**
 * The url of the translate server.
 * @type {string}
 */
const serverURL = 'https://translate-service.scratch.mit.edu/';

/**
 * How long to wait in ms before timing out requests to translate server.
 * @type {int}
 */
const serverTimeoutMs = 10000; // 10 seconds (chosen arbitrarily).


/**
 * How long to wait in ms before timing out requests to synthesis server.
 * @type {int}
 */
const SERVER_TIMEOUT = 10000; // 10 seconds

/**
 * Volume for playback of speech sounds, as a percentage.
 * @type {number}
 */
const SPEECH_VOLUME = 250;

/**
 * An id for one of the voices.
 */
const ALTO_ID = 'ALTO';

/**
 * An id for one of the voices.
 */
const TENOR_ID = 'TENOR';

/**
 * An id for one of the voices.
 */
const SQUEAK_ID = 'SQUEAK';

/**
 * An id for one of the voices.
 */
const GIANT_ID = 'GIANT';

/**
 * Playback rate for the tenor voice, for cases where we have only a female gender voice.
 */
const FEMALE_TENOR_RATE = 0.89; // -2 semitones

/**
 * Playback rate for the giant voice, for cases where we have only a female gender voice.
 */
const FEMALE_GIANT_RATE = 0.79; // -4 semitones

const _partsOfSpeech = {
    noun: ["NN", "PRP", "WP"],
    "proper noun": ["NNP"],
    verb: ["VB"],
    adverb: ["RB", "WRB"],
    adjective: ["JJ"],
    number: ["CD"],
};

/**
 * Class for the motion-related blocks in Scratch 3.0
 * @param {Runtime} runtime - the runtime instantiating this block package.
 * @constructor
 */
class Scratch3TextClassificationBlocks {
    constructor(runtime) {

        /**
        * The result from the most recent translation.
        * @type {string}
        * @private
        */
        this._translateResult = '';

        /**
         * The language of the text most recently translated.
         * @type {string}
         * @private
         */
        this._lastLangTranslated = '';

        /**
         * The text most recently translated.
         * @type {string}
         * @private
         */
        this._lastTextTranslated = '';

        /**
         * The runtime instantiating this block package.
         * @type {Runtime}
         */
        this.scratch_vm = runtime;
        this.sentencesample = [];
        this.labledsample = [];
        this.lastSentenceClassified = null;

        this.custom_NLP_model = tf.sequential();

        /**
         * The timer utility.
         * @type {Timer}
         */
        this._timer = new Timer();

        /**
         * The stored microphone loudness measurement.
         * @type {number}
         */
        this._cachedLoudness = -1;

        /**
         * The time of the most recent microphone loudness measurement.
         * @type {number}
         */
        this._cachedLoudnessTimestamp = 0;

        /**
        * Map of soundPlayers by sound id.
        * @type {Map<string, SoundPlayer>}
        */
        this._soundPlayers = new Map();

        this._stopAllSpeech = this._stopAllSpeech.bind(this);
        if (this.scratch_vm) {
            this.scratch_vm.on('PROJECT_STOP_ALL', this._stopAllSpeech);
        }

        this._onTargetCreated = this._onTargetCreated.bind(this);
        if (this.scratch_vm) {
            this.scratch_vm.on('targetWasCreated', this._onTargetCreated);
        }

        this.scratch_vm.on('EDIT_TEXT_MODEL', modelInfo => {
            console.log(modelInfo);
            console.log("Calling bound function");
            this.editModel.bind(this, modelInfo);
        });
        this.scratch_vm.on('EDIT_TEXT_CLASSIFIER', modelInfo => {
            console.log(modelInfo);
            console.log("Calling bound function");
            this.editModel.bind(this, modelInfo);
        });

        this.labelList = [''];
        this.labelListEmpty = true;

        // When a project is loaded, reset all the model data
        this.scratch_vm.on('PROJECT_LOADED', () => {
            this.clearLocal();
            this.loadModelFromRuntime();
        });
        // Listen for model editing events emitted by the text modal
        this.scratch_vm.on('NEW_EXAMPLES', (examples, label) => {
            this.newExamples(examples, label);
        });
        this.scratch_vm.on('NEW_LABEL', (label) => {
            this.newLabel(label);
        });
        this.scratch_vm.on('DELETE_EXAMPLE', (label, exampleNum) => {
            this.deleteExample(label, exampleNum);
        });
        this.scratch_vm.on('RENAME_LABEL', (oldName, newName) => {
            this.renameLabel(oldName, newName);
        });
        this.scratch_vm.on('DELETE_LABEL', (label) => {
            this.clearAllWithLabel({ LABEL: label });
        });
        this.scratch_vm.on('CLEAR_ALL_LABELS', () => {
            if (!this.labelListEmpty && confirm('Are you sure you want to clear all labels?')) {    //confirm with alert dialogue before clearing the model
                let labels = [...this.labelList];
                for (var i = 0; i < labels.length; i++) {
                    this.clearAllWithLabel({ LABEL: labels[i] });
                }
                //this.clearAll(); this crashed Scratch for some reason
            }
        });

        //Listen for model editing events emitted by the classifier modal
        this.scratch_vm.on('EXPORT_CLASSIFIER', () => {
            this.exportClassifier();
        });
        this.scratch_vm.on('LOAD_CLASSIFIER', () => {
            console.log("load");
            this.loadClassifier();

        });

        this.scratch_vm.on('DONE', () => {
            console.log("DONE");
            this.buildCustomDeepModel();
        });


        this._recognizedSpeech = "";

        this._toxicity_labels = {
            items: [
                {
                    value: 'toxicity',
                    text: 'toxic'
                }, {
                    value: 'severe_toxicity',
                    text: 'severely toxic'
                }, {
                    value: 'identity_attack',
                    text: 'an identity-based attack'
                }, {
                    value: 'insult',
                    text: 'insulting'
                }, {
                    value: 'threat',
                    text: 'threatening'
                }, {
                    //     value : 'sexual_explicit',
                    //     text : 'sexually explicit'
                    // }, {
                    value: 'obscene',
                    text: 'profanity'
                }
            ],
            acceptReporters: true
        };

        this.sentiment = new Sentiment();

    }

    /**
     * An object with info for each voice.
     */
    get VOICE_INFO() {
        return {
            [SQUEAK_ID]: {
                name: formatMessage({
                    id: 'text2speech.squeak',
                    default: 'squeak',
                    description: 'Name for a funny voice with a high pitch.'
                }),
                gender: 'female',
                playbackRate: 1.19 // +3 semitones
            },
            [TENOR_ID]: {
                name: formatMessage({
                    id: 'text2speech.tenor',
                    default: 'tenor',
                    description: 'Name for a voice with ambiguous gender.'
                }),
                gender: 'male',
                playbackRate: 1
            },
            [ALTO_ID]: {
                name: formatMessage({
                    id: 'text2speech.alto',
                    default: 'alto',
                    description: 'Name for a voice with ambiguous gender.'
                }),
                gender: 'female',
                playbackRate: 1
            },
            [GIANT_ID]: {
                name: formatMessage({
                    id: 'text2speech.giant',
                    default: 'giant',
                    description: 'Name for a funny voice with a low pitch.'
                }),
                gender: 'male',
                playbackRate: 0.84 // -3 semitones
            }
        };
    }

    /**
    * The key to load & store a target's text2speech state.
    * @return {string} The key.
    */
    static get STATE_KEY() {
        return 'Scratch.text2speech';
    }

    /**
     * The default state, to be used when a target has no existing state.
     * @type {Text2SpeechState}
     */
    static get DEFAULT_TEXT2SPEECH_STATE() {
        return {
            voiceId: SQUEAK_ID
        };
    }

    /**
     * @param {Target} target - collect  state for this target.
     * @returns {Text2SpeechState} the mutable state associated with that target. This will be created if necessary.
     * @private
     */
    _getState(target) {
        let state = target.getCustomState(Scratch3TextClassificationBlocks.STATE_KEY);
        if (!state) {
            state = Clone.simple(Scratch3TextClassificationBlocks.DEFAULT_TEXT2SPEECH_STATE);
            target.setCustomState(Scratch3TextClassificationBlocks.STATE_KEY, state);
        }
        return state;
    }

    /**
     * When a Target is cloned, clone the state.
     * @param {Target} newTarget - the newly created target.
     * @param {Target} [sourceTarget] - the target used as a source for the new clone, if any.
     * @listens Runtime#event:targetWasCreated
     * @private
     */
    _onTargetCreated(newTarget, sourceTarget) {
        if (sourceTarget) {
            const state = sourceTarget.getCustomState(Scratch3TextClassificationBlocks.STATE_KEY);
            if (state) {
                newTarget.setCustomState(Scratch3TextClassificationBlocks.STATE_KEY, Clone.simple(state));
            }
        }
    }

    /**
     * @returns {object} metadata for this extension and its blocks.
     */
    getInfo() {
        // Set the video display properties to defaults the first time
        // getInfo is run. This turns on the video device when it is
        // first added to a project, and is overwritten by a PROJECT_LOADED
        // event listener that later calls updateVideoDisplay
        if (this.firstInstall) {
            this.globalVideoState = VideoState.OFF;
            this.globalVideoTransparency = 50;
            this.updateVideoDisplay();
            this.firstInstall = false;
            this.predictionState = {};
        }

        // Return extension definition
        return {
            id: 'textClassification',
            name: formatMessage({
                id: 'textClassification.categoryName',
                default: 'Text Classification',
                description: 'Label for the Text Classification extension category'
            }),
            blockIconURI: blockIconURI,
            menuIconURI: menuIconURI,
            //color1, color2, color3
            blocks: [
                {
                    func: 'EDIT_TEXT_MODEL',
                    blockType: BlockType.BUTTON,
                    text: 'Edit Model'
                },
                {
                    func: 'EDIT_TEXT_CLASSIFIER',
                    blockType: BlockType.BUTTON,
                    text: 'Load / Save Model'
                },
                {
                    opcode: 'ifTextMatchesClass',
                    text: formatMessage({
                        id: 'textClassification.ifTextMatchesClass',
                        default: '[TEXT] matches [CLASS_NAME] ?',
                        description: 'Conditional that is true when the text matches the text classification model class [CLASS_NAME]'
                    }),
                    blockType: BlockType.BOOLEAN,
                    arguments: {
                        TEXT: {
                            type: ArgumentType.STRING,
                            defaultValue: 'text'
                        },
                        CLASS_NAME: {
                            type: ArgumentType.STRING,
                            menu: 'model_classes',
                            defaultValue: this.getLabels()[0],
                        }
                    }
                },
                {
                    opcode: 'getModelPrediction',
                    text: formatMessage({
                        id: 'textClassification.getModelPrediction',
                        default: 'predict class for [TEXT]',
                        description: 'Get the class name that the input text matches'
                    }),
                    blockType: BlockType.REPORTER,
                    arguments: {
                        TEXT: {
                            type: ArgumentType.STRING,
                            defaultValue: 'text'
                        }
                    },
                },
                {
                    opcode: 'getModelConfidence',
                    text: formatMessage({
                        id: 'textClassification.getModelConfidence',
                        default: 'confidence for [TEXT]',
                        description: 'Get the Confidence level of class name that the input text matches'
                    }),
                    blockType: BlockType.REPORTER,
                    arguments: {
                        TEXT: {
                            type: ArgumentType.STRING,
                            defaultValue: 'text'
                        }
                    },
                },
                {
                    opcode: 'getSimilarity',
                    text: formatMessage({
                        id: 'textClassification.getSimilarity',
                        default: 'similarity between [TEXT_ONE] and [TEXT_TWO]',
                        description: 'get the similarity between two words/sentences'
                    }),
                    blockType: BlockType.REPORTER,
                    arguments: {
                        TEXT_ONE: {
                            type: ArgumentType.STRING,
                            defaultValue: 'text one'
                        },
                        TEXT_TWO: {
                            type: ArgumentType.STRING,
                            defaultValue: 'text two'
                        }
                    }
                },
                '---',
                {
                    opcode: "getWordInString",
                    text: formatMessage({
                        id: "textClassification.getWordInString",
                        default: "word [NUM] of [TEXT]",
                        description:
                            "Reporter block that returns the nth word of an input string",
                    }),
                    blockType: BlockType.REPORTER,
                    arguments: {
                        NUM: {
                            type: ArgumentType.NUMBER,
                            defaultValue: "1",
                        },
                        NUM: {
                            type: ArgumentType.NUMBER,
                            defaultValue: "1",
                        },
                        TEXT: {
                            type: ArgumentType.STRING,
                            defaultValue: "Here comes the robot",
                        },
                    },
                },
                '---',
                {
                    opcode: "getPartOfSpeech",
                    text: formatMessage({
                        id: "textClassification.getPartOfSpeech",
                        default: "[POS] [NUM] of [TEXT]",
                        description:
                            "Reporter block that returns the 1st match for a requested part of speech",
                    }),
                    blockType: BlockType.REPORTER,
                    arguments: {
                        POS: {
                            type: ArgumentType.STRING,
                            menu: "parts_of_speech",
                            defaultValue: "noun",
                        },
                        NUM: {
                            type: ArgumentType.NUMBER,
                            defaultValue: "1",
                        },
                        TEXT: {
                            type: ArgumentType.STRING,
                            defaultValue: "My name is Scratch Cat",
                        },
                    },
                },
                {
                    opcode: "getWordsLike",
                    text: formatMessage({
                        id: "textClassification.getWordsLike",
                        default: "word [NUM] of [TEXT] like [LIST]",
                        description:
                            "Reporter block that returns words that match target words",
                    }),
                    blockType: BlockType.REPORTER,
                    arguments: {
                        NUM: {
                            type: ArgumentType.NUMBER,
                            defaultValue: "1",
                        },
                        LIST: {
                            type: ArgumentType.STRING,
                            defaultValue: "yes no maybe",
                        },
                        TEXT: {
                            type: ArgumentType.STRING,
                            defaultValue: "No I don't like them",
                        },
                    },
                },
                {
                    opcode: "textContainsPartOfSpeech",
                    text: formatMessage({
                        id: "textClassification.textContainsPartOfSpeech",
                        default: "[TEXT] contains [POS] ?",
                        description:
                            "Reporter block that returns true if a text has a part of speech",
                    }),
                    blockType: BlockType.BOOLEAN,
                    arguments: {
                        TEXT: {
                            type: ArgumentType.STRING,
                            defaultValue: "Spin five times",
                        },
                        POS: {
                            type: ArgumentType.STRING,
                            menu: "parts_of_speech",
                            defaultValue: "number",
                        },
                    },
                },
                {
                    opcode: "textContainsWordsLike",
                    text: formatMessage({
                        id: "textClassification.textContainsWordsLike",
                        default: "[TEXT] contains words like [LIST] ?",
                        description:
                            "Reporter block that returns true if a text contains text from a list",
                    }),
                    blockType: BlockType.BOOLEAN,
                    arguments: {
                        TEXT: {
                            type: ArgumentType.STRING,
                            defaultValue: "Move to the left",
                        },
                        LIST: {
                            type: ArgumentType.STRING,
                            defaultValue: "spin move say",
                        },
                    },
                },
                /*
                {
                    opcode: 'confidenceTrue',
                    text: formatMessage({
                        id: 'textClassification.confidencetrue',
                        default: 'probability that [TEXT] is [LABEL]'
                    }),
                    blockType: BlockType.REPORTER,
                    arguments: {
                        TEXT: {
                            type: ArgumentType.STRING,
                            defaultValue: 'TEXT'
                        },
                        LABEL: {
                            type: ArgumentType.STRING,
                            defaultValue: this._toxicity_labels.items[0].value,
                            menu: 'toxicitylabels'
                        }
                    }
                },
/*                {
                    opcode: 'confidenceFalse',
                    text: formatMessage({
                        id: 'textClassification.confidencefalse',
                        default: 'probability that [TEXT] is NOT [LABEL]'
                    }),
                    blockType: BlockType.REPORTER,
                    arguments: {
                        TEXT: {
                            type: ArgumentType.STRING,
                            defaultValue: 'TEXT'
                        },
                        LABEL: {
                            type: ArgumentType.STRING,
                            defaultValue: this._toxicity_labels.items[0].value,
                            menu: 'toxicitylabels'
                        }
                    }
                },
                {
                    opcode: 'sentimentScore',
                    text: formatMessage({
                        id: 'textClassification.sentimentScore',
                        default: 'Sentiment Score for [TEXT]'
                    }),
                    blockType: BlockType.REPORTER,
                    arguments: {
                        TEXT: {
                            type: ArgumentType.STRING,
                            defaultValue: 'TEXT'
                        }
                    }
                },
                '---',
                {
                    opcode: 'speakText',
                    text: formatMessage({
                        id: 'textClassification.speakText',
                        default: 'speak [TEXT]',
                        description: 'Send text to the speech to text engine'
                    }),
                    blockType: BlockType.COMMAND,
                    arguments: {
                        TEXT: {
                            type: ArgumentType.STRING,
                            defaultValue: 'Hello'
                        }
                    },
                },
                {
                    opcode: 'askSpeechRecognition',
                    text: formatMessage({
                        id: 'textClassification.askSpeechRecognition',
                        default: 'speak [PROMPT] then listen for response',
                        description: 'Get the class name that the input text matches'
                    }),
                    blockType: BlockType.COMMAND,
                    arguments: {
                        PROMPT: {
                            type: ArgumentType.STRING,
                            defaultValue: 'How are you?'
                        }
                    },
                },
                {
                    opcode: 'getRecognizedSpeech',
                    text: formatMessage({
                        id: 'textClassification.getRecognizedSpeech',
                        default: 'response',
                        description: 'Return the results of the speech recognition'
                    }),
                    blockType: BlockType.REPORTER,
                },
                {
                    opcode: 'setVoice',
                    text: formatMessage({
                        id: 'text2speech.setVoiceBlock',
                        default: 'set voice to [VOICE]',
                        description: 'Set the voice for speech synthesis.'
                    }),
                    blockType: BlockType.COMMAND,
                    arguments: {
                        VOICE: {
                            type: ArgumentType.STRING,
                            menu: 'voices',
                            defaultValue: SQUEAK_ID
                        }
                    }
                },
                {
                    opcode: 'onHeardSound',
                    text: formatMessage({
                        id: 'textClassification.onHeardSound',
                        default: 'when heard sound > [THRESHOLD]',
                        description: 'Event that triggers when a sound is heard above a threshold'
                    }),
                    blockType: BlockType.HAT,
                    arguments: {
                        THRESHOLD: {
                            type: ArgumentType.NUMBER,
                            defaultValue: 10
                        }
                    },
                }*/
            ],
            menus: {
                voices: {
                    acceptReporters: true,
                    items: this.getVoiceMenu()
                },
                model_classes: {
                    acceptReporters: false,
                    items: 'getLabels'
                },
                toxicitylabels: this._toxicity_labels,
                parts_of_speech: {
                    acceptReporters: true,
                    items: Object.keys(_partsOfSpeech),
                },
                runtime_lists: {
                    acceptReporters: true,
                    items: "getListNames",
                },
            }
        };
    }

    /**
     * TODO Moves info from the runtime into the classifier, called when a project is loaded
     */
    async loadModelFromRuntime() {
        this.labelList = [];
        this.labelListEmpty = false;
        let textData = this.scratch_vm.modelData.textData;

        for (let label in this.scratch_vm.modelData.textData) {
            if (this.scratch_vm.modelData.textData.hasOwnProperty(label)) {
                let textExamples = textData[label];
                this.newLabel(label);
                this.newExamples(textExamples, label);
            }
        }

        if (this.labelList.length == 0) {
            this.labelList.push('');    //if the label list is empty, fill it with an empty string
            this.labelListEmpty = true;
        }

        await this.buildCustomDeepModel()

    }

    /**
     * Return label list for block menus
     * @return {array of strings} an array of the labels for the text model classifier
     */
    getLabels() {
        return this.labelList;
    }

    /**
     * TODO grab text and add it as an example
     * @param {string} args.LABEL the name of the label to add an example to
     */
    textExample(args) {
        console.log("Get text example");
        // TODO grab text
        let text = '';
        if (frame) {
            this.newExamples([text], args.LABEL);
        }
    }

    /**
     * TODO Add new examples to a label
     * @param {array of strings} examples a list of text examples to add to a label
     * @param {string} label the name of the label
     */
    newExamples(text_examples, label) {   //add examples for a label
        console.log("Add examples to label " + label);
        console.log(text_examples);
        if (this.labelListEmpty) {
            // Edit label list accordingly
            this.labelList.splice(this.labelList.indexOf(''), 1);
            this.labelListEmpty = false;
        }
        if (!this.labelList.includes(label)) {
            this.labelList.push(label);
        }
        for (let text_example of text_examples) {
            if (!this.scratch_vm.modelData.textData[label].includes(text_example)) {
                this.scratch_vm.modelData.textData[label].push(text_example);
                this.scratch_vm.modelData.classifierData[label].push(text_example);
            }
        }

    }

    /**
     * TODO Add a new label to labelList
     * @param {string} label the name of the label
     */
    newLabel(newLabelName) {   //add the name of a new label
        if (this.labelListEmpty) {
            // Edit label list accordingly
            this.labelList.splice(this.labelList.indexOf(''), 1);
            this.labelListEmpty = false;
        }
        if (!this.labelList.includes(newLabelName)) {
            this.labelList.push(newLabelName);
        }

        this.scratch_vm.modelData.textData[newLabelName] = [];
        this.scratch_vm.modelData.classifierData[newLabelName] = [];
        // update drowndown of class names
        //this.scratch_vm.emit("TOOLBOX_EXTENSIONS_NEED_UPDATE");
        this.scratch_vm.requestToolboxExtensionsUpdate();
    }




    /**
     * TODO Rename a label
     * @param {string} oldName the name of the label to change
     * @param {string} newname the new name for the label
     */
    renameLabel(oldName, newName) {
        console.log("Rename a label");

        this.scratch_vm.modelData.classifierData[newName] = this.scratch_vm.modelData.classifierData[oldName];  //reset the runtime's model data with the new renamed label (to share with GUI)
        delete this.scratch_vm.modelData.classifierData[oldName];

        this.scratch_vm.modelData.textData[newName] = this.scratch_vm.modelData.textData[oldName];  //reset the runtime's model data with the new renamed label (to share with GUI)
        delete this.scratch_vm.modelData.textData[oldName];

        this.labelList.splice(this.labelList.indexOf(oldName), 1);  //reset label list with the new renamed label
        this.labelList.push(newName);
    }

    /**
     * TODO Delete an example (or all loaded examples, if exampleNum === -1)
     * @param {string} label the name of the label with the example to be removed
     * @param {integer} exampleNum which example, in the array of a label's examples, to remove
     */
    deleteExample(label, exampleNum) {
        console.log("Delete example " + exampleNum + " with label " + label);
        // Remove label from the runtime's model data (to share with the GUI)
        if (exampleNum === -1) {    //if this is true, delete all the loaded examples
            let numLoadedExamples = this.scratch_vm.modelData.classifierData[label].length - this.scratch_vm.modelData.textData[label].length;   //imageData[label].length is ONLY the length of the NEW examples (not the saved and then loaded ones!)
            this.scratch_vm.modelData.classifierData[label].splice(0, numLoadedExamples);
        } else {
            this.scratch_vm.modelData.textData[label].splice(exampleNum, 1);
            this.scratch_vm.modelData.classifierData[label].splice(exampleNum - this.scratch_vm.modelData.textData[label].length - 1, 1);
        }
    }

    /**
     * TODO Clear all data stored in the classifier and label list
     */
    clearLocal() {
        console.log("Clear local data");
        this.scratch_vm.emit("TOOLBOX_EXTENSIONS_NEED_UPDATE");
        this.labelList = [''];
        this.labelListEmpty = true;
    }

    resetModelData() {
        this.scratch_vm.modelData = { textData: {}, classifierData: {}, nextLabelNumber: 1 };
    }

    /**
     * TODO Clear local label list, but also clear all data stored in the runtime
     */
    clearAll() {
        console.log("Clear all data");
        this.clearLocal();
        // Clear runtime's model data

        this.resetModelData();
    }

    /**
     * TODO Clear all examples with a given label
     * @param {string} args.LABEL the name of the label to remove from the model
     */
    clearAllWithLabel(args) {
        console.log("Get rid of all examples with label " + args.LABEL);
        if (this.labelList.includes(args.LABEL)) {
            // Remove label from labelList
            this.labelList.splice(this.labelList.indexOf(args.LABEL), 1);
            // Remove label from the runtime's model data (to share with the GUI)
            delete this.scratch_vm.modelData.classifierData[args.LABEL];
            delete this.scratch_vm.modelData.textData[args.LABEL];
            // If the label list is now empty, fill it with an empty string
            if (this.labelList.length === 0) {
                this.labelListEmpty = true;
                this.labelList.push('');
            }
        }
    }

    /**
     * Stub function for determining the similarity between two words
     * @param args - TEXT_ONE and TEXT_TWO are the items to compare one another
     * @returns {float} value 0 (not at all similar) to 100 (very similar)
     */
    async getSimilarity(args) {
        if (!this._useModel) await this._loadUseModel();
        if (this._useModel) {
            const firstText = args.TEXT_ONE;
            const secondText = args.TEXT_TWO;

            // translates text from any language to english
            let newFirstText = await this.getTranslate(firstText, 'en');
            let newSecondText = await this.getTranslate(secondText, 'en');

            let firstEmbedding = await this._useModel.embed(newFirstText);
            let secondEmbedding = await this._useModel.embed(newSecondText);

            const distance = tf.losses.cosineDistance(firstEmbedding, secondEmbedding, 1).dataSync();
            this.similarity = 1 - distance[0];
            return this.similarity.toFixed(2) * 100;
        }
    }


    /**
     * Detects if the sound from the input mic is louder than a particular threshold
     * @param args.THRESHOLD {integer} the threshold of loudness to trigger on
     * @return {integer} true if the loudness is above the threshold and false if it is not
     */
    onHeardSound(args) {
        let threshold = args.THRESHOLD;

        return this.getLoudness() > threshold;
    }

    /**
     * Get the input volume from the mic
     * @return {integer} mic volume at current time
     */
    getLoudness() {
        if (typeof this.scratch_vm.audioEngine === 'undefined') return -1;
        if (this.scratch_vm.currentStepTime === null) return -1;

        // Only measure loudness once per step
        const timeSinceLoudness = this._timer.time() - this._cachedLoudnessTimestamp;
        if (timeSinceLoudness < this.scratch_vm.currentStepTime) {
            return this._cachedLoudness;
        }

        this._cachedLoudnessTimestamp = this._timer.time();
        this._cachedLoudness = this.scratch_vm.audioEngine.getLoudness();
        return this._cachedLoudness;
    }

    /**
     * Get the menu of voices for the "set voice" block.
     * @return {array} the text and value for each menu item.
     */
    getVoiceMenu() {
        return Object.keys(this.VOICE_INFO).map(voiceId => ({
            text: this.VOICE_INFO[voiceId].name,
            value: voiceId
        }));
    }

    /**
     * Set the voice for speech synthesis for this sprite.
     * @param  {object} args Block arguments
     * @param {object} util Utility object provided by the runtime.
     */
    setVoice(args, util) {
        const state = this._getState(util.target);

        let voice = args.VOICE;

        // If the arg is a dropped number, treat it as a voice index
        let voiceNum = parseInt(voice, 10);
        if (!isNaN(voiceNum)) {
            voiceNum -= 1; // Treat dropped args as one-indexed
            voiceNum = MathUtil.wrapClamp(voiceNum, 0, Object.keys(this.VOICE_INFO).length - 1);
            voice = Object.keys(this.VOICE_INFO)[voiceNum];
        }

        // Only set the voice if the arg is a valid voice id.
        if (Object.keys(this.VOICE_INFO).includes(voice)) {
            state.voiceId = voice;
        }
    }

    /**
     * Stop all currently playing speech sounds.
     */
    _stopAllSpeech() {
        this._soundPlayers.forEach(player => {
            player.stop();
        });
    }

    /**
     * Convert the provided text into a sound file and then play the file.
     * @param  {object} args Block arguments
     * @param {object} util Utility object provided by the runtime.
     * @return {Promise} A promise that resolves after playing the sound
     */
    async speakText(args, util) {
        // Cast input to string
        let words = Cast.toString(args.TEXT);
        let locale = 'en-US';

        const state = this._getState(util.target);

        let gender = this.VOICE_INFO[state.voiceId].gender;
        let playbackRate = this.VOICE_INFO[state.voiceId].playbackRate;

        // Build up URL
        let path = `${SERVER_HOST}/synth`;
        path += `?locale=${locale}`;
        path += `&gender=${gender}`;
        path += `&text=${encodeURIComponent(words.substring(0, 128))}`;
        // Perform HTTP request to get audio file
        return new Promise(resolve => {
            nets({
                url: path,
                timeout: SERVER_TIMEOUT
            }, (err, res, body) => {
                if (err) {
                    console.warn(err);
                    return resolve();
                }

                if (res.statusCode !== 200) {
                    console.warn(res.statusCode);
                    return resolve();
                }

                // Play the sound
                const sound = {
                    data: {
                        buffer: body.buffer
                    }
                };
                this.scratch_vm.audioEngine.decodeSoundPlayer(sound).then(soundPlayer => {
                    this._soundPlayers.set(soundPlayer.id, soundPlayer);

                    soundPlayer.setPlaybackRate(playbackRate);

                    // Increase the volume
                    const engine = this.scratch_vm.audioEngine;
                    const chain = engine.createEffectChain();
                    chain.set('volume', SPEECH_VOLUME);
                    soundPlayer.connect(chain);

                    soundPlayer.play();
                    soundPlayer.on('stop', () => {
                        this._soundPlayers.delete(soundPlayer.id);
                        resolve();
                    });
                });
            });
        });
    }

    recognizeSpeech() {
        let recognition = new webkitSpeechRecognition();
        let self = this;

        return new Promise(resolve => {
            recognition.start();
            recognition.onresult = function (event) {
                if (event.results.length > 0) {
                    self._recognizedSpeech = event.results[0][0].transcript;
                }
                resolve();
            };
        });
    }

    async askSpeechRecognition(args, util) {
        let prompt = Cast.toString(args.PROMPT);
        args.TEXT = prompt;
        await this.speakText(args, util);
        return this.recognizeSpeech();
    }

    getRecognizedSpeech() {
        return this._recognizedSpeech;
    }

    /**
     * A scratch conditional block that checks if a text example is a part of a particular class
     * @param {object} args - the block arguments
     * @param {BlockUtility} util - the block utility
     * @returns {boolean} true if the model matches
     *   reference
     */
    async ifTextMatchesClass(args, util) {
        const text = args.TEXT;
        const className = args.CLASS_NAME;
        const predictionState = await this.get_embeddings(text, "none", "predict");

        if (!predictionState) {
            return false;
        } else {
            const currentMaxClass = predictionState;
            return (currentMaxClass == String(className));
        }
    }

    /**
     * A scratch hat block reporter that returns whether the input text matches the model class.
     * @param {object} args - the block arguments
     * @param {BlockUtility} util - the block utility
     * @returns {string} class name if input text matched, empty string if there's a problem with the model
     */
    async getModelPrediction(args) {
        const text = args.TEXT;
        const predictionState = await this.get_embeddings(text, "none", "predict");
        return predictionState;
    }

    /**
     * A scratch hat block reporter that returns the confidance level of the input text matches the model class.
     * @param {object} args - the block arguments
     * @param {BlockUtility} util - the block utility
     * @returns {float} confidence of class name if input text matched, empty string if there's a problem with the model
     */
    async getModelConfidence(args) {
        const text = args.TEXT;
        const predictionConfidence = await this.get_confidence(text, "none", "predict");
        return predictionConfidence;
    }
    /**
     * Returns whether or not the text inputted is one of the examples inputted
     * @param text - the text inputted
     * @param className - the class whose examples are being checked
     * @returns a boolean true if the text is an example or false if the text is not an example
     */
    getPredictedClass(text, className) {
        if (!this.labelListEmpty) {   //whenever the classifier has some data
            try {
                for (let example of this.scratch_vm.modelData.textData[className]) {
                    if (text.toLowerCase() === example.toLowerCase()) {
                        return true;
                    }
                }
            } catch (err) {
                return false;
            }
        } else { //if there is no data in the classifier
            return false;
        }


    }

    /**
     * Calls the method which embeds text as a 2d tensor
     * @param text - the text inputted
     * @param label - this is always "none" when embedding examples
     * @param direction - is either "example" when an example is being inputted or "predict" when a word to be classified is inputted
     */
    // async getembeddedwords(text,label,direction) {
    //     if (!this.labelListEmpty) {
    //         const embeddedtext = await this.get_embeddings(text,label,direction);
    //     }
    // }


    /**
     * Embeds text and either adds examples to classifier or returns the predicted label
     * @param text - the text inputted
     * @param label - the label to add the example to
     * @param direction - is either "example" when an example is being inputted or "predict" when a word to be classified is inputted
     * @returns if the direction is "predict" returns the predicted label for the text inputted
     */
    async get_embeddings(text, label, direction) { //changes text into a 2d tensor
        const newText = await this.getTranslate(text, "en"); //translates text from any language to english
        console.log(newText);

        if (!this.labelListEmpty) {
            if (direction === "predict") {
                await this.predictScore(newText);
                return this.predictionClass;
            }
        } else {
            return "No classes inputted";

        }
    }

    /**
     * Embeds text and either adds examples to classifier or returns the predicted label
     * @param text - the text inputted
     * @param label - the label to add the example to
     * @param direction - is eitfher "example" when an example is being inputted or "predict" when a word to be classified is inputted
     * @returns if the direction is "predict" returns the predicted label for the text inputted
     */
    async get_confidence(text, label, direction) { //changes text into a 2d tensor
        const newText = await this.getTranslate(text, "en"); //translates text from any language to english
        console.log(newText);

        if (direction === "predict") {
            await this.predictScore(newText);
            return this.predictionScore;
        } else {
            return "No classes inputted";

        }
    }


    /**
     * Embeds text and either adds examples to classifier or returns the predicted label
     * @param text - the text inputted
     * @param label - the label to add the example to
     * @param direction - is either "example" when an example is being inputted or "predict" when a word to be classified is inputted
     * @returns if the direction is "predict" returns the predicted label for the text inputted
     */
    async buildCustomDeepModel() {
        var numClass = this.labelList.length;

        if (numClass < 2) {
            return "No classes inputted";
        }

        //console.log(this.scratch_vm)
        this.scratch_vm.emit('SAY', this.scratch_vm.executableTargets[1], 'think', 'wait .. loading model');

        // console.log(this.labelList)
        this.custom_NLP_model = tf.sequential();
        this.sentencesample = [];
        this.labledsample = [];
        for (let label of this.labelList) {
            //console.log(this.scratch_vm.modelData.textData[label])
            for (let sentense of this.scratch_vm.modelData.textData[label]) {
                //console.log(sentense)
                this.sentencesample.push(sentense);
                this.labledsample.push(label);
            }
        }
        console.log(this.labledsample)
        console.log(this.sentencesample)


        // console.log('model::'+JSON.stringify(this.custom_NLP_model));
        const ys = tf.oneHot(tf.tensor1d(this.labledsample.map((a) =>
            this.labelList.findIndex(e => e === a)), 'int32'), numClass);
        // console.log('ys',ys);

        let trainingData;
        try {
            if (!this.useModel) await this._loadUseModel();
            trainingData = await this._useModel.embed(this.sentencesample);
        } catch (err) {
            console.error('Fit Error:', err);
        }
        // console.log(trainingData)

        // Add layers to the model
        this.custom_NLP_model.add(tf.layers.dense({
            inputShape: [512],
            activation: 'sigmoid',
            kernelInitializer: 'ones',
            units: numClass,//number of label classes
        }));

        // Compile the model
        this.custom_NLP_model.compile({
            loss: 'meanSquaredError',
            optimizer: tf.train.adam(.06), // This is a standard compile config
        });
        // this.custom_NLP_model.compile({
        //     loss: 'categoricalCrossentropy', 
        //     optimizer: 'sgd', 
        //     metrics: ['acc']
        // });


        let info = await this.custom_NLP_model.fit(trainingData, ys, {
            epochs: 100,
            batchSize: 4,
            shuffle: true,
            validationSplit: 0.15,
            doValidation: true,
            callbacks: [
                tf.callbacks.earlyStopping({ monitor: 'val_loss', patience: 50 })
            ]
        });
        console.log('Final accuracy', info);
        console.log('model is trained')

        this.scratch_vm.emit('SAY', this.scratch_vm.executableTargets[1], 'say', 'The model is ready');
    }

    /**
     * Embeds text and either adds examples to classifier or returns the predicted label
     * @param text - the text inputted
     * @param label - the label to add the example to
     * @param direction - is either "example" when an example is being inputted or "predict" when a word to be classified is inputted
     * @returns if the direction is "predict" returns the predicted label for the text inputted
     */
    async predictScore(text) {
        // TODO: check if already got the predection
        if (this.lastSentenceClassified === text) {
            console.log('Classification done')
            console.log('Predicted Label', this.predictionLabel);
            console.log('Predicted Class', this.predictionClass);
            console.log('Predicted Score', this.predictionScore);
            return "elready done."
        }
        else {
            this.lastSentenceClassified = text;
        }

        if (this.custom_NLP_model.layers.length === 0) {
            await this.buildCustomDeepModel();
        }

        // TODO: early stopping  
        // var test_ex = ['great','nope','yes','no']
        //var test_ex = ["sorry , that is not true","yes sir","i am uncertain","please say it again"]
        //var test_ex = ["i really do not have a clue"]
        console.log(text)
        let test_ex = [text]
        let testData;
        try {
            if (!this._useModel) await this._loadUseModel();
            testData = await this._useModel.embed(test_ex);
        } catch (err) {
            console.error('Fit Error:', err); return;

        }
        // console.log(testData)
        // this.output = await this.custom_NLP_model.predict(testData);
        await this.custom_NLP_model.predict(testData).print();
        // console.log(this.output);

        const prediction = await this.custom_NLP_model.predict(testData);
        const predict = await prediction.data()
        this.predictionLabel = await prediction.as1D().argMax().dataSync()[0];
        this.predictionClass = this.labelList[this.predictionLabel];
        this.predictionScore = predict[this.predictionLabel];

        console.log('Predicted Label', this.predictionLabel);
        console.log('Predicted Class', this.predictionClass);
        console.log('Predicted Score', this.predictionScore);
    }
    /**
      * Exports the labels and examples in the form of a json document with the default name of "classifier-info.json"
      */
    exportClassifier() { //exports classifier as JSON file
        let dataset = this.scratch_vm.modelData.textData;
        let jsonStr = JSON.stringify(dataset);
        //exports json file
        var data = "text/json;charset=utf-8," + encodeURIComponent(jsonStr);
        var a = document.createElement('a');
        a.setAttribute("href", "data:" + data);
        a.setAttribute("download", "classifier-info.json");
        a.click();
    }
    /**
      * Loads the json document which contains labels and examples. Inputs the labels and examples into the classifier
      */
    async loadClassifier() { //loads classifier to project
        var self = this
        var dataset = document.getElementById("imported-classifier").files[0];
        if (dataset !== undefined) {
            fr = new FileReader();
            fr.onload = receivedText;
            await fr.readAsText(dataset);
            await this.buildCustomDeepModel();
        }

        function receivedText(e) { //parses through the json document and adds to the model textData and classifier
            let lines = e.target.result;
            try {
                var newArr = JSON.parse(lines);
                self.clearAll();
                for (let label in newArr) {
                    if (newArr.hasOwnProperty(label)) {
                        let textExamples = newArr[label];
                        self.newLabel(label);
                        self.newExamples(textExamples, label);
                    }
                }
            } catch (err) {
                console.log("Incorrect document form");
            }

        }
    }

    getTranslate(words, language) {
        // Don't remake the request if we already have the value.
        if (this._lastTextTranslated === words &&
            this._lastLangTranslated === language) {
            return this._translateResult;
        }

        const lang = language;

        let urlBase = `${serverURL}translate?language=`;
        urlBase += lang;
        urlBase += '&text=';
        urlBase += encodeURIComponent(words);

        const tempThis = this;
        const translatePromise = new Promise(resolve => {
            nets({
                url: urlBase,
                timeout: serverTimeoutMs
            }, (err, res, body) => {
                if (err) {
                    log.warn(`error fetching translate result! ${res}`);
                    resolve('');
                    return '';
                }
                const translated = JSON.parse(body).result;
                tempThis._translateResult = translated;
                // Cache what we just translated so we don't keep making the
                // same call over and over.
                tempThis._lastTextTranslated = words;
                tempThis._lastLangTranslated = language;
                resolve(translated);
                return translated;
            });

        });
        translatePromise.then(translatedText => translatedText);
        return translatePromise;
    }


    async confidenceTrue(args) {
        return await this._classifyText(args.TEXT, args.LABEL, true);
    }
    async confidenceFalse(args) {
        return await this._classifyText(args.TEXT, args.LABEL, false);
    }

    //-----------------------------------------------------------------------

    /*_loadToxicity() {
        var id = 'script-toxicity';
        if (document.getElementById(id)) {
            console.log('Toxicity script already loaded');
        }
        else {
            let scriptObj = document.createElement('script');
            scriptObj.id = id;
            scriptObj.type = 'text/javascript';
            scriptObj.src = 'https://cdn.jsdelivr.net/npm/@tensorflow-models/toxicity';

            scriptObj.onreadystatechange = this._loadToxicityModel.bind(this);
            scriptObj.onload = this._loadToxicityModel.bind(this);

            document.head.appendChild(scriptObj);
        }
    }*/

    async _loadToxicityModel() {
        if (this._toxicitymodel) {
            console.log('Toxicity model already loaded');
        }
        else {
            console.log('loading Toxicity model');
            const threshold = 0.1;

            try {
                this._toxicityModel = await toxicity.load(threshold, this._toxicity_labels.items.map(lbl => lbl.value))
                console.log('loaded Toxicity model');
            } catch (err) {
                console.log('Failed to load toxicity model', err);
            };
        }
    }

    async _loadUseModel() {
        if (this._useModel) {
            console.log('Universal sentence encoder model already loaded');
        } else {
            console.log('Loading Universal Sentence Encoder model');
            try {
                this._useModel = await use.load();
                console.log('Loaded Universal sentence encoder model');
            } catch (e) {
                console.log('Failed to load universal sentence encoder model');
                console.error(e);
            }
        }
    }

    //-----------------------------------------------------------------------

    async _classifyText(text, label, returnPositive) {
        if (!this._toxicityModel) await this._loadToxicityModel();

        if (this._toxicityModel && text && label) {
            return this._toxicitymodel.classify([text])
                .then((predictions) => {
                    const filtered = predictions.filter(prediction => prediction.label === label);
                    if (filtered && filtered.length === 1 &&
                        filtered[0].results && filtered[0].results.length > 0) {
                        const idx = returnPositive ? 1 : 0;
                        return Math.round(filtered[0].results[0].probabilities[idx] * 100);
                    }
                    return 0;
                })
                .catch((err) => {
                    console.log('Failed to classify text', err);
                });
        }
    }


    /**
     * chech sentiment score of a text 
     * @param text - the text inputted
     * @returns predicted acore for the text inputted -5 (negative) to 5 (positive)
     */
    async sentimentScore(text) {
        console.log(text.TEXT);
        console.log(this.sentiment.analyze(text.TEXT))
        this.predictedsentimentScore = this.sentiment.analyze(text.TEXT)
        return this.predictedsentimentScore.comparative;
    }

    getItemOfArray(item, array) {
        if (item === 'first') {
            return array[0];
        } else if (item === 'last') {
            return array[array.length - 1];
        } else if (item === 'random') {
            let randomIdx = Math.floor(Math.random() * array.length);
            return array[randomIdx];
        } else if (item === 'all') {
            return array.join(' ');
        }
        let wordIdx = Number.parseInt(item);
        if (wordIdx && wordIdx > 0) {
            if (wordIdx <= array.length) return array[wordIdx - 1];
        }
        return "";
    }

    getWordInString(args) {
        let splitText = this.splitText(args.TEXT);
        return this.getItemOfArray(args.NUM, splitText);
    }

    splitText(inputText) {
        let words = inputText
            .replace(/[^\w\s\'\-]|_/g, "") // don't erase apostrophes and dashes
            .replace(/\s+/g, " ") // remove extra spaces
            .split(/[\s']+/); // split on spaces and apostrophes
        return words;
    }

    tagMatchesPOS(tag, partOfSpeech) {
        let posRules = _partsOfSpeech[partOfSpeech];

        for (let j = 0; j < posRules.length; j++) {
            if (tag.startsWith(posRules[j])) return true;
        }

        return false;
    }

    // turn number words into values (e.g. "twenty" to 20)
    // if it cannot be converted, return original string
    convertStringToNum(inputText) {
        let convertToNum = wordsToNumbers(inputText);

        if (convertToNum) return convertToNum;
        return inputText;
    }

    textContainsPartOfSpeech(args) {
        args.NUM = "1";
        return this.getPartOfSpeech(args) !== "";
    }
    getPartOfSpeech(args) {
        let words = this.splitText(args.TEXT);
        let tags = new Tag(words).initial().smooth().tags;
        let matches = [];
        // loop through tagged words and return matches
        for (let i = 0; i < tags.length; i++) {
            let tag = tags[i];

            if (this.tagMatchesPOS(tag, args.POS)) {
                if (args.POS == "number") matches.push(this.convertStringToNum(words[i]));
                else matches.push(words[i]);
            }
        }
        return this.getItemOfArray(args.NUM, matches);
    }

    textContainsWordsLike(args) {
        args.NUM = "1";
        return this.getWordsLike(args) !== "";
    }
    getWordsLike(args) {
        // user can past name of list or a string
        let targetWords = targetWords = args.LIST.toLowerCase().split(" ");
        let splitText = this.splitText(args.TEXT);
        let matches = [];

        for (let i = 0; i < splitText.length; i++) {
            if (targetWords.includes(splitText[i].toLowerCase())) {
                matches.push(splitText[i].toLowerCase());
            }
        }
        return this.getItemOfArray(args.NUM, matches);
    }


}

module.exports = Scratch3TextClassificationBlocks;
