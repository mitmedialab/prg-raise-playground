/*
 * Resources:
 *  - Text to speech extension written by Scratch Team 2019
 *  - Speech to text extension written by Sayamindu Dasgupta <sayamindu@media.mit.edu>, April 2014
 *  - Knn Classifier model written by Katya3141 https://katya3141.github.io/scratch-gui/teachable-classifier/ August 2019
 */

require("regenerator-runtime/runtime");
const Runtime = require('../../engine/runtime');
const nets = require('nets');
const MathUtil = require('../../util/math-util');

const ArgumentType = require('../../extension-support/argument-type');
const BlockType = require('../../extension-support/block-type');
const Clone = require('../../util/clone');
const Cast = require('../../util/cast');
const formatMessage = require('format-message');
const Video = require('../../io/video');
const Timer = require('../../util/timer');
const tf = require('@tensorflow/tfjs');
const knnClassifier = require('@tensorflow-models/knn-classifier');
const use = require('@tensorflow-models/universal-sentence-encoder');


/**
 * Icon svg to be displayed in the blocks category menu, encoded as a data URI.
 * @type {string}
 */
// eslint-disable-next-line max-len
const menuIconURI = 'data:image/svg+xml;base64,<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<svg
   xmlns:dc="http://purl.org/dc/elements/1.1/"
   xmlns:cc="http://creativecommons.org/ns#"
   xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
   xmlns:svg="http://www.w3.org/2000/svg"
   xmlns="http://www.w3.org/2000/svg"
   xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
   id="Layer_1_1_"
   enable-background="new 0 0 64 64"
   height="72.780205"
   viewBox="0 0 9.1991234 9.0975256"
   width="73.592987"
   version="1.1"
   inkscape:version="0.48.4 r9939"
   sodipodi:docname="text-classification-blocks-menu.svg">
  <metadata
     id="metadata21">
    <rdf:RDF>
      <cc:Work
         rdf:about="">
        <dc:format>image/svg+xml</dc:format>
        <dc:type
           rdf:resource="http://purl.org/dc/dcmitype/StillImage" />
        <dc:title></dc:title>
      </cc:Work>
    </rdf:RDF>
  </metadata>
  <defs
     id="defs19" />
  <sodipodi:namedview
     pagecolor="#ffffff"
     bordercolor="#666666"
     borderopacity="1"
     objecttolerance="10"
     gridtolerance="10"
     guidetolerance="10"
     inkscape:pageopacity="0"
     inkscape:pageshadow="2"
     inkscape:window-width="1007"
     inkscape:window-height="783"
     id="namedview17"
     showgrid="false"
     fit-margin-top="0"
     fit-margin-left="0"
     fit-margin-right="0"
     fit-margin-bottom="0"
     inkscape:zoom="10.429825"
     inkscape:cx="44.912112"
     inkscape:cy="33.108471"
     inkscape:window-x="627"
     inkscape:window-y="178"
     inkscape:window-maximized="0"
     inkscape:current-layer="Layer_1_1_" />
  <path
     sodipodi:type="arc"
     style="fill:#aaffcc;fill-opacity:1;stroke:#00aa44"
     id="path2993"
     sodipodi:cx="-4.3624892"
     sodipodi:cy="28.581223"
     sodipodi:rx="32.934399"
     sodipodi:ry="32.934399"
     d="m 28.571909,28.581223 a 32.934399,32.934399 0 1 1 -65.868797,0 32.934399,32.934399 0 1 1 65.868797,0 z"
     transform="matrix(0.13755698,0,0,0.13610137,5.2013733,0.65924101)" />
  <path
     d="m 2.9791233,6.137428 c 0,0.139175 -0.03202,0.269729 -0.09114,0.385503 -0.140407,0.283277 -0.433537,0.476644 -0.771006,0.476644 -0.476644,0 -0.862147,-0.385503 -0.862147,-0.862147 0,-0.476644 0.385503,-0.862147 0.862147,-0.862147 0.173661,0 0.333774,0.0505 0.468023,0.137943 0.237706,0.153955 0.394124,0.419989 0.394124,0.724204 z"
     id="path3"
     inkscape:connector-curvature="0"
     style="fill:#000080;fill-opacity:1" />
  <path
     d="m 7.5002307,3.8572393 c 0.476644,0 0.862147,0.385503 0.862147,0.862147 0,0.476644 -0.385503,0.862147 -0.862147,0.862147 -0.231548,0 -0.440926,-0.08991 -0.594881,-0.24017 -0.16504,-0.155186 -0.267266,-0.376881 -0.267266,-0.621977 0,-0.03941 0.0025,-0.07759 0.0086,-0.115774 0.02463,-0.192136 0.113311,-0.363334 0.243864,-0.493887 0.156418,-0.156418 0.370723,-0.252486 0.609661,-0.252486 z"
     id="path7"
     inkscape:connector-curvature="0"
     style="fill:#000080" />
  <path
     style="fill:#000080;fill-opacity:1;stroke:none"
     d="M 1.6842184,3.641441 C 1.2629901,3.3627243 1.2006396,2.7462127 1.5557106,2.3707757 1.9022591,2.0043501 2.4951785,2.0633456 2.7794918,2.4925419 3.2449268,3.1951577 2.3803563,4.1020583 1.6842184,3.641441 z"
     id="path2988"
     inkscape:connector-curvature="0" />
  <path
     style="fill:#000080;fill-opacity:1;stroke:none"
     d="M 4.3049044,2.5776682 C 4.0127706,2.3282715 3.9342559,2.0011231 4.0810112,1.6447697 4.3064184,1.0974329 4.9784113,0.92659387 5.3886513,1.3123316 6.1978274,2.0731787 5.1487365,3.2980525 4.3049044,2.5776682 z"
     id="path2990"
     inkscape:connector-curvature="0" />
  <path
     style="fill:#000080;fill-opacity:1;stroke:none"
     d="M 4.3784972,4.9757011 C 3.8278365,4.6409554 3.8928456,3.8504273 4.4938182,3.5733694 4.866088,3.4017469 5.2893822,3.5302824 5.5101175,3.8819738 5.7301862,4.2326033 5.7089766,4.5244492 5.4425609,4.8115608 5.1456488,5.1315377 4.7382343,5.1943846 4.3784972,4.9757011 z"
     id="path2992"
     inkscape:connector-curvature="0" />
  <path
     style="fill:#000080;fill-opacity:1;stroke:none"
     d="M 4.3246268,7.9820751 C 4.0366848,7.7379754 3.9592965,7.4177752 4.1039462,7.0689904 4.326119,6.5332782 4.9884695,6.3660676 5.392823,6.7436128 6.1903885,7.4883005 5.1563507,8.6871597 4.3246268,7.9820751 z"
     id="path2994"
     inkscape:connector-curvature="0" />
  <path
     style="fill:#f6db40;fill-opacity:1;stroke:none"
     d=""
     id="path3001"
     inkscape:connector-curvature="0" />
  <path
     d="m 2.5436163,5.250648 c -0.129322,-0.06244 -0.27367,-0.09853 -0.42664,-0.09853 -0.543275,0 -0.985311,0.442035 -0.985311,0.985311 0,0.543276 0.442036,0.985311 0.985311,0.985311 0.340918,0 0.641807,-0.174154 0.818793,-0.438094 l 0.93075,0.465929 c -0.01601,0.07033 -0.02525,0.143362 -0.02525,0.218492 0,0.543276 0.442035,0.985311 0.985311,0.985311 0.543275,0 0.98531,-0.442035 0.98531,-0.985311 0,-0.204205 -0.06244,-0.394001 -0.16935,-0.551527 l 1.307877,-1.367489 c 0.164054,0.121686 0.366289,0.194722 0.585767,0.194722 0.543276,0 0.985311,-0.442035 0.985311,-0.98531 0,-0.543276 -0.442035,-0.985311 -0.985311,-0.985311 -0.22736,0 -0.436246,0.07809 -0.603256,0.207901 L 5.6039903,2.553115 c 0.129815,-0.16701 0.2079,-0.375896 0.2079,-0.603257 0,-0.543275 -0.442035,-0.98531102 -0.98531,-0.98531102 -0.543276,0 -0.985311,0.44203602 -0.985311,0.98531102 0,0.07488 0.0091,0.147674 0.02512,0.217877 L 2.9929113,2.48599 C 2.8292333,2.168104 2.4984153,1.949857 2.1169763,1.949857 c -0.543275,0 -0.985311,0.442035 -0.985311,0.985311 0,0.543276 0.442036,0.985311 0.985311,0.985311 0.140161,0 0.273301,-0.02981 0.394125,-0.08289 l 0.453366,0.763 z m -0.42664,1.625763 c -0.407549,0 -0.738983,-0.331434 -0.738983,-0.738983 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.407549 -0.331434,0.738983 -0.738983,0.738983 z m 0.928532,-0.412476 c 0.03609,-0.102349 0.05678,-0.211965 0.05678,-0.326507 0,-0.302121 -0.136958,-0.572589 -0.351633,-0.753393 l 0.354219,-0.547094 1.067954,1.797083 c -0.08991,0.08006 -0.165163,0.175878 -0.220956,0.283647 z m 1.781073,-3.528767 c 0.22736,0 0.436246,-0.07809 0.603256,-0.207901 l 1.329061,1.329061 c -0.07969,0.102473 -0.139298,0.220833 -0.173661,0.349663 L 5.8115223,4.299577 c -1.23e-4,-0.0032 3.69e-4,-0.0064 3.69e-4,-0.0096 0,-0.543275 -0.442035,-0.985311 -0.98531,-0.985311 -0.340918,0 -0.64193,0.174154 -0.818793,0.438094 L 3.8608533,3.66935 4.4000643,2.836639 c 0.129199,0.06244 0.273547,0.09853 0.426517,0.09853 z m 0.123164,3.457086 V 5.266659 c 0.400282,-0.05025 0.725927,-0.341163 0.827907,-0.723218 l 0.773715,0.106414 c 0,0.0032 -4.92e-4,0.0064 -4.92e-4,0.0096 0,0.235243 0.08301,0.451149 0.221079,0.620746 L 5.4787333,6.632416 C 5.3337693,6.503956 5.1513643,6.417619 4.9497453,6.392247 z M 4.8265813,3.550987 c 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.407549 -0.331434,0.738983 -0.738983,0.738983 -0.407549,0 -0.738983,-0.331434 -0.738983,-0.738983 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 z m -0.928532,0.412476 c -0.03609,0.102349 -0.05678,0.211965 -0.05678,0.326507 0,0.501523 0.376881,0.915847 0.862147,0.976813 v 1.125594 c -0.116759,0.01466 -0.226991,0.04964 -0.32737,0.101487 L 3.2542703,4.606132 3.7261113,3.877495 z m 0.928532,4.144586 c -0.407549,0 -0.738983,-0.331434 -0.738983,-0.738983 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.407549 -0.331434,0.738983 -0.738983,0.738983 z m 2.709604,-4.18757 c 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.407549 -0.331434,0.738983 -0.738983,0.738983 -0.407549,0 -0.738983,-0.331434 -0.738983,-0.738983 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 z M 4.8265813,1.210874 c 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.407549 -0.331434,0.738983 -0.738983,0.738983 -0.407549,0 -0.738983,-0.331434 -0.738983,-0.738983 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 z m -0.875818,1.188162 c 0.06023,0.116882 0.142623,0.220217 0.242263,0.304214 L 3.6392813,3.5585 3.0456323,3.261675 c 0.03596,-0.102349 0.05665,-0.211965 0.05665,-0.326507 0,-0.07488 -0.0091,-0.147673 -0.02512,-0.217877 z m -2.57277,0.536132 c 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.407549 -0.331434,0.738983 -0.738983,0.738983 -0.407549,0 -0.738983,-0.331434 -0.738983,-0.738983 z m 1.344334,0.775809 c 0.08252,-0.06454 0.15494,-0.141392 0.213442,-0.228592 l 0.568648,0.284262 -0.390553,0.603133 z"
     id="path15"
     inkscape:connector-curvature="0"
     style="fill:#000000" />
</svg>
';

/**
 * Icon svg to be displayed at the left edge of each extension block, encoded as a data URI.
 * @type {string}
 */
// eslint-disable-next-line max-len
const blockIconURI = 'data:image/svg+xml;base64,<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<svg
   xmlns:dc="http://purl.org/dc/elements/1.1/"
   xmlns:cc="http://creativecommons.org/ns#"
   xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
   xmlns:svg="http://www.w3.org/2000/svg"
   xmlns="http://www.w3.org/2000/svg"
   xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
   id="Layer_1_1_"
   enable-background="new 0 0 64 64"
   height="59.118649"
   viewBox="0 0 7.3898301 7.3898311"
   width="59.118641"
   version="1.1"
   inkscape:version="0.48.4 r9939"
   sodipodi:docname="text-classification-blocks-small.svg">
  <metadata
     id="metadata21">
    <rdf:RDF>
      <cc:Work
         rdf:about="">
        <dc:format>image/svg+xml</dc:format>
        <dc:type
           rdf:resource="http://purl.org/dc/dcmitype/StillImage" />
        <dc:title></dc:title>
      </cc:Work>
    </rdf:RDF>
  </metadata>
  <defs
     id="defs19" />
  <sodipodi:namedview
     pagecolor="#ffffff"
     bordercolor="#666666"
     borderopacity="1"
     objecttolerance="10"
     gridtolerance="10"
     guidetolerance="10"
     inkscape:pageopacity="0"
     inkscape:pageshadow="2"
     inkscape:window-width="1007"
     inkscape:window-height="783"
     id="namedview17"
     showgrid="false"
     fit-margin-top="0"
     fit-margin-left="0"
     fit-margin-right="0"
     fit-margin-bottom="0"
     inkscape:zoom="7.375"
     inkscape:cx="40.244264"
     inkscape:cy="27.374394"
     inkscape:window-x="627"
     inkscape:window-y="178"
     inkscape:window-maximized="0"
     inkscape:current-layer="Layer_1_1_" />
  <path
     d="m 1.847458,5.172881 c 0,0.139175 -0.03202,0.269729 -0.09114,0.385503 -0.140407,0.283277 -0.433537,0.476644 -0.771006,0.476644 -0.476644,0 -0.862147,-0.385503 -0.862147,-0.862147 0,-0.476644 0.385503,-0.862147 0.862147,-0.862147 0.173661,0 0.333774,0.0505 0.468023,0.137943 0.237706,0.153955 0.394124,0.419989 0.394124,0.724204 z"
     id="path3"
     inkscape:connector-curvature="0"
     style="fill:#000080;fill-opacity:1" />
  <path
     d="m 6.3685654,2.8926923 c 0.476644,0 0.862147,0.385503 0.862147,0.862147 0,0.476644 -0.385503,0.862147 -0.862147,0.862147 -0.231548,0 -0.440926,-0.08991 -0.594881,-0.24017 -0.16504,-0.155186 -0.267266,-0.376881 -0.267266,-0.621977 0,-0.03941 0.0025,-0.07759 0.0086,-0.115774 0.02463,-0.192136 0.113311,-0.363334 0.243864,-0.493887 0.156418,-0.156418 0.370723,-0.252486 0.609661,-0.252486 z"
     id="path7"
     inkscape:connector-curvature="0"
     style="fill:#000080" />
  <path
     style="fill:#000080;fill-opacity:1;stroke:none"
     d="M 0.5525531,2.676894 C 0.1313248,2.3981773 0.0689743,1.7816657 0.4240453,1.4062287 0.7705938,1.0398031 1.3635132,1.0987986 1.6478265,1.5279949 2.1132615,2.2306107 1.248691,3.1375113 0.5525531,2.676894 z"
     id="path2988"
     inkscape:connector-curvature="0" />
  <path
     style="fill:#000080;fill-opacity:1;stroke:none"
     d="M 3.1732391,1.6131212 C 2.8811053,1.3637245 2.8025906,1.0365761 2.9493459,0.68022271 3.1747531,0.13288591 3.846746,-0.03795312 4.256986,0.34778461 5.0661621,1.1086317 4.0170712,2.3335055 3.1732391,1.6131212 z"
     id="path2990"
     inkscape:connector-curvature="0" />
  <path
     style="fill:#000080;fill-opacity:1;stroke:none"
     d="M 3.2468319,4.0111541 C 2.6961712,3.6764084 2.7611803,2.8858803 3.3621529,2.6088224 3.7344227,2.4371999 4.1577169,2.5657354 4.3784522,2.9174268 4.5985209,3.2680563 4.5773113,3.5599022 4.3108956,3.8470138 4.0139835,4.1669907 3.606569,4.2298376 3.2468319,4.0111541 z"
     id="path2992"
     inkscape:connector-curvature="0" />
  <path
     style="fill:#000080;fill-opacity:1;stroke:none"
     d="M 3.1929615,7.0175281 C 2.9050195,6.7734284 2.8276312,6.4532282 2.9722809,6.1044434 3.1944537,5.5687312 3.8568042,5.4015206 4.2611577,5.7790658 5.0587232,6.5237535 4.0246854,7.7226127 3.1929615,7.0175281 z"
     id="path2994"
     inkscape:connector-curvature="0" />
  <path
     style="fill:#f6db40;fill-opacity:1;stroke:none"
     d=""
     id="path3001"
     inkscape:connector-curvature="0" />
  <path
     d="M 1.411951,4.286101 C 1.282629,4.223661 1.138281,4.187571 0.985311,4.187571 0.442036,4.187571 0,4.629606 0,5.172882 c 0,0.543276 0.442036,0.985311 0.985311,0.985311 0.340918,0 0.641807,-0.174154 0.818793,-0.438094 l 0.93075,0.465929 c -0.01601,0.07033 -0.02525,0.143362 -0.02525,0.218492 0,0.543276 0.442035,0.985311 0.985311,0.985311 0.543275,0 0.98531,-0.442035 0.98531,-0.985311 0,-0.204205 -0.06244,-0.394001 -0.16935,-0.551527 L 5.818752,4.485504 c 0.164054,0.121686 0.366289,0.194722 0.585767,0.194722 0.543276,0 0.985311,-0.442035 0.985311,-0.98531 0,-0.543276 -0.442035,-0.985311 -0.985311,-0.985311 -0.22736,0 -0.436246,0.07809 -0.603256,0.207901 L 4.472325,1.588568 C 4.60214,1.421558 4.680225,1.212672 4.680225,0.98531101 4.680225,0.44203601 4.23819,0 3.694915,0 3.151639,0 2.709604,0.44203601 2.709604,0.98531101 c 0,0.07488 0.0091,0.14767399 0.02512,0.21787699 L 1.861246,1.521443 C 1.697568,1.203557 1.36675,0.98531001 0.985311,0.98531001 0.442036,0.98531001 0,1.427345 0,1.970621 c 0,0.543276 0.442036,0.985311 0.985311,0.985311 0.140161,0 0.273301,-0.02981 0.394125,-0.08289 l 0.453366,0.763 z m -0.42664,1.625763 c -0.407549,0 -0.738983,-0.331434 -0.738983,-0.738983 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.407549 -0.331434,0.738983 -0.738983,0.738983 z M 1.913843,5.499388 C 1.949933,5.397039 1.970623,5.287423 1.970623,5.172881 1.970623,4.87076 1.833665,4.600292 1.61899,4.419488 L 1.973209,3.872394 3.041163,5.669477 C 2.951253,5.749537 2.876,5.845355 2.820207,5.953124 z M 3.694916,1.970621 c 0.22736,0 0.436246,-0.07809 0.603256,-0.207901 L 5.627233,3.091781 C 5.547543,3.194254 5.487935,3.312614 5.453572,3.441444 L 4.679857,3.33503 c -1.23e-4,-0.0032 3.69e-4,-0.0064 3.69e-4,-0.0096 0,-0.543275 -0.442035,-0.985311 -0.98531,-0.985311 -0.340918,0 -0.64193,0.174154 -0.818793,0.438094 L 2.729188,2.704803 3.268399,1.872092 c 0.129199,0.06244 0.273547,0.09853 0.426517,0.09853 z M 3.81808,5.427707 V 4.302112 C 4.218362,4.251862 4.544007,3.960949 4.645987,3.578894 l 0.773715,0.106414 c 0,0.0032 -4.92e-4,0.0064 -4.92e-4,0.0096 0,0.235243 0.08301,0.451149 0.221079,0.620746 L 4.347068,5.667869 C 4.202104,5.539409 4.019699,5.453072 3.81808,5.4277 z M 3.694916,2.58644 c 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.407549 -0.331434,0.738983 -0.738983,0.738983 -0.407549,0 -0.738983,-0.331434 -0.738983,-0.738983 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 z M 2.766384,2.998916 c -0.03609,0.102349 -0.05678,0.211965 -0.05678,0.326507 0,0.501523 0.376881,0.915847 0.862147,0.976813 V 5.42783 C 3.454992,5.44249 3.34476,5.47747 3.244381,5.529317 L 2.122605,3.641585 2.594446,2.912948 z m 0.928532,4.144586 c -0.407549,0 -0.738983,-0.331434 -0.738983,-0.738983 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.407549 -0.331434,0.738983 -0.738983,0.738983 z M 6.40452,2.955932 c 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.407549 -0.331434,0.738983 -0.738983,0.738983 -0.407549,0 -0.738983,-0.331434 -0.738983,-0.738983 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 z M 3.694916,0.24632701 c 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.40754899 -0.331434,0.73898299 -0.738983,0.73898299 -0.407549,0 -0.738983,-0.331434 -0.738983,-0.73898299 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 z M 2.819098,1.434489 c 0.06023,0.116882 0.142623,0.220217 0.242263,0.304214 L 2.507616,2.593953 1.913967,2.297128 c 0.03596,-0.102349 0.05665,-0.211965 0.05665,-0.326507 0,-0.07488 -0.0091,-0.147673 -0.02512,-0.217877 z m -2.57277,0.536132 c 0,-0.407549 0.331434,-0.738983 0.738983,-0.738983 0.407549,0 0.738983,0.331434 0.738983,0.738983 0,0.407549 -0.331434,0.738983 -0.738983,0.738983 -0.407549,0 -0.738983,-0.331434 -0.738983,-0.738983 z M 1.590662,2.74643 C 1.673182,2.68189 1.745602,2.605038 1.804104,2.517838 L 2.372752,2.8021 1.982199,3.405233 z"
     id="path15"
     inkscape:connector-curvature="0"
     style="fill:#000000" />
</svg>
';

/**
 * The url of the synthesis server.
 * @type {string}
 */
const SERVER_HOST = 'https://synthesis-service.scratch.mit.edu';

/**
 * The url of the translate server.
 * @type {string}
 */
const serverURL = 'https://translate-service.scratch.mit.edu/';

/**
 * How long to wait in ms before timing out requests to translate server.
 * @type {int}
 */
const serverTimeoutMs = 10000; // 10 seconds (chosen arbitrarily).


/**
 * How long to wait in ms before timing out requests to synthesis server.
 * @type {int}
 */
const SERVER_TIMEOUT = 10000; // 10 seconds

/**
 * Volume for playback of speech sounds, as a percentage.
 * @type {number}
 */
const SPEECH_VOLUME = 250;

/**
 * An id for one of the voices.
 */
const ALTO_ID = 'ALTO';

/**
 * An id for one of the voices.
 */
const TENOR_ID = 'TENOR';

/**
 * An id for one of the voices.
 */
const SQUEAK_ID = 'SQUEAK';

/**
 * An id for one of the voices.
 */
const GIANT_ID = 'GIANT';

/**
 * Playback rate for the tenor voice, for cases where we have only a female gender voice.
 */
const FEMALE_TENOR_RATE = 0.89; // -2 semitones

/**
 * Playback rate for the giant voice, for cases where we have only a female gender voice.
 */
const FEMALE_GIANT_RATE = 0.79; // -4 semitones



/**
 * Class for the motion-related blocks in Scratch 3.0
 * @param {Runtime} runtime - the runtime instantiating this block package.
 * @constructor
 */
class Scratch3TextClassificationBlocks {
    constructor (runtime) {

         /**
         * The result from the most recent translation.
         * @type {string}
         * @private
         */
        this._translateResult = '';

        /**
         * The language of the text most recently translated.
         * @type {string}
         * @private
         */
        this._lastLangTranslated = '';

        /**
         * The text most recently translated.
         * @type {string}
         * @private
         */
        this._lastTextTranslated = '';

        /**
         * The runtime instantiating this block package.
         * @type {Runtime}
         */
         this.scratch_vm = runtime;
         this.predictedLabel=null;
         //this.mobilenetModule = null;
         this.classifier = knnClassifier.create();
         this.embedding = null;
         this.count = 0;
         this.classifiedData = null;
         this.confidence = 0;
         this.classifiedData = null;   
         this.exampleEmbeddings = {};
         this.lastEmbedding = {};
                 
        /**
         * The timer utility.
         * @type {Timer}
         */
        this._timer = new Timer();

        /**
         * The stored microphone loudness measurement.
         * @type {number}
         */
        this._cachedLoudness = -1;

        /**
         * The time of the most recent microphone loudness measurement.
         * @type {number}
         */
        this._cachedLoudnessTimestamp = 0;
         
         /**
         * Map of soundPlayers by sound id.
         * @type {Map<string, SoundPlayer>}
         */
        this._soundPlayers = new Map();

        this._stopAllSpeech = this._stopAllSpeech.bind(this);
        if (this.scratch_vm) {
            this.scratch_vm.on('PROJECT_STOP_ALL', this._stopAllSpeech);
        }

        this._onTargetCreated = this._onTargetCreated.bind(this);
        if (this.scratch_vm) {
            this.scratch_vm.on('targetWasCreated', this._onTargetCreated);
        }
        
        this.scratch_vm.on('EDIT_TEXT_MODEL', modelInfo => {
            console.log(modelInfo);
            console.log("Calling bound function");
            this.editModel.bind(this, modelInfo);
        });
        this.scratch_vm.on('EDIT_TEXT_CLASSIFIER', modelInfo => {
            console.log(modelInfo);
            console.log("Calling bound function");
            this.editModel.bind(this, modelInfo);
        });
        
        this.labelList = [];
        this.labelListEmpty = true;
        
        // When a project is loaded, reset all the model data
        this.scratch_vm.on('PROJECT_LOADED', () => {
            this.clearLocal();
            this.loadModelFromRuntime();
        });
        // Listen for model editing events emitted by the text modal
        this.scratch_vm.on('NEW_EXAMPLES', (examples, label) => {
            this.newExamples(examples, label);
        });
        this.scratch_vm.on('NEW_LABEL', (label) => {
            this.newLabel(label);
        });
        this.scratch_vm.on('DELETE_EXAMPLE', (label, exampleNum) => {
            this.deleteExample(label, exampleNum);
        });
        this.scratch_vm.on('RENAME_LABEL', (oldName, newName) => {
            this.renameLabel(oldName, newName);
        });
        this.scratch_vm.on('DELETE_LABEL', (label) => {
            this.clearAllWithLabel({LABEL: label});
        });
        this.scratch_vm.on('CLEAR_ALL_LABELS', () => {
            if (!this.labelListEmpty && confirm('Are you sure you want to clear all labels?')) {    //confirm with alert dialogue before clearing the model
                let labels = [...this.labelList];
                for (var i = 0; i < labels.length; i++) {
                    this.clearAllWithLabel({LABEL: labels[i]});
                }
                //this.clearAll(); this crashed Scratch for some reason
            }
        });

        //Listen for model editing events emitted by the classifier modal
        this.scratch_vm.on('EXPORT_CLASSIFIER', () => {
            this.exportClassifier();
        });
        this.scratch_vm.on('LOAD_CLASSIFIER', () => {
            console.log("load");
            this.loadClassifier();
        });

        
        this._recognizedSpeech = "";

    }

    /**
     * An object with info for each voice.
     */
    get VOICE_INFO () {
        return {
            [SQUEAK_ID]: {
                name: formatMessage({
                    id: 'text2speech.squeak',
                    default: 'squeak',
                    description: 'Name for a funny voice with a high pitch.'
                }),
                gender: 'female',
                playbackRate: 1.19 // +3 semitones
            },
            [TENOR_ID]: {
                name: formatMessage({
                    id: 'text2speech.tenor',
                    default: 'tenor',
                    description: 'Name for a voice with ambiguous gender.'
                }),
                gender: 'male',
                playbackRate: 1
            },
            [ALTO_ID]: {
                name: formatMessage({
                    id: 'text2speech.alto',
                    default: 'alto',
                    description: 'Name for a voice with ambiguous gender.'
                }),
                gender: 'female',
                playbackRate: 1
            },
            [GIANT_ID]: {
                name: formatMessage({
                    id: 'text2speech.giant',
                    default: 'giant',
                    description: 'Name for a funny voice with a low pitch.'
                }),
                gender: 'male',
                playbackRate: 0.84 // -3 semitones
            }
        };
    }
    
     /**
     * The key to load & store a target's text2speech state.
     * @return {string} The key.
     */
    static get STATE_KEY () {
        return 'Scratch.text2speech';
    }

    /**
     * The default state, to be used when a target has no existing state.
     * @type {Text2SpeechState}
     */
    static get DEFAULT_TEXT2SPEECH_STATE () {
        return {
            voiceId: SQUEAK_ID
        };
    }
    
    /**
     * @param {Target} target - collect  state for this target.
     * @returns {Text2SpeechState} the mutable state associated with that target. This will be created if necessary.
     * @private
     */
    _getState (target) {
        let state = target.getCustomState(Scratch3TextClassificationBlocks.STATE_KEY);
        if (!state) {
            state = Clone.simple(Scratch3TextClassificationBlocks.DEFAULT_TEXT2SPEECH_STATE);
            target.setCustomState(Scratch3TextClassificationBlocks.STATE_KEY, state);
        }
        return state;
    }

    /**
     * When a Target is cloned, clone the state.
     * @param {Target} newTarget - the newly created target.
     * @param {Target} [sourceTarget] - the target used as a source for the new clone, if any.
     * @listens Runtime#event:targetWasCreated
     * @private
     */
    _onTargetCreated (newTarget, sourceTarget) {
        if (sourceTarget) {
            const state = sourceTarget.getCustomState(Scratch3TextClassificationBlocks.STATE_KEY);
            if (state) {
                newTarget.setCustomState(Scratch3TextClassificationBlocks.STATE_KEY, Clone.simple(state));
            }
        }
    }
    
    /**
     * @returns {object} metadata for this extension and its blocks.
     */
    getInfo () {
        // Set the video display properties to defaults the first time
        // getInfo is run. This turns on the video device when it is
        // first added to a project, and is overwritten by a PROJECT_LOADED
        // event listener that later calls updateVideoDisplay
        if (this.firstInstall) {
            this.globalVideoState = VideoState.ON;
            this.globalVideoTransparency = 50;
            this.updateVideoDisplay();
            this.firstInstall = false;
            this.predictionState = {};
        }

        // Return extension definition
        return {
            id: 'textClassification',
            name: formatMessage({
                id: 'textClassification.categoryName',
                default: 'Text Classification',
                description: 'Label for the Text Classification extension category'
            }),
            blockIconURI: blockIconURI,
            menuIconURI: menuIconURI,
            //color1, color2, color3
            blocks: [
                {
                    func: 'EDIT_TEXT_MODEL',
                    blockType: BlockType.BUTTON,
                    text: 'Edit Model'
                },
                {
                    func: 'EDIT_TEXT_CLASSIFIER',
                    blockType: BlockType.BUTTON,
                    text: 'Load / Save Model'
                },
                
                {
                    opcode: 'ifTextMatchesClass',
                    text: formatMessage({
                        id: 'textClassification.ifTextMatchesClass',
                        default: '[TEXT] matches [CLASS_NAME] ?',
                        description: 'Conditional that is true when the text matches the text classification model class [CLASS_NAME]'
                    }),
                    blockType: BlockType.BOOLEAN,
                    arguments: {
                        TEXT: {
                            type: ArgumentType.STRING,
                            defaultValue: 'Enter text or answer block'
                        },
                        CLASS_NAME: {
                            type: ArgumentType.STRING,
                            menu: 'model_classes',
                            defaultValue: this.getLabels()[0],
                        }
                    }
                },
                {
                    opcode: 'getModelPrediction',
                    text: formatMessage({
                        id: 'textClassification.getModelPrediction',
                        default: 'predict class for [TEXT]',
                        description: 'Get the class name that the input text matches'
                    }),
                    blockType: BlockType.REPORTER,
                    arguments: {
                        TEXT: {
                            type: ArgumentType.STRING,
                            defaultValue: 'Enter text or answer block'
                        }
                    },
                },
                {
                    opcode: 'getConfidence',
                    text: formatMessage({
                        id: 'textClassification.getConfidence',
                        default: 'get confidence for [TEXT]',
                        description: 'get the confidence for the labeling of a specified text'
                    }),
                    blockType: BlockType.REPORTER,
                    arguments: {
                        TEXT: {
                            type: ArgumentType.STRING,
                            defaultValue: 'Enter text or answer block'
                        }
                    }
                },
                '---',
                {
                    opcode: 'speakText',
                    text: formatMessage({
                        id: 'textClassification.speakText',
                        default: 'speak [TEXT]',
                        description: 'Send text to the speech to text engine'
                    }),
                    blockType: BlockType.COMMAND,
                    arguments: {
                        TEXT: {
                            type: ArgumentType.STRING,
                            defaultValue: 'Hello'
                        }
                    },
                },
                {
                    opcode: 'askSpeechRecognition',
                    text: formatMessage({
                        id: 'textClassification.askSpeechRecognition',
                        default: 'ask [PROMPT] and wait',
                        description: 'Get the class name that the input text matches'
                    }),
                    blockType: BlockType.COMMAND,
                    arguments: {
                        PROMPT: {
                            type: ArgumentType.STRING,
                            defaultValue: 'How are you?'
                        }
                    },
                },
                {
                    opcode: 'getRecognizedSpeech',
                    text: formatMessage({
                        id: 'textClassification.getRecognizedSpeech',
                        default: 'answer',
                        description: 'Return the results of the speech recognition'
                    }),
                    blockType: BlockType.REPORTER,
                },
                {
                    opcode: 'setVoice',
                    text: formatMessage({
                        id: 'text2speech.setVoiceBlock',
                        default: 'set voice to [VOICE]',
                        description: 'Set the voice for speech synthesis.'
                    }),
                    blockType: BlockType.COMMAND,
                    arguments: {
                        VOICE: {
                            type: ArgumentType.STRING,
                            menu: 'voices',
                            defaultValue: SQUEAK_ID
                        }
                    }
                },
                '---',
                {
                    opcode: 'onHeardSound',
                    text: formatMessage({
                        id: 'textClassification.onHeardSound',
                        default: 'when heard sound > [THRESHOLD]',
                        description: 'Event that triggers when a sound is heard above a threshold'
                    }),
                    blockType: BlockType.HAT,
                    arguments: {
                        THRESHOLD: {
                            type: ArgumentType.NUMBER,
                            defaultValue: 10
                        }
                    },
                }
            ],
            menus: {
                voices: {
                    acceptReporters: true,
                    items: this.getVoiceMenu()
                },
                model_classes: {
                    acceptReporters: false,
                    items: 'getLabels'
                }
            }
        };
    }
    
    /**
     * Moves info from the runtime into the classifier, called when a project is loaded
     */    
    loadModelFromRuntime () {
        //console.log("Load model from runtime");
        this.labelList = [];
        this.labelListEmpty = false;
        let textData = this.scratch_vm.modelData.textData;

        for (let label in this.scratch_vm.modelData.textData) {
            if (this.scratch_vm.modelData.textData.hasOwnProperty(label)) {
                let textExamples = textData[label];
                this.newLabel(label);
                this.newExamples(textExamples, label);
            }
        }

        if (this.labelList.length == 0) {
            this.labelList.push('');    //if the label list is empty, fill it with an empty string
            this.labelListEmpty = true;
        }
    }

    /**
     * Return label list for block menus
     * @return {array of strings} an array of the labels for the text model classifier
     */
    getLabels () {
        return this.labelList;
    }

    /**
     * TODO grab text and add it as an example
     * @param {string} args.LABEL the name of the label to add an example to
     */
    textExample (args) {
        console.log("Get text example");
        // TODO grab text
        let text = '';
         if (frame) {
             this.newExamples([text], args.LABEL);
         }
    }

    /**
     * Add new examples to a label
     * @param {array of strings} examples a list of text examples to add to a label
     * @param {string} label the name of the label
     */
    newExamples (text_examples, label) {   //add examples for a label
        console.log("Add examples to label " + label);
        console.log(text_examples);
        if (this.labelListEmpty) {
            // Edit label list accordingly
            this.labelList.splice(this.labelList.indexOf(''), 1);
            this.labelListEmpty = false;
        }
        if (!this.labelList.includes(label)) {
            this.labelList.push(label);
        }
        for (let text_example of text_examples) {
            if (!this.scratch_vm.modelData.textData[label].includes(text_example)) {
                const embeddedexample = this.getembeddedwords(text_example,label,"example");
                this.scratch_vm.modelData.textData[label].push(text_example);
                this.scratch_vm.modelData.classifierData[label].push(text_example);
                this.count++;
            }
        }

    }
    
    /**
     * Add a new label to labelList
     * @param {string} label the name of the label
     */
    newLabel (newLabelName) {   //add the name of a new label
        if (this.labelListEmpty) {
            // Edit label list accordingly
            this.labelList.splice(this.labelList.indexOf(''), 1);
            this.labelListEmpty = false;
        }
        if (!this.labelList.includes(newLabelName)) {
            this.labelList.push(newLabelName);
        }
        
        this.scratch_vm.modelData.textData[newLabelName] = [];
        this.scratch_vm.modelData.classifierData[newLabelName] = [];
        // update drowndown of class names
        //this.scratch_vm.emit("TOOLBOX_EXTENSIONS_NEED_UPDATE");
        this.scratch_vm.requestToolboxExtensionsUpdate();
    }

    /**
     * Rename a label
     * @param {string} oldName the name of the label to change
     * @param {string} newname the new name for the label
     */
    renameLabel (oldName, newName) {
        console.log("Rename a label");

        let data = {...this.classifier.getClassifierDataset()};  //reset the classifier dataset with the renamed label
        if (data[oldName]) {
            data[newName] = data[oldName];
            delete data[oldName];
            this.classifier.setClassifierDataset(data);
        }


        this.scratch_vm.modelData.classifierData[newName] = this.scratch_vm.modelData.classifierData[oldName];  //reset the runtime's model data with the new renamed label (to share with GUI)
        delete this.scratch_vm.modelData.classifierData[oldName];

        this.scratch_vm.modelData.textData[newName] = this.scratch_vm.modelData.textData[oldName];  //reset the runtime's model data with the new renamed label (to share with GUI)
        delete this.scratch_vm.modelData.textData[oldName];

        this.labelList.splice(this.labelList.indexOf(oldName), 1);  //reset label list with the new renamed label
        this.labelList.push(newName);
    }

    /**
     * Delete an example (or all loaded examples, if exampleNum === -1)
     * @param {string} label the name of the label with the example to be removed
     * @param {integer} exampleNum which example, in the array of a label's examples, to remove
     */
    deleteExample (label, exampleNum) {
        console.log("Delete example " + exampleNum + " with label " + label);
        let data = {...this.classifier.getClassifierDataset()};  //reset the classifier dataset with the deleted example
        let labelExamples = data[label].arraySync();
         // Remove label from the runtime's model data (to share with the GUI)
         if (exampleNum === -1) {    //if this is true, delete all the loaded examples
            let numLoadedExamples = this.scratch_vm.modelData.classifierData[label].length - this.scratch_vm.modelData.textData[label].length;   //imageData[label].length is ONLY the length of the NEW examples (not the saved and then loaded ones!)
            this.scratch_vm.modelData.classifierData[label].splice(0, numLoadedExamples);
            labelExamples.splice(0, numLoadedExamples);
         } else {
         this.scratch_vm.modelData.textData[label].splice(exampleNum, 1);
         this.scratch_vm.modelData.classifierData[label].splice(exampleNum - this.scratch_vm.modelData.textData[label].length - 1, 1);
         labelExamples.splice(exampleNum - this.scratch_vm.modelData.textData[label].length - 1, 1);
         }

         if (labelExamples.length > 0) {
            data[label] = tf.tensor(labelExamples);
            this.classifier.setClassifierDataset(data);
        } else {
            this.classifier.clearClass(label);  //if there are no more examples for this label, don't consider it in the classifier anymore (but keep it in labelList and the runtime model data)
        }

    }

    /**
     * Clear all data stored in the classifier and label list
     */
    clearLocal () {
        console.log("Clear local data");
        this.scratch_vm.emit("TOOLBOX_EXTENSIONS_NEED_UPDATE");
        this.labelList = [''];
        this.labelListEmpty = true;
        this.classifier.clearAllClasses();
    }

    /**
     * Clear local label list, but also clear all data stored in the runtime
     */
    clearAll () {
        console.log("Clear all data");
        this.clearLocal();
        // Clear runtime's model data
        
        this.scratch_vm.modelData = {textData: {}, classifierData: {}, nextLabelNumber: 1};
        
    }

    /**
     * Clear all examples with a given label
     * @param {string} args.LABEL the name of the label to remove from the model
     */
    clearAllWithLabel (args) {
        console.log("Get rid of all examples with label " + args.LABEL);
        if (this.labelList.includes(args.LABEL)) {
            if (this.classifier.getClassExampleCount()[args.LABEL] > 0) {
                this.classifier.clearClass(args.LABEL);  //remove label from the classifier
                console.log("number of classes");
                console.log(this.classifier.getNumClasses());
            }
            // Remove label from labelList
            this.labelList.splice(this.labelList.indexOf(args.LABEL), 1);
            // Remove label from the runtime's model data (to share with the GUI)
            delete this.scratch_vm.modelData.classifierData[args.LABEL];  
            delete this.scratch_vm.modelData.textData[args.LABEL];
            // If the label list is now empty, fill it with an empty string
            if (this.labelList.length === 0) {  
                this.labelListEmpty = true;
                this.labelList.push('');
            }
        }
    }
    
    
    /**
     * Detects if the sound from the input mic is louder than a particular threshold
     * @param args.THRESHOLD {integer} the threshold of loudness to trigger on
     * @return {integer} true if the loudness is above the threshold and false if it is not
     */    
    onHeardSound(args) {
        let threshold = args.THRESHOLD;
        
        return this.getLoudness() > threshold;
    }
    
    /**
     * Get the input volume from the mic
     * @return {integer} mic volume at current time
     */
    getLoudness () {
        if (typeof this.scratch_vm.audioEngine === 'undefined') return -1;
        if (this.scratch_vm.currentStepTime === null) return -1;

        // Only measure loudness once per step
        const timeSinceLoudness = this._timer.time() - this._cachedLoudnessTimestamp;
        if (timeSinceLoudness < this.scratch_vm.currentStepTime) {
            return this._cachedLoudness;
        }

        this._cachedLoudnessTimestamp = this._timer.time();
        this._cachedLoudness = this.scratch_vm.audioEngine.getLoudness();
        return this._cachedLoudness;
    }
    
    /**
     * Get the menu of voices for the "set voice" block.
     * @return {array} the text and value for each menu item.
     */
    getVoiceMenu () {
        return Object.keys(this.VOICE_INFO).map(voiceId => ({
            text: this.VOICE_INFO[voiceId].name,
            value: voiceId
        }));
    }
    
    /**
     * Set the voice for speech synthesis for this sprite.
     * @param  {object} args Block arguments
     * @param {object} util Utility object provided by the runtime.
     */
    setVoice (args, util) {
        const state = this._getState(util.target);

        let voice = args.VOICE;

        // If the arg is a dropped number, treat it as a voice index
        let voiceNum = parseInt(voice, 10);
        if (!isNaN(voiceNum)) {
            voiceNum -= 1; // Treat dropped args as one-indexed
            voiceNum = MathUtil.wrapClamp(voiceNum, 0, Object.keys(this.VOICE_INFO).length - 1);
            voice = Object.keys(this.VOICE_INFO)[voiceNum];
        }

        // Only set the voice if the arg is a valid voice id.
        if (Object.keys(this.VOICE_INFO).includes(voice)) {
            state.voiceId = voice;
        }
    }
    
    /**
     * Stop all currently playing speech sounds.
     */
    _stopAllSpeech () {
        this._soundPlayers.forEach(player => {
            player.stop();
        });
    }

    /**
     * Convert the provided text into a sound file and then play the file.
     * @param  {object} args Block arguments
     * @param {object} util Utility object provided by the runtime.
     * @return {Promise} A promise that resolves after playing the sound
     */
    async speakText(args, util) {
        // Cast input to string
        let words = Cast.toString(args.TEXT);
        let locale = 'en-US';

        const state = this._getState(util.target);

        let gender = this.VOICE_INFO[state.voiceId].gender;
        let playbackRate = this.VOICE_INFO[state.voiceId].playbackRate;
        
        // Build up URL
        let path = `${SERVER_HOST}/synth`;
        path += `?locale=${locale}`;
        path += `&gender=${gender}`;
        path += `&text=${encodeURIComponent(words.substring(0, 128))}`;
        // Perform HTTP request to get audio file
        return new Promise(resolve => {
            nets({
                url: path,
                timeout: SERVER_TIMEOUT
            }, (err, res, body) => {
                if (err) {
                    console.warn(err);
                    return resolve();
                }

                if (res.statusCode !== 200) {
                    console.warn(res.statusCode);
                    return resolve();
                }

                // Play the sound
                const sound = {
                    data: {
                        buffer: body.buffer
                    }
                };
                this.scratch_vm.audioEngine.decodeSoundPlayer(sound).then(soundPlayer => {
                    this._soundPlayers.set(soundPlayer.id, soundPlayer);

                    soundPlayer.setPlaybackRate(playbackRate);

                    // Increase the volume
                    const engine = this.scratch_vm.audioEngine;
                    const chain = engine.createEffectChain();
                    chain.set('volume', SPEECH_VOLUME);
                    soundPlayer.connect(chain);

                    soundPlayer.play();
                    soundPlayer.on('stop', () => {
                        this._soundPlayers.delete(soundPlayer.id);
                        resolve();
                    });
                });
            });
        });
    }
    
    recognizeSpeech() {
        let recognition = new webkitSpeechRecognition();
        let self = this;
        
        return new Promise(resolve => {
            recognition.start();
            recognition.onresult = function(event) {
                if (event.results.length > 0) {
                    self._recognizedSpeech = event.results[0][0].transcript;
                }
                resolve();
            };
        });
    }
    
    async askSpeechRecognition(args, util) {
        let prompt = Cast.toString(args.PROMPT);
        args.TEXT = prompt;
        let speakTextResolved = await this.speakText(args, util);
        return this.recognizeSpeech();
     }
    
    getRecognizedSpeech() {
        return this._recognizedSpeech;
    }

    /**
     * A scratch conditional block that checks if a text example is a part of a particular class
     * @param {object} args - the block arguments
     * @param {BlockUtility} util - the block utility
     * @returns {boolean} true if the model matches
     *   reference
     */
     async ifTextMatchesClass (args) {
        const text = args.TEXT;
        const className = args.CLASS_NAME;

        if (className) {
            await this.get_embeddings(text, 'none', 'predict');
            return className == this.predictedLabel;
        }

        return false;
    }

    /**
     * A scratch hat block reporter that returns whether the input text matches the model class.
     * @param {object} args - the block arguments
     * @param {BlockUtility} util - the block utility
     * @returns {string} class name if input text matched, empty string if there's a problem with the model
     */
     async getModelPrediction (args) {
        const text = args.TEXT;
        await this.get_embeddings(text, 'none', 'predict');
        return this.predictedLabel;
    }

    async getConfidence (args) {
        const text = args.TEXT;
        await this.get_embeddings(text, 'none', 'predict');
        return this.confidence;
    }

    /**
     * Calls the method which embeds text as a 2d tensor
     * @param text - the text inputted
     * @param label - this is always "none" when embedding examples
     * @param direction - is either "example" when an example is being inputted or "predict" when a word to be classified is inputted
     */
        async getembeddedwords(text,label,direction) {
            if (!this.labelListEmpty) {
                const embeddedtext = await this.get_embeddings(text,label,direction);
            }
        }

    /**
     * Embeds text and either adds examples to classifier or returns the predicted label
     * Changes text into a 2d tensor
     * @param text - the text inputted
     * @param label - the label to add the example to
     * @param direction - is either "example" when an example is being inputted or "predict" when a word to be classified is inputted
     * @returns if the direction is "predict" returns the predicted label for the text inputted
     */
    // TODO rename this function to better represent what it does
    async get_embeddings (text, label, direction) {
        // translates text from any language to english
        const newText = await this.getTranslate(text, 'en');

        if (!this.labelListEmpty) {
            // before going through with the expensive USE model loading
            //   check to see if we already have an embedding for this input
            let textEmbeddings = this.exampleEmbeddings[newText] || this.lastEmbedding[newText];
            if (!textEmbeddings) {
                let useModel = await use.load();
                textEmbeddings = await useModel.embed(newText);    
            }
            if (direction === "example") {
                await this.classifier.addExample(textEmbeddings, label);

                // save embeddings of examples for later use
                this.exampleEmbeddings[newText] = textEmbeddings;
                return "Inputting to classes";
    
            } else if (direction === "predict") {
                // TODO consider making this value the n-th root of the number of labels e.g. for 5 labels, take the 5th root
                const k = Math.sqrt(this.count);
                let prediction = await this.classifier.predictClass(textEmbeddings, k);
                console.log("get embeddings result:", prediction);
                this.predictedLabel = prediction.label;
                this.confidence = prediction.confidences[prediction.label];
                return [this.predictedLabel, this.confidence];
            }
        } else {
            return "No class inputted";
        }
    }
   /**
     * Exports the labels and examples in the form of a json document with the default name of "classifier-info.json"
     */
      exportClassifier() { //exports classifier as JSON file
        let dataset = this.scratch_vm.modelData.textData;
        let jsonStr = JSON.stringify(dataset);
        //exports json file
        var data = "text/json;charset=utf-8," + encodeURIComponent(jsonStr);
        var a = document.createElement('a');
        a.setAttribute("href", "data:" + data);
        a.setAttribute("download", "classifier-info.json");
        a.click();
      }
   /**
     * Loads the json document which contains labels and examples. Inputs the labels and examples into the classifier
     */
      async loadClassifier() { //loads classifier to project
        var self = this
        var dataset = document.getElementById("imported-classifier").files[0];
        if (dataset !== undefined) {
        fr = new FileReader();
        fr.onload = receivedText;
        fr.readAsText(dataset);
        }
  
      function receivedText(e) { //parses through the json document and adds to the model textData and classifier
        let lines = e.target.result;
        try {
        var newArr = JSON.parse(lines);
        self.clearAll();
        for (let label in newArr) {
            if (newArr.hasOwnProperty(label)) {
                let textExamples = newArr[label];
                self.newLabel(label);
                self.newExamples(textExamples, label);
            }
        }
    } catch (err) {
        console.log("Incorrect document form");
    }
        
      }
    }

    getTranslate (words,language) {
        // Don't remake the request if we already have the value.
        if (this._lastTextTranslated === words &&
            this._lastLangTranslated === language) {
            return this._translateResult;
        }

        const lang = language;

        let urlBase = `${serverURL}translate?language=`;
        urlBase += lang;
        urlBase += '&text=';
        urlBase += encodeURIComponent(words);

        const tempThis = this;
        const translatePromise = new Promise(resolve => {
            nets({
                url: urlBase,
                timeout: serverTimeoutMs
            }, (err, res, body) => {
                if (err) {
                    log.warn(`error fetching translate result! ${res}`);
                    resolve('');
                    return '';
                }
                const translated = JSON.parse(body).result;
                tempThis._translateResult = translated;
                // Cache what we just translated so we don't keep making the
                // same call over and over.
                tempThis._lastTextTranslated = words;
                tempThis._lastLangTranslated = language;
                resolve(translated);
                return translated;
            });

        });
        translatePromise.then(translatedText => translatedText);
        return translatePromise;
    }
     



      
}

module.exports = Scratch3TextClassificationBlocks;
